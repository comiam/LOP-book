\documentclass[18pt, a4paper]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[table]{xcolor}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage[english,russian]{babel}
\usepackage[14pt]{extsizes}
\usepackage[left=5mm, top=5mm, right=5mm, bottom=20mm, nohead, footskip=5mm]{geometry}
\usepackage{indentfirst}
\usepackage{misccorr}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{longtable}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{extarrows}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage{mmap}
\usepackage{cancel}
\usepackage{pgfplots}

\title{Логические основы программирования}
\author{Лекции Г.Э. Яхъяевой для 2 курса ФИТ НГУ}
\date{2 издание: 1 семестр, 2021 г.}


\newcounter{thm}
\newcounter{par}
\newcounter{spar}
\newcounter{zap}

\newcommand{\msection}[1]{\stepcounter{thm}\section*{\thethm. #1}\addcontentsline{toc}{section}{\thethm. #1}}

\newcommand{\msubsection}[1]{\setcounter{spar}{0}\stepcounter{par}\setcounter{zap}{1}\section*{\S \thepar. #1 }\addcontentsline{toc}{subsection}{\S \thepar. #1}}

\newcommand{\msssection}[1]{\stepcounter{spar}\setcounter{zap}{1}\section*{\S \thepar.\thespar. #1 }\addcontentsline{toc}{subsubsection}{\S \thepar.\thespar. #1}}

\newcommand{\opr}{\textbf{\textsc{Определение \thepar.\if\thespar1\thespar.\fi\thezap.\;}}\stepcounter{zap}}
\newcommand{\predl}{\textbf{\textsc{Предложение \thepar.\if\thespar1\thespar.\fi\thezap.\;}}\stepcounter{zap}}
\newcommand{\sled}{\textbf{\textsc{Следствие \thepar.\if\thespar1\thespar.\fi\thezap.\;}}\stepcounter{zap}}
\newcommand{\teor}{\textbf{\textsc{Теорема \thepar.\if\thespar1\thespar.\fi\thezap.\;}}\stepcounter{zap}}
\newcommand{\zam}{\textbf{\textsc{Замечание \thepar.\if\thespar1\thespar.\fi\thezap.\;}}\stepcounter{zap}}
\newcommand{\lemma}{\textbf{\textsc{Лемма \thepar.\if\thespar1\thespar.\fi\thezap.\;}}\stepcounter{zap}}

\newcommand{\oprT}[1]{\textbf{\textsc{Определение \thepar.\if\thespar1\thespar.\fi\thezap.}(#1).}\stepcounter{zap}}
\newcommand{\predlT}[1]{\textbf{\textsc{Предложение \thepar.\if\thespar1\thespar.\fi\thezap.}(#1).}\stepcounter{zap}}
\newcommand{\sledT}[1]{\textbf{\textsc{Следствие \thepar.\if\thespar1\thespar.\fi\thezap.}(#1).}\stepcounter{zap}}
\newcommand{\teorT}[1]{\textbf{\textsc{Теорема \thepar.\if\thespar1\thespar.\fi\thezap.}(#1).}\stepcounter{zap}}
\newcommand{\lemT}[1]{\textbf{\textsc{Лемма \thepar.\if\thespar1\thespar.\fi\thezap.}(#1).}\stepcounter{zap}}
\newcommand{\bftex}[1]{\textbf{\textsc{#1}.}}

\newcommand{\centr}[1]{\makebox[\linewidth]{#1}}

\newcommand{\primer}{\textbf{Пример:\;}}
\newcommand{\primerT}[1]{\textbf{Пример #1:\;}}

\newcommand{\mA}{\mathfrak{A}}
\newcommand{\mB}{\mathfrak{B}}
\newcommand{\mC}{\mathfrak{C}}
\newcommand{\mJ}{\mathfrak{J}}
\newcommand{\mL}{\mathfrak{L}}
\newcommand{\mR}{\mathfrak{N}}
\newcommand{\mM}{\mathfrak{M}}
\newcommand{\msM}{\mathfrak{m}}
\newcommand{\msP}{\mathfrak{p}}
\newcommand{\mzero}{\mathfrak{0}}
\newcommand{\dok}{\textsc{Доказательство:}}
\newcommand{\dokup}{\textsc{Доказательство: упражнение.}}
\newcommand{\bezdok}{\textsc{Без доказательства.}}
\newcommand{\rightdok}{\boxed{(\Rightarrow)}}
\newcommand{\leftdok}{\boxed{(\Leftarrow)}}
\newcommand{\galoisup}{{^\uparrow}}
\newcommand{\galoisdown}{{^\downarrow}}

\newcommand{\ovl}[1]{\overline{#1}}

\newcommand{\ampersand}{\;\&\;}
\newcommand{\Gm}{\Gamma}
\newcommand{\vp}{\varphi}
\newcommand{\vpsko}{\varphi_{sko}}
\newcommand{\sko}{\textbf{\text{ссф}}\;}
\newcommand{\vd}{\vdash}
\newcommand{\vD}{\vDash}
\newcommand{\al}{\alpha}
\newcommand{\res}[2]{Res(#1,#2)}
\DeclareUnicodeCharacter{22AD}{\nvDash}
\DeclareUnicodeCharacter{22AC}{\nvdash}

\newcommand{\sg}{\sigma}
\newcommand{\lod}[3]{#1_#2\dots#1_#3}
\newcommand{\lot}[3]{#1_#2,\dots,#1_#3}
\newcommand{\lotk}[4]{#1_#3 #2_#3,\dots,#1_#4 #2_#4}
\newcommand{\mr}{{r-1}}
\newcommand{\pr}{{r+1}}

\newcommand{\toPr}{:\!\!\text{-}}

\newcommand{\lm}{\lambda}
\newcommand{\lmb}{\Lambda}
\newcommand{\kb}{\mathcal{B}}
\newcommand{\kc}{\mathcal{C}}
\newcommand{\ki}{\mathcal{I}}
\newcommand{\kk}{\mathcal{K}}
\newcommand{\ks}{\mathcal{S}}
\newcommand{\kw}{\mathcal{W}}
\newcommand{\ky}{\mathcal{Y}}

\newcommand{\redb}{\underset{\beta}{\longrightarrow}}
\newcommand{\reda}{\underset{\alpha}{\longrightarrow}}
\newcommand{\rede}{\underset{\eta}{\longrightarrow}}
\newcommand{\redr}{\rightarrow_R}
\newcommand{\redrm}{\twoheadrightarrow_R}

\newcommand{\modal}{M\!O\!D}
\newcommand{\st}[1]{st_#1}
\newcommand{\may}{\scalebox{0.8}{$\diamondsuit$}}
\newcommand{\need}{\scalebox{0.75}{$\Box$}}
\newcommand{\bigs}[1]{\scalebox{1.3}{$#1$}}
\newcommand{\chf}{\bigs\mu}

\newcommand{\lfunction}[1]{\textcolor{purple}{\textbf{#1}}}
\newcommand{\churchnum}[1]{{\underline{#1}}}
    
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.95}
\definecolor{linkc}{rgb}{0.33,	0.51,	0.78}

\hypersetup{
    colorlinks=true,
    urlcolor=linkc,
    linkcolor=black,
    linkbordercolor=red,
    pdfborderstyle={/S/U/W 1}
    pdfpagemode=FullScreen,
    }
    
\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour},   commentstyle=\color{magenta},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=1,
  extendedchars=true,
	literate={Ö}{{\"O}}1
	{Ä}{{\"A}}1
	{Ü}{{\"U}}1
	{ß}{{\ss}}1
	{ü}{{\"u}}1
	{ä}{{\"a}}1
	{ö}{{\"o}}1
	{~}{{\textasciitilde}}1
	{а}{{\selectfont\char224}}1
	{б}{{\selectfont\char225}}1
	{в}{{\selectfont\char226}}1
	{г}{{\selectfont\char227}}1
	{д}{{\selectfont\char228}}1
	{е}{{\selectfont\char229}}1
	{ё}{{\"e}}1
	{ж}{{\selectfont\char230}}1
	{з}{{\selectfont\char231}}1
	{и}{{\selectfont\char232}}1
	{й}{{\selectfont\char233}}1
	{к}{{\selectfont\char234}}1
	{л}{{\selectfont\char235}}1
	{м}{{\selectfont\char236}}1
	{н}{{\selectfont\char237}}1
	{о}{{\selectfont\char238}}1
	{п}{{\selectfont\char239}}1
	{р}{{\selectfont\char240}}1
	{с}{{\selectfont\char241}}1
	{т}{{\selectfont\char242}}1
	{у}{{\selectfont\char243}}1
	{ф}{{\selectfont\char244}}1
	{х}{{\selectfont\char245}}1
	{ц}{{\selectfont\char246}}1
	{ч}{{\selectfont\char247}}1
	{ш}{{\selectfont\char248}}1
	{щ}{{\selectfont\char249}}1
	{ъ}{{\selectfont\char250}}1
	{ы}{{\selectfont\char251}}1
	{ь}{{\selectfont\char252}}1
	{э}{{\selectfont\char253}}1
	{ю}{{\selectfont\char254}}1
	{я}{{\selectfont\char255}}1
	{А}{{\selectfont\char192}}1
	{Б}{{\selectfont\char193}}1
	{В}{{\selectfont\char194}}1
	{Г}{{\selectfont\char195}}1
	{Д}{{\selectfont\char196}}1
	{Е}{{\selectfont\char197}}1
	{Ё}{{\"E}}1
	{Ж}{{\selectfont\char198}}1
	{З}{{\selectfont\char199}}1
	{И}{{\selectfont\char200}}1
	{Й}{{\selectfont\char201}}1
	{К}{{\selectfont\char202}}1
	{Л}{{\selectfont\char203}}1
	{М}{{\selectfont\char204}}1
	{Н}{{\selectfont\char205}}1
	{О}{{\selectfont\char206}}1
	{П}{{\selectfont\char207}}1
	{Р}{{\selectfont\char208}}1
	{С}{{\selectfont\char209}}1
	{Т}{{\selectfont\char210}}1
	{У}{{\selectfont\char211}}1
	{Ф}{{\selectfont\char212}}1
	{Х}{{\selectfont\char213}}1
	{Ц}{{\selectfont\char214}}1
	{Ч}{{\selectfont\char215}}1
	{Ш}{{\selectfont\char216}}1
	{Щ}{{\selectfont\char217}}1
	{Ъ}{{\selectfont\char218}}1
	{Ы}{{\selectfont\char219}}1
	{Ь}{{\selectfont\char220}}1
	{Э}{{\selectfont\char221}}1
	{Ю}{{\selectfont\char222}}1
	{Я}{{\selectfont\char223}}1
	{і}{{\selectfont\char105}}1
	{ї}{{\selectfont\char168}}1
	{є}{{\selectfont\char185}}1
	{ґ}{{\selectfont\char160}}1
	{І}{{\selectfont\char73}}1
	{Ї}{{\selectfont\char136}}1
	{Є}{{\selectfont\char153}}1
	{Ґ}{{\selectfont\char128}}1
}
\lstset{style=mystyle}

\setlength{\arrayrulewidth}{1.3pt}

\begin{document}
\linespread{1.3}
 \fontsize{19pt}{22pt}\selectfont
\maketitle

\tableofcontents

\leavevmode\\\\\leavevmode\begin{center}
    Если нашли очепятки, то пишите \href{https://vk.com/id177003653}{\underline{мне}}, я поправлю :)\\
	Если если есть желание обновить методичку, то тебе \href{https://github.com/comiam/LOP-book}{\underline{сюда}}.
\end{center}

\newpage

\setcounter{par}{22}
\setcounter{zap}{1}
\setcounter{thm}{0}

\msection{Автоматизация рассуждений}

В прошлом семестре мы с вами сталкивались с какими нибудь большущими-пребольшущими формулами логики предикатов, с кванторами всякими, замороченными... и мы хотели понять, являются ли они тождественно истинными или нет. Чтобы выяснить это, мы рассуждали логически. Но единого алгоритма проверки истинности для формул логики предикатов не существует. Если мы интуитивно понимали, что формула истинная, то мы доказывали от противного и так приходили к противоречию. Если же наоборот, то искали контраргумент. Но это все хорошо, когда эти задачки на сообразительность кажутся занимательными и мы их решали. 

Гораздо сложнее становится, когда мы хотим автоматизировать, когда хотим придумать программу, которая сама будет решать задачи. Это сделать достаточно сложно... Тем более существует еще одна проблема: теоремы Гёделя и Чёрча о неразрешимости. Что значит неразрешимо? Т.е. нет такого рекурсивного алгоритма, проверяющего, т.и. формула или т.л.? Есть у нас рекурсивно-перечислимые алгоритмы, т.е. проблема перечислима, но не разрешима. Это значит, что не существует алгоритма, на вход которому мы подали формулу, а на выходе выдавался ответ на истинность.

Но опять же, проблема перечислима. Мы можем на вход подать формулу и, если она т.и., то за конечное число шагов мы вычислим это. В противном случае алгоритм будет работать бесконечно и никогда не остановится. На практике строятся алгоритмы, которые, грубо говоря, приближённые. Они считают какую-то вероятность ответа: т.е. если все же программа выяснила, что формула т.и., то нам повезло и на выходе получаем истину. В противном же случае после какого то N-го шага, какого-то этапа, программа завершает работу и показывает некоторую вероятность того, что формула т.л.. Тут проблема состоит в том, на каком этапе обрывать проверку формулы, но это решают различные алгоритмы...

Допустим, такой алгоритм(что решает формулы) у нас есть. Как мы доказывали т.и. формулы? Через построение дерева вывода. Можно ли это запрограммировать? Да. Но у нас правил вывода достаточно много, и мы сидим и думаем, каким способом построить дерево, в какой момент нужно дерево строить подобным образом, а когда наоборот... Т.е. здесь все равно нужна человеческая сообразительность. Перебором построить дерево практически невозможно. Поэтому процедуру построения дерева надо как то оптимизировать. Оптимизация заключается в том, что строится \textit{правило резолюции}(чуть позже разберём) и у нас все доказывается с использованием только одного правила. Вот это и есть основная идея нашего автомата.\\

\msubsection{Скулемовские стандартные формы}

Все мы уже \sout{солдаты} видели страшные формулы, что состоят из тонны кванторов, логических всяких связок, где снаружи ещё стоит куча отрицаний, а внутри орда импликаций или, если фантазия у автора слишком больная, тонна XOR'ов. И доказывать истинность такой формулы в первозданном виде не то чтобы становится тяжело... но очень больно, согласитесь. 

И хотелось бы избавиться от всяких корявых кванторов и задурённых логических связок, т.е. привести формулу к такому виду, в котором будет куда проще что-то выяснять. Этим особым видом формулы у нас будет являться \textbf{скулемовская стандартная форма}.

\newpage

\opr 

\textbf{Литерой} мы будем называть атомарную формулу или её отрицание.

Атомарная формула(вспомним) - это:

$P(\ovl x),\;\lnot P(\ovl x),\;t_1=t_2,\;t_1\neq t_2$.

\textbf{Дизъюнктом} называют дизъюнкцию литер. Аналогия - элементарная дизъюнкция.

$\square$ обозначают пустой дизъюнкт(когда нечего дизъюнктить). $\square$ всегда является т.л.

Пусть у нас есть сигнатура логики предикатов $\sg,\;\vp\in S(\sg)$. Пусть $\vp$ в \textbf{ПНФ} имеет вид $\vp=Q_1x_1\dots Q_n x_n\;\psi(\ovl x),\;Q_i\in\{\exists,\forall\}$ и $\psi$-бескванторная.

Обозначим через $r$ номер первого $\exists$ в $\vp$:

$1)\;r=1,\;\vp=\exists x_1 Q_2x_2\dots Q_n x_n\;\psi(\ovl x)$;

Тогда возъмём новую константу $c\notin\sg$ и возьмём $\sg'=\sg\cup\{c\}$.
Построим формулу $\vp'=Q_2x_2\dots Q_n x_n\;\psi(c,x_2,\dots,x_n)$. Так мы избавились от квантора существования, добавив новую константу.

$2)\;r>1,\;$ т.е. $\vp=\forall_1x_1\dots \forall_{r-1} x_{r-1}\exists_r x_r Q_{r+1}x_{r+1}\dots Q_n x_n\;\psi(x_1,\dots,x_n)$. Обогощаем сигнатуру функцией $f^{(r-1)}\notin\sg,\;\sg'=\sg\cup\{f^{(r-1)}\}$. Построим $\vp'=\forall_1x_1\dots \forall_{r-1} x_{r-1} Q_{r+1}x_{r+1}\dots Q_n x_n\;\psi(x_1,\dots,x_{r-1},f(x_1,\dots,x_{r-1}),\newline x_{r+1},\dots,x_n)$. Так мы избавились от квантора существования, добавив новую функцию. 

После этого мы посмотрели на нашу формулу $\vp'$: если она имеет еще кванторы существования, то таким же образом от них избавляемся. И когда мы дошли до конца, т.е. избавились от всех $\exists$, то такая формула обозначается \underline{$\vpsko$} - \textbf{скулемовская стандартная форма}.\\

\primer

Пусть есть предикат $P(x,y)$="Студент $x$ прочёл книгу $y$"{}.

И пусть есть высказывание "Каждый студент прочитал хотя бы одну книгу"{}, т.е. некоторая $\vp=\forall x\exists yP(x,y)$. У Иванова прочтена одна книга, у Петрова другая книга. Т.е. у 

Иванова - прочтена книга $a$,

Петрова - прочтена книга $b$.

Т.е. мы можем сделать функцию, что в зависимости от фамилии человека дает книгу, что тот прочел, т.е. $\vp=\forall xP(x,f(x))$.

Приведем еще одно высказывание "Данную книгу прочли все студенты"{}, т.е. $\vp=\exists y\forall xP(x,y)$. Заменили книгу на константу, как бы у нас одна "константная книга"{}, которую все прочли, т.е $\vp'=\forall xP(x,c)$.

Сигнатура для $\sko$ $\sg(\vpsko)=\sg\cup\{c_1,\dots,c_l\}\cup\{f_1,\dots,f_k\}$,\\
где $l+k$ - число $\exists$ в $\vp$.\\

\teor 

Пусть $\vp\in S(\sg),\;\vp$ - тожд.л. $\Leftrightarrow\vpsko$ - тожд.л.

\dok

Рассмотрим 2 случая:

\qquad \textbf{Случай 1}: $\vp=\exists_1 x_1 Q_2 x_2\dots Q_n x_n\;\psi(\ovl x)$. 

Тогда $\vp'=Q_2 x_2\dots Q_n x_n\;\psi(c,\lot x 2 n)$.

Покажем, что $\vp$ - т.л. $\Leftrightarrow\vp'$ - т.л.

$\rightdok$ Пусть $\vp$ - т.л. и $\vp'$ - выполнима $\Rightarrow\exists\mA'\in K(\sg\cup\{c\})\!:\mA'\vD\vp'$.

Тогда есть некоторая интерпретация константы, т.е. $c^{\mA'}=a\in|\mA'|$.

Распишем $\mA'\vD\vp'\Leftrightarrow\mA'\vD\lotk Q x 2 n\;\psi(c^{\mA'},\lot x 2 n)\Leftrightarrow\newline\Leftrightarrow\exists a\in|\mA'|\!:\mA'\vD\lotk Q x 2 n\;\psi(a,\lot x 2 n)$.
\newline Возьмём $\mA=\mA'\upharpoonright\sg$. Тогда $\exists a\in|\mA|\!:\mA\vD\lotk Q x 2 n\;\psi(a,\lot x 2 n)\Rightarrow\;\Rightarrow\mA\vD\exists x_1\lotk Q x 2 n\;\psi(\lot x 1 n)\Rightarrow\mA\vD\vp$. \underline{Получили противоречие} с тем, что $\vp$ - т.л.

$\leftdok$ Пусть $\vp'$ - т.л. и $\vp$ - выполнима $\Rightarrow\exists\mA\in K(\sg)\!:\mA\vD\vp$.

Т.е. $\mA\vD\exists x_1\lotk Q x 2 n\;\psi(\lot x 1 n)\Leftrightarrow\newline\Leftrightarrow\exists a\in|\mA|\!:\mA\vD\lotk Q x 2 n\;\psi(a,\lot x 2 n)$.

Теперь обогатим сигнатуру константой $\sg'=\sg\cup\{c\}$ и расширим модель $\mA'=\mA\downharpoonright\sg'$. 

Тогда, по определению, $c^{\mA'}=a\Rightarrow\mA'\vD\lotk Q x 2 n\;\psi(c^{\mA'},\lot x 2 n)\Rightarrow\;\Rightarrow\mA'\vD\vp'$. \underline{Получили противоречие} с тем, что $\vp'$ - т.л.

\qquad \textbf{Случай 2}: 

$\vp=\lotk \forall x 1 \mr \exists_r x_r\lotk Q x \pr n\;\psi(\lot x 1 n)$.

Тогда $\vp'=\lotk \forall x 1 \mr \lotk Q x \pr n\;\psi(\lot x 1 \mr,\newline f(\lot x 1 \mr),\lot x \pr n)$.

Покажем, что $\vp$ - т.л. $\Leftrightarrow\vp'$ - т.л.

$\rightdok$ Пусть $\vp$ - т.л. и $\vp'$ - выполнима.

Тогда $\exists\mA'\in K(\sg\cup\{f\})\!:\mA'\vD\vp'$.

Т.е. $\mA'\vD\lotk \forall x 1 \mr \lotk Q x \pr n\;\psi(\lot x 1 \mr,\newline f(\lot x 1 \mr),\lot x \pr n)\Rightarrow\forall\lot a 1 \mr\in|\mA'|\!:\newline: \mA'\vD\lotk Q x \pr n\;\psi(\lot a 1 \mr, f(\lot a 1 \mr),\lot x \pr n)$.

Пусть $f(\lot a 1 \mr):=c$, т.к. функция уже определена, то она для каждого набора аргументов выдает значение, здесь же для $\lot a 1 \mr$\\выдается $c$. 

Тогда для $\forall\lot a 1 \mr\in|\mA'|\;\exists c\in|\mA'|\!:\newline:\mA'\vD\lotk Q x \pr n\;\psi(\lot a 1 \mr,c,\lot x \pr n)$.

Возьмём $\mA=\mA'\upharpoonright\sg$. Тогда $\forall\lot a 1 \mr\in|\mA|\;\exists c\in|\mA|\!:\newline:\mA\vD\lotk Q x \pr n\;\psi(\lot a 1 \mr,c,\lot x \pr n)\Rightarrow\mA\vD\vp$. 

\underline{Получили противоречие} с тем, что $\vp$ - т.л.

$\leftdok$ Пусть $\vp'$ - т.л. и $\vp$ - выполнима $\Rightarrow\exists\mA\in K(\sg)\!:\mA\vD\vp$.
\newline Тогда $\mA\vD\lotk \forall x 1 \mr\exists_r x_r\lotk Q x \pr n\;\psi(\lot x 1 n)\Rightarrow\newline\Rightarrow\forall\lot a 1 \mr\in|\mA|\;\exists c\in|\mA|\!:\mA\vD\lotk Q x \pr n\;\psi(\lot a 1 \mr,c,\newline \lot x \pr n)$.

Зададим новую функцию, тогда $\sg'=\sg\cup\{f^{(r-1)}\},\;\mA'=\mA\downharpoonright\sg'$. Зададим интерпретацию для функции на модели $f^{\mA'}(\lot a 1 \mr):=c$. Тогда \newline$\forall\lot a 1 \mr\in|\mA'|\!:\mA'\vD\lotk Q x \pr n\psi(\lot a 1 \mr,f(\lot a 1 \mr),\newline \lot x \pr n)\Rightarrow\mA'\vD\lotk \forall x 1 \mr\lotk Q x \pr n\;\psi(\lot x 1 \mr,\newline f(\lot x 1 \mr),\lot x \pr n)\Rightarrow\mA'\vD\vp'$. \underline{Получили противоречие} с тем, что $\vp'$ - т.л.

Из случаев 1) и 2) получаем то, что за один шаг преобразования мы сохранили т.л. формулы. В итоге за конечное число шагов преобразования мы получаем то, что $\vpsko$ так же остается т.л. 

Теорема доказана.\\

\sled 

Предложение $\vp$ - т.и. $\Leftrightarrow(\lnot\vp)_{sko}$ - т.л.\\

Ну и что нам делать с этой формой? Заметим, что теперь эти кванторы всеобщности в \sko мы можем \textit{мысленно убрать}, сказав, что бескванторная часть рассматривается как \underline{для всех входных переменных}, т.е. как бы сведя значимость кванторов в формуле к минимуму, что для нас достаточно удобно. Ну а что делать с бескванторной частью?\\

\opr

Возьмём формулу $\vp$ и её $\sko\vpsko$.

Пусть $\vpsko=\lotk \forall x 1 n\;\psi(\lot x 1 n)$, \\где $\psi(\lot x 1 n)$ - конъюнкция дизъюнктов(аналогия \textbf{КНФ}, но \underline{это не КНФ}).

Т.е. $\psi(\lot x 1 n)=\vp_1(x_1,\dots,x_{m_1})\ampersand\dots\ampersand\vp_k(x_1,\dots,x_{m_k})$.\\Здесь $\vp_i(x_1,\dots,x_{m_i})$ - это дизъюнкт, $m_i\leqslant n$, т.к. могут быть разные формулы и в них могут быть фиктивные переменные, т.е. подформулы могут зависеть от разного количества переменных.

Обозначим $S=\{\vp_1(x_1,\dots,x_{m_1}),\dots,\vp_k(x_1,\dots,x_{m_k})\}$.\\Мы будем говорить, что \textbf{множество дизъюнктов $S$ представляет $\vpsko$}.

\underline{Через $S$ мы будем обозначать $\psi$} и далее все рассуждения будут над множеством дизъюнктов. Нам нужно показать, что $S$ - т.л.\\

\opr

1) $S$ - т.л. $\Leftrightarrow\vpsko$ - т.л. 

2) $S$ - выполнимо $\Leftrightarrow\vpsko$ - выполнима. 

3) $S$ - т.л. $\Leftrightarrow\forall\mA\;\exists\lot a 1 n\in|\mA|\;\exists i\!:\mA\nvDash\vp_i(\lot a 1 n)$.

4) $\vpsko$ выполнима $\Leftrightarrow\exists\mA\;\forall\lot a 1 n\in|\mA|\;\forall i\!:\mA\vD\vp_i(\lot a 1 n)$.\\

Почему мы должны проверять именно т.л., а не т.и., вы спросите. Снова посмотрим на \sko\!\!:

\centr{$\vpsko=\lotk \forall x 1 n\;(\vp_1(x_1,\dots,x_{m_1})\ampersand\dots\ampersand\vp_k(x_1,\dots,x_{m_k}))$}

Тут выходит, что бескванторная часть - это огромная конъюнкция дизъюнктов. И если хотя бы один входящий в конъюнкцию дизъюнкт станет ложным, то ложной станет вся формула. И поэтому при проверке т.л. нам достаточно при каждом наборе входных переменных просто смотреть, стал ли ложным какой либо из входящих в формулу дизъюнкт. А при проверке т.и. нам бы приходилось постоянно проверять истинность \underline{всех дизъюнктов}, и эта проверка тогда была бы очень тяжёлой.

Но разумеется мы не будем перебирать все наборы входных аргументов. Может так сложиться, что таких наборов вовсе континуум. Так что мы пойдём более умным путём, но сохраняя идею с т.л. формулы.

\newpage
\msubsection{Эрбрановский универсум}

Мы говорили, что $S$ - т.л., когда на любой модели существует набор всяких и т.д.. Но что значит "на любой модели"? Это значит, что у нас зафиксирована сигнатура, но могут быть разные универсумы у моделей. Пусть вот сигнатура у нас состоит из двух функций, например, + и -, а универсум может быть из натуральных, вещественных, комплексных чисел, а то и вообще каких нибудь яблок, и мы еще умудряемся их складывать... 

И тогда проверять т.л. у \sko очень тяжело, потому что у нас необозримое множество моделей, на которых нужно будет все проверять. Будет в разы проще, если мы будем рассматривать не любые модели, а модели, у которых \textit{некоторый фиксированный универсум}. Данное фиксированное множество называется \textbf{эрбрановским универсумом}.\\

\opr 

Пусть дано $S$ - множество дизъюнктов, и имеется сигнатура множества $\sg(S)$.

Определим $\sg_S=\begin{cases}
   \sg(S)\cup\{c\}, \text{если не имеет констант}\\
   \sg(S), \text{если имеются константы}
\end{cases}$\\

\opr 

Пусть $S=\{\vp_1(\lot x 1 m),\vp_2(\lot x 1 m),\dots,\vp_k(\lot x 1 m)\}$ - множество дизъюнктов.

Тогда:

1) $H_S=\{t\in T(\sg_S)\;|\;FV(t)=\varnothing(t\text{ - замкнутый терм)}\}$ - \textbf{эрбранов универсум для $S$};

2) Множество всех атомарных предложений 
\newline$A_S=\{P(\lot h 1 n)\;|\;P\in\sg_S,\;\lot h 1 n\in H_S\}$ - \textbf{эрбранов базис для $S$};

3) $\vp_i(\lot h 1 n),\;\vp_i\in S,\;\lot h 1 n\in H_S$ - \textbf{основной пример дизъюнкта $\vp_i(\lot x 1 n)$}; 

4) $\mA_H=\langle H_S;\sg_S\rangle$ - \textbf{$H$-интерпретация $S$}, если выполняются:

\qquad а) $\forall c\in\sg_S\!:c^{\mA_H}=c$;

\qquad б) $\forall f^n\in\sg_S\;\forall\lot h 1 n\in H_S$ выполняется:
\\\centr{$f^{\mA_H}(\lot h 1 n)=f(\lot h 1 n)\in H_S$.}\\


Все данные модели будем называть $H$-интерпретациями. Обратим внимание на то, что значения истинности предикатов перманентно здесь не задаются, т.е. предикаты мы можем задавать любым образом. Как именно? Через эрбранов базис. Отсюда у нас получается много различных $H$-интерпретаций с разными истинностями, хотя у них те же самые функции и константы.\\

\primer

Пусть $S=\{\underset{\vp_1(x1,x2)}{\underbrace{P(x_1,x_2)\vee Q(f(x_1))}},\underset{\vp_2(x1,x2,x3)}{\underbrace{\lnot Q(x_2)\vee R(x_1,x_3)}} \}$.

Тогда $\sg(S)=\{P^{(2)},Q^{(1)},R^{(2)},f^{(1)}\}$ и $\sg_S=\{c,P^{(2)},Q^{(1)},R^{(2)},f^{(1)}\}$.

Из $\sg_S$ нам нужны все замкнутые термы для $H_S$. 

Тогда $H_S$ примет вид $H_S=\{c,f(c),f(f(c)),\dots\}$, т.е. будет бесконечным множеством. Если бы функции $f^{(1)}$ не было, то у нас была бы одна константа в универсуме(только в том случае, если $f(x)\neq x$ !).

Эрбранов базис выглядит тогда так $A_S=\{P(c,c),P(c,f(c)),P(f(c),c),\dots\newline\dots,Q(c),Q(f(c)),\dots,R(c,c),\dots\}$, т.е. мы перебираем все возможные наборы аргументов для всех предикатов в $\sg_S$.

Основным примером для дизъюнкта $P(x_1,x_2)\vee Q(f(x_1))$ будет 
\newline$P(c,f(c))\vee Q(f(c))$. Т.е. у нас основных примеров достаточно много. 

Все зависит от наличия функции в $S$. Если её нет, то эрбранов универсум состоит из одной константы, а $A_S$ конечен.

И теперь о $H$-интерпретации. Мы строим модель, основным множеством которого будет $H_S$ и $\sg_S$. Затем задаём истинность предикатов, строя $A_S$ удобным нам образом.

Так строятся эти модели.\\

\opr 

Пусть $S$ - множество дизъюнктов, $\mA\in K(\sg(S))$. Говорят, что \textbf{$\mA_H$ соответствует $\mA$}, если $\forall P\in\sg(S)\;\forall\lot h 1 n\in H_S$ выполняется:
\\\centr{$\mA'\vD P(\lot {h^{\mA'}} 1 n)\Leftrightarrow\mA_H\vD P(\lot h 1 n)$,}

где $\mA'=\mA\downharpoonright\sg_S$.\\

\zam 

Модели $\mA$ может соответсвовать \underline{более одной} $\mA_H$.\\

\lemma 

Пусть $S$ - множество дизъюнктов, $\mA\in K(\sg(S)),$ некоторая $\mA_H$ соответствует $\mA$. Тогда $S$ выполнима на  $\mA\Leftrightarrow S$ выполнима на $\mA_H$.

\dok

$\rightdok$ Пусть $\mA\vD S$ и $\mA_H\nvDash S\Leftrightarrow\exists\vp\in S\;\exists\lot h 1 n\in H_S\!:\newline:\mA_H\nvDash\vp(\lot h 1 n)$.

Т.к. $\vp(\ovl h)=P_1(\ovl h)\vee\dots\vee P_k(\ovl h)\vee\lnot P_{k+1}(\ovl h)\vee\dots\vee\lnot P_{k+l}(\ovl h)\Leftrightarrow$

$\left.
  \begin{array}{ccc}
    \forall i\in\{1,k\}\!: & & \mA_H\nvDash P_i(\ovl h)\Leftrightarrow\mA'\nvDash P_i(\ovl h)\\

    \text{и} & &\\

    \forall j\in\{k+1,k+l\}\!: & & \mA_H\vD P_j(\ovl h)\Leftrightarrow\mA'\vD P_j(\ovl h)
  \end{array}
  \right\}\Rightarrow\newline\Rightarrow\exists a\in|\mA|\!\!:\mA\nvDash[P_i(\ovl h)]^{c\in\sg_S\backslash\sg(S)}_a$ и $\mA\vD[P_j(\ovl h)]^{c\in\sg_S\backslash\sg(S)}_a\Rightarrow \mA\nvDash S$. Пришли к противоречию.

$\leftdok$ Пусть $\mA_H\vD S$ и $\mA\nvDash S\Leftrightarrow\forall\vp\in S\;\forall\lot h 1 n\in H_S\!:\newline:\mA_H\vD\vp(\lot h 1 n)$.

Т.к. $\vp(\ovl h)=P_1(\ovl h)\vee\dots\vee P_k(\ovl h)\vee\lnot P_{k+1}(\ovl h)\vee\dots\vee\lnot P_{k+l}(\ovl h)\Leftrightarrow$

$\left.
  \begin{array}{ccc}
    \exists i\in\{1,k\}\!: & & \mA_H\vD P_i(\ovl h)\Leftrightarrow\mA'\vD P_i(\ovl h)\\

    \text{или} & &\\

    \exists j\in\{k+1,k+l\}\!: & & \mA_H\nvDash P_j(\ovl h)\Leftrightarrow\mA'\nvDash P_j(\ovl h)
  \end{array}
  \right\}\Rightarrow\newline\Rightarrow\exists a\in|\mA|\!:\mA\vD [P_i(\ovl h)]^{c\in\sg_S\backslash\sg(S)}_a$ или $\mA\nvDash[P_j(\ovl h)]^{c\in\sg_S\backslash\sg(S)}_a\Rightarrow S$ выполнима на $\mA$. Пришли к противоречию. 

Лемма доказана. (Подлежит редактированию)\\

\teor 

$S$ - т.л. $\Leftrightarrow S$ - ложно на всех $\mA_H$.

\dok\\
$\rightdok$ Если $S$ т.л., то оно ложно на всех моделях.\\
$\leftdok$ Пусть $S$ - ложно на всех $\mA_H,\;S$ выполнима $\Rightarrow$ по лемме 24.5.\\ $\exists\mA\in K(\sg(S))\!:\mA\vD S\Rightarrow\exists\mA_H\!\!:\mA_H\vD S$. Пришли к противоречию.

Теорема доказана.\\

Таким образом мы можем доказывать т.л. $S$, не рассматривая истинность на абсолютно всех моделях, \underline{а только на $H$-интерпретациях}. Хотя мы и фиксируем универсум, у нас моделей все так же много, а в некоторых случаях их количество равно континууму. Но тем не менее, в следующих рассуждениях мы будем пользоваться преимущественно только $H$-интерпретациями.

\newpage

\msubsection{Семантические деревья}

\opr 

Пусть $\vp$ - предложение. Тогда \textbf{контрарной парой} называют пару $\{\vp,\lnot\vp\}$.\\

\opr 

\textbf{Семантическим деревом $D(S)$}, построенным над $S$, будем называть бинарным деревом, в котором каждому ребру приписывается $\vp\in A_S$, либо его отрицание следующим образом:

1) Ребрам, выходящим из одной вершины, приписываются элементы контра-\;-рной пары;

2) Для каждой вершины $N$ строится множество атомарных предложений $I(N)$, приписанных всем рёбрам ветвей, соединяющих $N$ с корнем дерева.  

Тогда в $I(N)$ \underline{не должны содержаться контрарные пары} и все элементы в ветви перечисляются только один раз.\\

\primer

1) Пусть $S=\{P(x)\vee Q(x), R(x)\}$. Тогда:

$\sg(S)=\{P^{(1)},Q^{(1)},R^{(1)}\},\;\sg_S=\{c,P^{(1)},Q^{(1)},R^{(1)}\}$;

$H_S=\{c\}$;

$A_S=\{P(c),Q(c),R(c)\}$.

Тогда $D(S)$ будет выглядеть так(один из возможных видов): 

\begin{center}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

%left
\draw[color=black, very thick](2, -1) -- (1, -2);
\draw[color=black, very thick](2, -1) -- (2.5, -2);

\draw[color=black, very thick](1, -2) -- (0, -3);
\draw[color=black, very thick](1, -2) -- (1.5, -3);

\draw[color=black, very thick](2.5, -2) -- (2.3, -3);
\draw[color=black, very thick](2.5, -2) -- (2.7, -3);
%left

%right
\draw[color=black, very thick](4, -1) -- (3.5, -2);
\draw[color=black, very thick](4, -1) -- (5, -2);

\draw[color=black, very thick](3.5, -2) -- (3.7, -3);
\draw[color=black, very thick](3.5, -2) -- (3.3, -3);

\draw[color=black, very thick](5, -2) -- (6, -3);
\draw[color=black, very thick](5, -2) -- (4.5, -3);
%right


\node[scale=0.8] at (1.9,-0.25) {$P(c)$};
\node[scale=0.8] at (4.1,-0.25) {$\lnot P(c)$};

\node[scale=0.6] at (2.6,-1.4) {$Q(c)$};
\node[scale=0.6] at (0.9,-1.4) {$\lnot Q(c)$};

\node[scale=0.6] at (3.4,-1.4) {$Q(c)$};
\node[scale=0.6] at (4.9,-1.4) {$\lnot Q(c)$};
\node[scale=0.6] at (9.5,-1.4) {$\text{(мы можем приписывать элементы из контрарной}$};
\node[scale=0.6] at (9.1,-1.9) {$\text{пары в таком порядке, каком мы захотим)}$};

\node[scale=0.6] at (1.69,-2.4) {$\lnot R(c)$};
\node[scale=0.6] at (0.1,-2.4) {$R(c)$};

\node[] at (4.5,-3.2) {$\dots\dots\dots$};

\node[] at (-0.1,-3.3) {$N$};

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](2.5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3.5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](0, -3) circle (0.05);
\draw[fill=black, color=black, very thick](1.5, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2.3, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2.7, -3) circle (0.05);
\draw[fill=black, color=black, very thick](3.7, -3) circle (0.05);
\draw[fill=black, color=black, very thick](3.3, -3) circle (0.05);
\draw[fill=black, color=black, very thick](6, -3) circle (0.05);
\draw[fill=black, color=black, very thick](4.5, -3) circle (0.05);

\end{tikzpicture}
\end{center}

Здесь $I(N)=\{R(c),\lnot Q(c),P(c)\}$.

2) Пусть $S=\{P(x),Q(f(x))\}$. Тогда:

$\sg_S=\{c,P,Q,f\}$;

$H_S=\{c,f(c),f(f(c)),f(f(f(c))),\dots\}$;

$A_S=\{P(c),Q(c),P(f(c)),Q(f((c)),\dots\}$;

$D(S)\!:$

\begin{center}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

%left
\draw[color=black, very thick](2, -1) -- (1, -2);
\draw[color=black, very thick](2, -1) -- (2.5, -2);

\draw[color=black, very thick](1, -2) -- (0, -3);
\draw[color=black, very thick](1, -2) -- (1.5, -3);

\draw[color=black, very thick](2.5, -2) -- (2.3, -3);
\draw[color=black, very thick](2.5, -2) -- (2.7, -3);
%left

%right
\draw[color=black, very thick](4, -1) -- (3.5, -2);
\draw[color=black, very thick](4, -1) -- (5, -2);

\draw[color=black, very thick](3.5, -2) -- (3.7, -3);
\draw[color=black, very thick](3.5, -2) -- (3.3, -3);

\draw[color=black, very thick](5, -2) -- (6, -3);
\draw[color=black, very thick](5, -2) -- (4.5, -3);
%right


\node[scale=0.8] at (1.9,-0.25) {$P(c)$};
\node[scale=0.8] at (4.1,-0.25) {$\lnot P(c)$};

\node[scale=0.6] at (2.6,-1.4) {$Q(c)$};
\node[scale=0.6] at (0.9,-1.4) {$\lnot Q(c)$};

\node[scale=0.6] at (3.4,-1.4) {$Q(c)$};
\node[scale=0.6] at (4.9,-1.4) {$\lnot Q(c)$};

\node[scale=0.45] at (1.78,-2.4) {$\lnot P(f(c))$};
\node[scale=0.6] at (-0.15,-2.4) {$P(f(c))$};

\node[] at (3,-3.2) {$\dots\dots\dots\dots\dots\dots\dots\dots$};

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](2.5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3.5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](0, -3) circle (0.05);
\draw[fill=black, color=black, very thick](1.5, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2.3, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2.7, -3) circle (0.05);
\draw[fill=black, color=black, very thick](3.7, -3) circle (0.05);
\draw[fill=black, color=black, very thick](3.3, -3) circle (0.05);
\draw[fill=black, color=black, very thick](6, -3) circle (0.05);
\draw[fill=black, color=black, very thick](4.5, -3) circle (0.05);

\end{tikzpicture}
\end{center}

Данное дерево будет бесконечным из-за наличия в $S$ функции в дизъюнкте. 

Напоминает ли ветвь из бесконечного дерева что нибудь нам? Если мы рассмотрим какую нибудь $H$-интерпретацию и построим её элементарную диаграмму, то можем заметить, что каждая ветвь у дерева как раз задает ту саммую диаграмму для модели, т.е. каждая бесконечная ветка \underline{интерпретирует} \underline{какую-то одну $H$-интерпретацию}. 

Таким образом, у нас может быть континуум $H$-интерпретаций, которые полностью легли в одно семантическое дерево.\\

\opr 

Будем говорить, что вершина $N$ \textbf{ставится в соответствие} некоторой
\\$\mA_H\!:\mA_H\!\vD\! I(N)$, т.е. одной вершине соответствует сразу несколько\\$H$-интерпретаций.

Классом моделей, соответствующих $N$, является 

\begin{center}
    $\mA_{I(N)}=\{\mA_H\;|\;\mA_H\vD I(N)\}$.\\
\end{center}

\newpage

\opr 

1) Пусть $D(S)$ - конечное. Тогда $D(S)$ является \textbf{полным}, если для любой тупиковой вершины $N$ выполняется $I(N)=\{\vp\in A_S\text{ или }\lnot\vp\in A_S\}$;

2) Пусть $D(S)$ - бесконечное. Тогда $D(S)$ является \textbf{полным}, если каждая его бесконечная ветка содержит все элементы Эрбрановского базиса, взятые с отрицанием или без.\\

\opr 

Пусть $D(S)$ - семанитическое дерево. Говорят, что вершина $N$ называется \textbf{опровергающей вершиной}, \\
если $\exists\vp(\ovl x)\in S\;\exists\lot h 1 n\in H_S\;\forall\mA_H\in\mA_{I(N)}\!:\mA_H\nvDash\vp(\ovl h)$.

Конечное поддерево полного семантического дерева называется \textbf{замкнутым}, если каждая его ветвь оканчивается опровергающей вершиной.\\

\primer

1) Пусть $S=\{P(x),Q(x)\vee R(x),\lnot P(x)\vee\lnot Q(x),\lnot P(x)\vee\lnot R(x)\}$. Тогда $D(S)\!:$

\begin{wrapfigure}{l}{0.25\textwidth}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

%left
\draw[color=black, very thick](2, -1) -- (1, -2);
\draw[color=black, very thick](2, -1) -- (3, -2);

\draw[color=black, very thick](3, -2) -- (2, -3);
\draw[color=black, very thick](3, -2) -- (4, -3);
%left

\node[scale=0.8] at (1.9,-0.25) {$P(c)$};
\node[scale=0.8] at (4.1,-0.25) {$\lnot P(c)$};

\node[scale=0.6] at (3,-1.4) {$\lnot Q(c)$};
\node[scale=0.6] at (1,-1.4) {$ Q(c)$};

\node[scale=0.65] at (2.05,-2.4) {$R(c)$};
\node[scale=0.65] at (4,-2.4) {$\lnot R(c)$};

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -2) circle (0.05);
\draw[fill=black, color=black, very thick](4, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2, -3) circle (0.05);

\node[scale=1.3,rotate=30] at (4,-3) {$\times$};
\node[scale=1.3,rotate=30] at (2,-3) {$\times$};

\node[scale=1.3,rotate=30] at (4,-1) {$\times$};
\node[scale=1.3,rotate=30] at (1,-2) {$\times$};

\node[scale=0.9] at (3.9,-1.4) {$N$};
\node[scale=0.9] at (1,-2.5) {$N_1$};

\end{tikzpicture}
\end{wrapfigure}

Возьмём $\mA_H\in\mA_{I(N)}$.

$\mA_H\vD\lnot P(c)$. 

$\mA_H\nvDash P(c)$(на модели ложен дизъюнкт $P(c)\in S$) $\Rightarrow\newline\Rightarrow$ $N$ - опровергающая вершина. 

Возьмём $\mA_H'\in\mA_{I(N_1)}$.

$\mA_H'\vD P(c)$ и $\mA_H'\vD Q(c)$. 

\qquad\qquad\qquad\qquad\;\;\; но $\mA_H'\nvDash\lnot P(c)\vee\lnot Q(c)\Rightarrow N_1$ - опровергающая

\qquad\qquad\qquad\qquad\;\;\; вершина. 

Рассмотрев все вершины, мы поймём, что дерево замкнутое.\\

2) Пусть $S=\{P(x),\lnot P(x)\vee Q(f(x))\}$. Тогда $D(S)\!:$

\begin{center}
\begin{tikzpicture}

\draw[fill=black, color=black, very thick](7, 0) circle (0.05);
\draw[color=black, very thick](7, 0) -- (5, -1);
\draw[fill=black, color=black, very thick](5, -1) circle (0.05);
\draw[color=black, very thick](7, 0) -- (9, -1);
\draw[fill=black, color=black, very thick](9, -1) circle (0.05);

\node[scale=0.65] at (5.4,-0.4) {$Q(c)$};
\node[scale=0.65] at (8.5,-0.4) {$\lnot Q(c)$};

%left
\draw[color=black, very thick](5, -1) -- (4, -2);
\draw[fill=black, color=black, very thick](4, -2) circle (0.05);
\draw[color=black, very thick](5, -1) -- (6, -2);
\draw[fill=black, color=black, very thick](6, -2) circle (0.05);
\node[scale=1.3,rotate=30] at (6,-2) {$\times$};

\node[scale=0.65] at (4,-1.4) {$P(c)$};
\node[scale=0.65] at (6,-1.4) {$\lnot P(c)$};

\draw[color=black, very thick](4, -2) -- (3, -3);
\draw[fill=black, color=black, very thick](3, -3) circle (0.05);
\draw[color=black, very thick](4, -2) -- (5, -3);
\draw[fill=black, color=black, very thick](5, -3) circle (0.05);
\node[scale=1.3,rotate=30] at (5,-3) {$\times$};

\draw[color=black, very thick](3, -3) -- (2, -4);
\draw[fill=black, color=black, very thick](2, -4) circle (0.05);
\draw[color=black, very thick](3, -3) -- (4, -4);
\draw[fill=black, color=black, very thick](4, -4) circle (0.05);
\node[scale=1.3,rotate=30] at (4,-4) {$\times$};

\draw[color=black, very thick](2, -4) -- (1, -5);
\draw[fill=black, color=black, very thick](1, -5) circle (0.05);
\draw[color=black, very thick](2, -4) -- (3, -5);
\draw[fill=black, color=black, very thick](3, -5) circle (0.05);
\node[scale=1.3,rotate=30] at (3,-5) {$\times$};

\node[scale=0.8] at (1,-5.4) {$\dots\dots$};
%left

%right
\draw[color=black, very thick](9, -1) -- (8, -2);
\draw[fill=black, color=black, very thick](8, -2) circle (0.05);
\draw[color=black, very thick](9, -1) -- (10, -2);
\draw[fill=black, color=black, very thick](10, -2) circle (0.05);
\node[scale=1.3,rotate=30] at (10,-2) {$\times$};

\node[scale=0.65] at (8,-1.4) {$P(c)$};
\node[scale=0.65] at (10,-1.4) {$\lnot P(c)$};

\draw[color=black, very thick](8, -2) -- (7, -3);
\draw[fill=black, color=black, very thick](7, -3) circle (0.05);
\draw[color=black, very thick](8, -2) -- (9, -3);
\draw[fill=black, color=black, very thick](9, -3) circle (0.05);
\node[scale=1.3,rotate=30] at (9,-3) {$\times$};

\node[scale=0.58] at (6.9,-2.4) {$Q(f(c))$};
\node[scale=0.58] at (9.1,-2.4) {$\lnot Q(f(c))$};

\draw[color=black, very thick](7, -3) -- (6, -4);
\draw[fill=black, color=black, very thick](6, -4) circle (0.05);
\draw[color=black, very thick](7, -3) -- (8, -4);
\draw[fill=black, color=black, very thick](8, -4) circle (0.05);
\node[scale=1.3,rotate=30] at (8,-4) {$\times$};

\node[scale=0.58] at (5.9,-3.4) {$P(f(c))$};
\node[scale=0.58] at (8.1,-3.4) {$\lnot P(f(c))$};

\draw[color=black, very thick](6, -4) -- (5, -5);
\draw[fill=black, color=black, very thick](5, -5) circle (0.05);
\draw[color=black, very thick](6, -4) -- (7, -5);
\draw[fill=black, color=black, very thick](7, -5) circle (0.05);
\node[scale=1.3,rotate=30] at (7,-5) {$\times$};

\node[scale=0.8] at (5,-5.4) {$\dots\dots$};
%right

\node[scale=1.3,rotate=225] at (3,-6) {$\to$};
\node[scale=1.3] at (2.7,-6.6) {$\infty$};
\end{tikzpicture}
\end{center}

В конечном итоге данное дерево является незамкнутым, но стоит добавить в $S$ предикат $\lnot Q(f(x))$, то дерево замкнется. \\

Чтобы понять, для чего нужны семантические деревья, нужно ввести теорему Эрбрана.\\

\teorT{Эрбрана}

$S$ - т.л. $\Leftrightarrow\forall D(S)$ существует замкнутое поддерево.

\dok

$\rightdok$ Пусть $S$ - т.л.. Построим полное семантическое дерево $D(S)$. Рассмотрим бесконечную ветку $B$. Тогда $I(B)$ - множество атомарных предложений, лежащее на данной ветви. Т.к. $B$ бесконечная $\Rightarrow B$ не замкнутая $\Rightarrow\exists\mA_H\!\!:\mA_H\vD I(B)$. Получаем противоречие, т.к. $S$ - т.л.. 

$\leftdok$ Пусть существует замкнутое поддерево $D(S)$. Допустим, что $S$ выполнима $\Rightarrow\exists\mA_H\;\forall\vp(\ovl x)\in S\;\forall\lot h 1 n\in H_S\!\!:\mA_H\vD\vp(\ovl h)\Rightarrow$ В $D(S)$ существует бесконечная ветка $\Rightarrow$ получаем противоречие с тем, что у нас дерево замкнуто.

Теорема доказана.

Данная теорема является знаковой, т.к. она существенно упрощает задачу доказательства истинности формулы. Если мы найдём замкнутое конечное поддерево, то мы сможем обойти его за конечное число шагов и решить задачу. Но проблема все равно остается не рекурсивной, а лишь перечислимой, т.к. дерево может быть незамкнутым, а бесконечным, и мы будем по нему идти соответственно тоже бесконечно.

Но тем не менее, все алгоритмы, что ищут ответ на вопрос "т.л. формула или нет?"{}, по сути сводятся к обходу семантического дерева.

Позже на практике мы разберем, как более оптимально нам строить данные деревья, т.к. можем его начать с абсолютно любого предиката. 

Самым популярным алгоритмом для построения семантического дерева в программах поиска истинности формулы является \textit{правило резолюции}, что рассмотрим чуть позже.\\

Далее мы рассмотрим применение теоремы Эрбрана.

\msubsection{Правила Дэвиса-Патнема}

Ниже приведены правила, которые упрощают доказательство т.л. $S$:\\

\predlT{правило тавтологий} 

Пусть $S'$ получено из множества $S$ вычёркиванием всех тавтологий, т.е. вычеркиванием всех т.и. дизъюнктов.

Тогда $S$ - т.л. $\Leftrightarrow S'$ - т.л. 

\dok

Очевидно.\\

\predlT{правило однолитерных дизъюнктов}

Пусть есть однолитерный дизъюнкт $L(\lot x 1 n)\in S$.

Строим множество $S'=\{\vp\in S\;|\;L\notin\vp\}$. Тогда:

1) Если $S'=\varnothing$, то $S$ - выполнима;

2) Если $S'\neq\varnothing$, то строим $S''=\{[\vp]^{\lnot L}_\varnothing\;|\;\vp\in S'\}$. 

Тогда $S$ - т.л. $\Leftrightarrow S''$ - т.л..

\dok

Рассмотрим два случая:

$\boxed{S'=\varnothing}\Rightarrow\forall\vp\in S\!:\vp(\ovl x)=\vp'(\ovl x)\vee L(\ovl x)$.

Возьмём $\mA_H$ и для $\forall\lot h 1 n\in H_S\!:\mA_H\vD L(\lot h 1 n)\Rightarrow\newline\Rightarrow\mA_H\vD\vp\Rightarrow S$ - выполнима.

$\boxed{S'\neq\varnothing}$ Тогда строим $S''$ и доказываем от противного:

$\rightdok$ Пусть $S$ - т.л. и $S''$ - выполнимо $\Rightarrow\exists\mA_H'\in K(\sg_S\backslash\{L\})\!:\mA_H'\vD S''$. Это значит, что $\forall\vp(\ovl x)\in S''\;\forall\lot h 1 n\in H_{S''}\!:\mA_H'\vD\vp(\lot h 1 n)$.

Определим $\mA_H=\mA_H'\downharpoonright\sg_S$(доопределим $L$). Тогда полагаем, что\\ $\forall\lot h 1 s\in H_S\!:\mA_H\vD L(\lot h 1 s)$. 

Возьмём $\psi\in S$. Тогда рассмотрим следующие случаи:

1) $\psi=\psi'\vee L\Rightarrow\mA_H\vD\psi$;

2) $\psi=\psi'\vee\lnot L\Rightarrow$ т.к. $\psi'\in S''\Rightarrow\mA_H'\vD\psi'\Rightarrow\mA_H\vD\psi'\Rightarrow\mA_H\vD\psi$;

3) $L\notin\psi\Rightarrow$ т.к. $\psi\in S''$, выходит $\mA_H\vD\psi$.

В трёх случаях вышло, что $\mA_H\vD\psi\Rightarrow S$ - выполнима $\Rightarrow$ получаем противоречие с начальными условиями.

$\leftdok$ Пусть $S''$ - т.л. и $S$ - выполнима $\Rightarrow\exists\mA_H\in K(\sg_S)\!:\mA_H\vD S\Rightarrow\newline\Rightarrow\forall\lot h 1 n\in H_S\!:\mA_H\vD L(\ovl h)\Rightarrow\forall\vp\in S\!:\vp=\vp'\vee L$ и $\mA_H\vD\vp$.

Если $\vp=\vp'\vee\lnot L$ и имеем, что $\mA_H\vD\vp$ и $\mA_H\nvDash\lnot L(\ovl h)\Rightarrow\mA_H\vD\vp'\Rightarrow\newline\Rightarrow L\notin\vp\!:\mA_H\vD\vp$.%FIXME

Теперь возьмём $\mA_H''=\mA_H\upharpoonright\sg_S''$, где $\sg_S''=\sg_S\backslash\{L\}$.

Тогда $\forall\psi\in S''\!\!:\mA_H\vD\psi\Rightarrow\mA_H''\vD\psi\Rightarrow S''$ - выполнима $\Rightarrow$ получаем противоречие с начальными условиями.

Предложение доказано.\\

\primer

Пусть $S=\{P(x),P(x)\vee Q(x),\lnot P(x)\vee R(x)\}$.

Тогда 

$S'=\{\lnot P(x)\vee R(x)\}$,

$S''=\{R(x)\}$.

И мы доказываем т.л. $S''$, если $S'\neq\varnothing$. \\

\predlT{правило чистых литер}

Пусть даны $L(\ovl x)$ и множество дизъюнктов $S$. Пусть для $\forall\vp\in S\!:\lnot L\notin\vp$.

Литера $L$ - \textit{чистая}, т.е. нигде нет её отрицания.

Тогда $S$ - т.л. $\Leftrightarrow S'=\{\vp\in S\;|\;L\notin\vp\}$ - т.л..

\dok

$\rightdok$ Пусть $S$ - т.л.. Допустим, что $S'$ - выполнима $\Rightarrow\newline\Rightarrow\exists\mA_H'\in K(\sg_S\backslash\{L\})\!:\mA_H'\vD S'$.

Определим $\mA_H=\mA_H'\downharpoonright\sg_S$ такую, что $\forall\lot h 1 n\in H_S\!:\mA_H\vD L(\ovl h)$.

Тогда мы получим, что для $\forall\vp\in S\!:$

1) $\vp=\vp_1\vee L\Rightarrow\forall\lot h 1 n\in H_S\!:\mA_H\vD\vp(\ovl h)$;

2) $L\notin\vp\Rightarrow\mA_H'\vD\vp\Rightarrow\mA_H\vD\vp$.

Отсюда вышло, что $\mA_H\vD\vp\Rightarrow S$ - выполнима. Пришли к противоречию.

$\leftdok$ Пусть $S'$ - т.л. и $S$ - выполнима $\Rightarrow\exists\mA_H\in K(\sg_S)\!:\mA_H\vD S$.

Т.к. $S'\subseteq S\Rightarrow\mA_H\vD S'$. Тогда вводим $\mA_H'=\mA_H\upharpoonright\sg_S\backslash\{L\}$ такую, что $\mA_H'\vD S'\Rightarrow S'$ - выполнима. Пришли к противоречию.

Предложение доказано.

\predlT{правило расщепления}

Пусть $S=\{\vp_1\vee L,\dots,\vp_n\vee L,\psi_1\vee\lnot L,\dots,\psi_m\vee\lnot L,\lot \xi 1 k\}$, где $\vp_i,\psi_j,\xi_l$ не содержат $L$.

Пусть $S_1=\{\lot \vp 1 n,\lot \xi 1 k\}$ и $S_2=\{\lot \psi 1 m,\lot \xi 1 k\}$.

Тогда $S$ - т.л. $\Leftrightarrow S_1$ - т.л. и $S_2$ - т.л..

\dok

$\rightdok$ Пусть $S$ - т.л.. Предположим, что одно из $S_1$ и $S_2$ не является т.л..\\
Допустим, $S_1$ - выполнимо(случай для $S_2$ аналогичен, но не забываем про отрицание $L$) $\Rightarrow\exists\mA_H'\in K(\sg_S\backslash\{L\})\!:\mA_H'\vD S_1$. Расширим модель, получим \\
$\mA_H=\mA_H'\downharpoonright\sg_S$ такую, что $\forall\lot h 1 n\in H_S\!:\mA_H\vD\lnot L(\ovl h)$. Тогда получается для:

$\forall i=\ovl{1,n}\!:\mA_H'\vD\vp_i\Rightarrow\mA_H\vD\vp_i\Rightarrow\mA_H\vD\vp_i\vee L$.

$\forall j=\ovl{1,m}\!:\mA_H\vD\lnot L\Rightarrow\mA_H\vD\psi_j\vee\lnot L$.%FIXME

$\forall l=\ovl{1,k}\!:\mA_H'\vD\xi_l\Rightarrow\mA_H\vD\xi_l$.

Отсюда следует, $\mA_H\vD S\Rightarrow S$ - выполнима. Пришли к противоречию.

$\leftdok$ Пусть $S_1$ - т.л., $S_2$ - т.л. и $S$ - выполнимо.

$S$ - выполнимо $\Rightarrow\exists\mA_H\in K(\sg_S)\!:\mA_H\vD S$.

Т.к. $L$ входит в $S$, то у нас есть два случая:

\underline{Сл.1.} $\mA_H\vD L(\ovl h)$;

\underline{Сл.2.} $\mA_H\vD\lnot L(\ovl h)$.\\
Рассмотрим их подробнее.

Возьмём $\mA_H'=\mA_H\upharpoonright\sg_S\backslash\{L\}$. Тогда:

\underline{Сл.1.}

$\forall j=\ovl{1,m}\!:\mA_H\vD\psi_j\vee\lnot L$ и $\mA_H\vD L\Rightarrow\mA_H\vD\psi_j\Rightarrow\mA_H'\vD\psi_j$;

$\forall l=\ovl{1,k}\!:\mA_H\vD\xi_l\Rightarrow\mA_H'\vD\xi_l$.

Отсюда следует, что $\mA_H'\vD S_2\Rightarrow S_2$ - выполнимо. Пришли к противоречию.

\underline{Сл.2.}

$\forall i=\ovl{1,n}\!:\mA_H\vD\vp_i\vee L$ и $\mA_H\vD \lnot L\Rightarrow\mA_H\vD\vp_i\Rightarrow\mA_H'\vD\vp_i$;

$\forall l=\ovl{1,k}\!:\mA_H\vD\xi_l\Rightarrow\mA_H'\vD\xi_l$.

Отсюда следует, что $\mA_H'\vD S_1\Rightarrow S_1$ - выполнимо. Пришли к противоречию.

Предложение доказано.\\

\sled 

Если $S=\{\vp\vee L,\psi\vee\lnot L\}$, то $S$ - т.л. $\Leftrightarrow$ множество $\{\vp\vee\psi\}$ - т.л..

Это следствие и является \textbf{правилом резолюции}.

Более общее определение правила резолюции:

\begin{center}
    $\underset{\displaystyle\vp\vee\psi}{\underline{\vp\vee L,\psi\vee\lnot L}}$
\end{center}

Правилами Дэвиса-Патнема мы можем упрощать доказательство т.л. или же пробовать применять правило резолюции. Далее наша задача состоит в том, чтобы понять, что \textit{правила резолюции} нам хватит для того, чтобы доказывать т.л. формул, т.е. нам более не потребуются все правила вывода с прошлого семестра. Тогда автоматизировать доказательство становится уже более просто.

Но есть еще одна проблема.\\

\msubsection{Подстановка и унификация}

Ну и какая же проблема у нас возникает? Рассмотрим пример:

$S=\{P(x)\vee Q(x),\lnot P(f(y))\vee R(y)\},\;x,y$ - свободные переменные. 

Вроде бы есть $P$ и его отрицание, так и хочется применить \textsc{правило резолюции}, но они различаются входными термами.

Тогда пусть $[P(x)\vee Q(x)]^x_{f(a)}=P(f(a))\vee Q(f(a))$.

А в другом \;$[\lnot P(f(y))\vee R(y)]^y_a=\lnot P(f(a))\vee R(a)$.

Теперь \textit{правило резолюции} можно применить.

Но можно пойти и иным путем: 

$[P(x)\vee Q(x)]^x_{f(x)}\;\;=P(f(x))\vee Q(f(x))$ и

$[\lnot P(f(y))\vee R(y)]^y_x=\lnot P(f(x))\vee R(x)$.

Подобных примеров можно придумать много и к ним применить \textsc{правило резолюции}.

Все замены называются \textbf{подстановками}, процесс приведения к одинаковым термам называется \textbf{унификацией}.

Далее мы узнаем, как это делать, и можно ли это всё \textit{унифицировать}.\\

\opr 

Матрицу вида $\begin{pmatrix}\lot x 1 n\\ \lot t 1 n\end{pmatrix}$, где переменные $x_i\neq x_j$, а $t_i$ - терм, называется \textbf{подстановкой}. 

Если для $\forall i=\ovl{1,n}\!:t_i$ - замкнутый терм, то матрица называется \textbf{основной подстановкой}.

Обозначим (основную)подстановку $\theta,\;E$ - некоторое выражение, \\
а $[E]^\theta$ - \textbf{(основной)пример выражения $E$}.\\\\

\opr 

Пусть даны подстановки $\theta=\begin{pmatrix}\lot x 1 n\\ \lot t 1 n\end{pmatrix},\;\lambda=\begin{pmatrix}\lot y 1 m\\ \lot u 1 m\end{pmatrix}$. Тогда как построить композицию подстановок? \\
Строим матрицу $\theta\circ\lambda=\begin{pmatrix}\lot x 1 n & \lot y 1 m\\ [t_1]^\lambda\dots[t_n]^\lambda & \lot u 1 m\end{pmatrix}$, затем:\\
1) $\forall j=\ovl{1,m}\!:$ если $\exists x_i\!\!:x_i=y_j$, то мы должны вычеркнуть из матрицы $\begin{pmatrix}y_j\\u_j\end{pmatrix}$ столбец; \\
2) $\forall i=\ovl{1,n}\!:$ если $x_i=[t_i]^\lambda$, то вычеркиваем $\begin{pmatrix}x_i\\{[t_i]^\lambda}\end{pmatrix}$ столбец. 


Данные действия проделывать в строгом порядке!\\

\primer

Пусть $\theta=\begin{pmatrix}x & y\\f(y) & z\end{pmatrix},\;\lambda=\begin{pmatrix}x & y & z\\a & b & y\end{pmatrix}$ Тогда \\

$\theta\circ\lambda=\begin{pmatrix}\begin{matrix}x\\f(b)\end{matrix}\;\begin{matrix}y\\y\end{matrix}\;\begin{matrix}x\\a\end{matrix}\;\begin{matrix}y\\b\end{matrix}\;\begin{matrix}z\\y\end{matrix}\end{pmatrix}$;\\

Применяем шаг 1:

$\theta\circ\lambda=\begin{pmatrix}\begin{matrix}x\\f(b)\end{matrix}\;\bcancel{\begin{matrix}y\\y\end{matrix}}\;\begin{matrix}x\\a\end{matrix}\;\begin{matrix}y\\b\end{matrix}\;\begin{matrix}z\\y\end{matrix}\end{pmatrix}$;\\

Применяем шаг 2:

$\theta\circ\lambda=\begin{pmatrix}\begin{matrix}x\\f(b)\end{matrix}\;\bcancel{\begin{matrix}x\\a\end{matrix}}\;\begin{matrix}y\\b\end{matrix}\;\begin{matrix}z\\y\end{matrix}\end{pmatrix}$;\\

В конце получаем:

$\theta\circ\lambda=\begin{pmatrix}\begin{matrix}x\\f(b)\end{matrix}\;\begin{matrix}y\\b\end{matrix}\;\begin{matrix}z\\y\end{matrix}\end{pmatrix}$.\\

\opr 

Пусть дано множество выражений $W=\{\lot E 1 n\}$. Говорят, что подстановка $\theta$ - \textbf{унификатор} для множества $W$, \\
если $[E_1]^\theta=[E_2]^\theta=\dots=[E_n]^\theta$.\\

\primer

$\begin{matrix}P(x)\\\lnot P(f(y))\end{matrix}\to\begin{bmatrix}\theta=\begin{pmatrix}\begin{matrix}x\\f(a)\end{matrix}\;\begin{matrix}y\\a\end{matrix}\end{pmatrix}\end{bmatrix}\to\begin{matrix}P(f(a))\\\lnot P(f(a))\end{matrix}$\\

Здесь $\theta$ - унификатор.\\ 

\opr 

Унификатор $\sg$ называют \textbf{наиболее общим унификатором} для множества выражений $W=\{\lot E 1 n\}$, если для любого $\theta$ для $W$ существует подстановка $\lambda$ такая, что $\theta=\sg\circ\lambda$, т.е. стоит применить к $\sg$ какую то подстановку, то мы получаем другой унификатор.\\

Теперь введём \textit{алгоритм унификации}. Но прежде, чем его вводить, определим несколько понятий.\\

\opr 

Пусть дано множество выражений $W=\{\lot E 1 n\}$. Тогда \textbf{множество рассогласований $D$ для $W$} получается появлением первой слева позиции, на которой не для всех выражений из $W$ стоит один и тот же символ, а затем выписыванием из каждого выражения в $W$ подвыражения, которое начинается с символа, занимающего ту же позицию.\\

\primer

Пусть $W=\{P(x,f(x,y)),P(x,y),P(x,g(h(k(x))))\}$.

Тогда $D=\{f(x,y),y,g(h(k(x)))\}$, т.е. это множество, что содержит символы, с которых начались различия в выражениях из $W$. Это множество надо как раз \textit{унифицировать} и найти \textbf{НОУ}.\\

\textbf{\textsc{Алгоритм унификации:}}

На вход подается $W=\{\lot E 1 n\}$.

\textsc{\underline{Шаг 1:}} $k:=0;\;W_k=W;\;\sg_k=\varnothing$;

\textsc{\underline{Шаг 2:}} Если $||W_k||=1$, тогда $\{$

\qquad\qquad\qquad $\sg_k$ - \textbf{НОУ}; 

\qquad\qquad\qquad конец алгоритма; 

\qquad\qquad $\}$ Иначе мы строим $D_k$;

\textsc{\underline{Шаг 3:}} Если $\exists x_k\in D_k\;\exists$ терм $t_k\in D_k\!:x_k\notin t_k$, тогда $\{$

\qquad\qquad\qquad $\sg_{k+1}:=\sg_k\circ\begin{pmatrix}x_k\\t_k\end{pmatrix}$;

\qquad\qquad\qquad $W_{k+1}:=[W_k]^{x_k}_{t_k}$;

\qquad\qquad\qquad $k:=k+1$;

\qquad\qquad\qquad $goto$ \textsc{\underline{Шаг 2}};

\qquad\qquad $\}$ Иначе \textbf{НОУ} не существует и конец алгоритма;\\

\primer

Пусть $W=\{P(a,x,f(g(y))),P(z,f(z),f(u))\}$.

Запустим алгоритм:

\underline{Шаг 1.}

\underline{Шаг 2.} Строим $D_0=\{a,z\}$;

\underline{Шаг 3.}

$\sg_1=\begin{pmatrix}z\\a\end{pmatrix}$;

$W_1=\{P(a,x,f(g(y))),P(a,f(a),f(u))\}$;

\underline{Шаг 2.} $D_1=\{x,f(a)\}$;

\underline{Шаг 3.} 

$\sg_2=\begin{pmatrix}\begin{matrix}z\\a\end{matrix}\;\;\begin{matrix}x\\f(a)\end{matrix}\end{pmatrix}$;

$W_2=\{P(a,f(a),f(g(y))),P(a,f(a),f(u))\}$;

\underline{Шаг 2.} $D_2=\{g(y),u\}$;

\underline{Шаг 3.} Делаем последнюю замену и получаем $W_3$, состоящий из 1 дизъюнкта $\Rightarrow W-$унифицируем $\Rightarrow$ конец алгоритма(освободи память потом;) ).

Здесь \textbf{НОУ} будет $\sg_3=\begin{pmatrix}\begin{matrix}z\\a\end{matrix}\;\;\begin{matrix}x\\f(a)\end{matrix}\;\;\begin{matrix}u\\g(y)\end{matrix}\end{pmatrix}$.

Важно отметить, что мы можем заменить переменную на переменную, переменную на терм, но никак не имеем права \underline{менять терм на терм или} \underline{переменную}!

По соглашению, переменными в этих записях принято считать \underline{$x,y,z,u,v,w$}, а константами \underline{$a,b,c$} и все отличные от переменных буквы.\\

\msubsection{Правило резолюций}

\opr 

Пусть $\vp=L_1\vee L_2\vee\vp'$, где $L_1, L_2$ - литеры.

Тогда если существует \textbf{НОУ} $\sg$ такой, что $[L_1]^\sg=[L_2]^\sg$, то $[\vp]^\sg$ - \textbf{склейка} дизъюнкта $\vp$.\\

\primer

Пусть $\vp=P(x)\vee P(f(y))\vee Q(x,y)$.

Литеры $P(x)$ и $P(f(y))$ можно склеить.

Тогда \textbf{НОУ} $\sg=\begin{pmatrix}x\\f(y)\end{pmatrix}$ и склейкой будет $[\vp]^\sg=P(f(y))\vee Q(f(y),y)$.\\

\oprT{правило резолюций}

Пусть даны $\vp(\lot x 1 n)$ и $\psi(\lot y 1 n)$, не имеющих общих переменных, две литеры $L_1\in\vp$ и $L_2\in\psi$ и \textbf{НОУ} $\sg$ такое, что $[L_1]^\sg=[\lnot L_2]^\sg$.

Тогда \textbf{резольвентой} $Res(\vp,\psi)=[\vp']^\sg\backslash[L_1]^\sg\vee[\psi']^\sg\backslash[L_2]^\sg$, где $\vp'=\vp$ или склейка $\vp$, $\psi'=\psi$ или склейка $\psi$. Склейки образованы с помощью \textbf{НОУ} $\sg$.\\

\primer

Пусть $\vp=P(x)\vee\lnot Q(y)\vee P(f(y)),\;\psi=Q(a)\vee R(x,f(y))$.

Переименуем переменные. Возьмём, например, $\psi$, и получим 

$\psi_1=Q(a)\vee R(u,f(y))$.

Возьмём в качестве \textbf{НОУ} $\sg=\begin{pmatrix}\begin{matrix}x\\f(y)\end{matrix}\;\;\begin{matrix}y\\a\end{matrix}\end{pmatrix}$, тогда

$[\vp]^\sg=P(f(y))\vee\lnot Q(a)$,

$[\psi_1]^\sg=Q(a)\vee R(u,f(v))$.

Тогда $\res \vp {\psi_1}=P(f(y))\vee R(u,f(v))$.\\

\teorT{о логическом следствии}

Пусть для $\vp$ и $\psi$ существует $\res \vp \psi$. Говорят, что $\vp,\psi$ - выполнимы\\
на $\mA\Rightarrow\res \vp \psi$ - выполнима на $\mA$, где $\mA\in K(\sg(\{\vp,\psi\}))$.

\dok

Допустим, что $\res \vp \psi$ - не выполнима на $\mA$. Резольвента - некоторый дизъюнкт $\Rightarrow\res \vp \psi=\xi(\ovl x)$. Раз $\res \vp \psi$ не выполнима $\Rightarrow\newline\Rightarrow\forall\lot a 1 n\in|\mA|\!:\mA\nvDash\xi(\ovl a)$.

В свою очередь, $\vp=\vp'\vee L,\psi=\psi'\vee\lnot L$. Тогда $\xi=\vp'\vee\psi'$.

Получается 2 случая: $\forall\lot a 1 n\!:\mA\vD L(\ovl a)$, либо $\mA\vD\lnot L(\ovl a)\!:$

\underline{Сл.1.} $\mA\vD L(\ovl a)\Rightarrow\mA\nvDash\psi(\ovl a)$, т.к. $\mA\nvDash\vp'(\ovl a)\vee\psi'(\ovl a)\Rightarrow\mA\nvDash\vp'(\ovl a)$ \\и $\mA\nvDash\psi'(\ovl a)\Rightarrow$ получили противоречие($\psi$ выполнима).

\underline{Сл.2.} $\mA\vD\lnot L(\ovl a)\Rightarrow\mA\nvDash\vp(\ovl a)$, т.к. $\mA\nvDash\vp'(\ovl a)\vee\psi'(\ovl a)\Rightarrow\mA\nvDash\vp'(\ovl a)$ \\и $\mA\nvDash\psi'(\ovl a)\Rightarrow$ получили противоречие($\vp$ выполнима).

Из противоречий получаем, что $\res \vp \psi$ выполнима.
Теорема доказана.
\msubsection{Полнота метода резолюций}

\opr 

Пусть $S$ - множество дизъюнктов. Говорят, что последовательность \\$\lot \vp 1 n=\vp$ называется \textbf{резолютивным выводом} дизъюнкта $\vp$ из $S$, где каждая $\vp_i\in S$ или $\vp_i=\res {\vp_j} {\vp_k},\;j<i,k<i, j\neq k$.\\

\lemT{подъёма}

Пусть даны дизъюнкты $\vp,\psi$. Тогда если существуют основные примеры дизъюнктов $\vp'=[\vp]^{x_i}_{h_i\in H_S}$ и $\psi'=[\psi]^{y_j}_{p_j\in H_S}$ такие, что существует $\res {\vp'} {\psi'}$, то существует и $\res \vp \psi$.

\bezdok\\

\teorT{о полноте}

$S$ - т.л. $\Leftrightarrow\exists$ резолютивный вывод $\square$.

\dok

$\rightdok$ Т.к. $S$ - т.л. $\Rightarrow\exists$ замкнутое семантическое дерево $D(S)$. Если $D(S)$ вырождено и состоит из одной вершины, то теорема выполняется. В ином случае(если есть более одной вершины и разветвляется) рассмотрим дерево:

\begin{wrapfigure}{l}{0.25\textwidth}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

%left
\draw[color=black, very thick](2, -1) -- (1, -2);
\draw[color=black, very thick](2, -1) -- (3, -2);

\draw[color=black, very thick](3, -2) -- (2, -3);
\draw[color=black, very thick](3, -2) -- (4, -3);
%left

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -2) circle (0.05);
\draw[fill=black, color=black, very thick](4, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2, -3) circle (0.05);

\node[scale=1.3,rotate=30] at (4,-3) {$\times$};
\node[scale=1.3,rotate=30] at (2,-3) {$\times$};

\node[scale=1.3,rotate=30] at (4,-1) {$\times$};
\node[scale=1.3,rotate=30] at (1,-2) {$\times$};

\node[scale=0.9] at (5,-1.8) {$N$ - выводящая};
\node[scale=0.9] at (5.8,-2.3) {вершина};
\node[scale=0.9] at (4,-3.5) {$N_2$};
\node[scale=0.9] at (2,-3.5) {$N_1$};
\node[scale=0.7] at (3,-4) {опровергающие вершины};

\node[scale=0.8] at (2.1,-0.25) {$A_1^1$};
\node[scale=0.8] at (3.9,-0.25) {$A_1^0$};

\node[scale=0.8] at (2.8,-1.2) {$A_n^{\epsilon_n}$};

\node[scale=0.6] at (1.9,-2.4) {$A_{n+1}^1$};
\node[scale=0.6] at (3.95,-2.4) {$A_{n+1}^0$};

\end{tikzpicture}
\end{wrapfigure}
\leavevmode

\qquad У вершины $N$ есть путь $I(N)=\{A_1^{\epsilon_1},A_2^{\epsilon_2},\dots,A_n^{\epsilon_n}\}$, 

\qquad где $\epsilon_i=\{0,1\}$ и $A_i^0=\lnot A_i,\;A_i^1=A_i$.

\qquad Тогда $I(N_1)=\{A_1^{\epsilon_1},A_2^{\epsilon_2},\dots,A_n^{\epsilon_n},A_{n+1}^1\}$, 

\qquad $I(N_2)=\{A_1^{\epsilon_1},A_2^{\epsilon_2},\dots,A_n^{\epsilon_n},A_{n+1}^0\}$. \\\\
\\\\
$N_1$- опровергающий $\Rightarrow\exists\vp(\ovl x)\in S\;\exists\lot h 1 k\in H_S\!:\mA_{I(N_1)}\nvDash\vp(\lot h 1 k)$.\\
$N_2$- опровергающий $\Rightarrow\exists\psi(\ovl x)\in S\;\exists\lot p 1 k\in H_S\!:\mA_{I(N_2)}\nvDash\psi(\lot p 1 k)$.

Но на вершине $N$ выполняется $\mA_{I(N)}\vD\vp(\lot h 1 k)$ и 

$\mA_{I(N)}\vD\psi(\lot p 1 k)$. 

Стоит добавить в путь еще одно $A_n$, так дизъюнкты $\vp$ и $\psi$ опровергаются сразу. Значит они имеют вид:

1) $\vp=\vp'(\ovl h)\vee\lnot A_{n+1}$ и $\mA_{I(N)}\nvDash\vp'$;

2) $\psi=\psi'(\ovl p)\vee A_{n+1}$ и $\mA_{I(N)}\nvDash\psi'$.

Из 1) и 2) следует, что $\mA_{I(N)}\nvDash\vp'(\ovl h)\vee\psi'(\ovl p)\Rightarrow\mA_{I(N)}\nvDash\res {\vp(\ovl h)} {\psi(\ovl p)}\Rightarrow\;\Rightarrow$ по лемме 29.2. существует $\res \vp \psi$, где переменные не из $H_S$.

Тогда добавим новую резольвенту в $S$, тогда $S'=S\cup\{\res\vp\psi\}$, т.е. добавим еще один дизъюнкт. $S'$ стала больше, но в дереве вершина $N$ стала опровергающей как раз из-за того, что добавили резольвенту $\Rightarrow$ мы можем выкинуть ветви, что исходили из $N$. Далее мы берём следующие две вершины и повторяем конечное число раз этот процесс сокращения, и в конце дерево сократится до пустого дизъюнкта, т.е. для нашего случая:

\begin{center}
    $
\begin{matrix}
\begin{matrix}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

%left
\draw[color=black, very thick](2, -1) -- (1, -2);
\draw[color=black, very thick](2, -1) -- (3, -2);

\draw[color=black, very thick](3, -2) -- (2, -3);
\draw[color=black, very thick](3, -2) -- (4, -3);
%left

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -2) circle (0.05);
\draw[fill=black, color=black, very thick](4, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2, -3) circle (0.05);

\node[scale=1.3,rotate=30] at (4,-3) {$\times$};
\node[scale=1.3,rotate=30] at (2,-3) {$\times$};

\node[scale=1.3,rotate=30] at (4,-1) {$\times$};
\node[scale=1.3,rotate=30] at (1,-2) {$\times$};
\end{tikzpicture} 
\end{matrix}
\begin{matrix}\to\end{matrix}
\begin{matrix}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

%left
\draw[color=black, very thick](2, -1) -- (1, -2);
\draw[color=black, very thick](2, -1) -- (3, -2);
%left

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -2) circle (0.05);

\node[scale=1.3,rotate=30] at (4,-1) {$\times$};
\node[scale=1.3,rotate=30] at (1,-2) {$\times$};
\node[scale=1.3,rotate=30] at (3, -2) {$\times$};

\end{tikzpicture}
\end{matrix}
\begin{matrix}\to\end{matrix}
\begin{matrix}
\begin{tikzpicture}

\draw[color=black, very thick](3, 0) -- (2, -1);
\draw[color=black, very thick](3, 0) -- (4, -1);

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, -1) circle (0.05);

\node[scale=1.3,rotate=30] at (4,-1) {$\times$};
\node[scale=1.3,rotate=30] at (2, -1) {$\times$};
\end{tikzpicture}
\end{matrix}
\begin{matrix}\to\end{matrix}\;\;
\begin{matrix}\square\end{matrix}
\end{matrix}
$
\end{center}

А всё множество $S'$ как раз и является резолютивным выводом, где в итоге всё сводится к пустому дизъюнкту, что означает т.л. $S$.

$\leftdok$ Пусть $S$ - выполнимо $\Rightarrow\exists\mA\!\!:\mA\vD S$. Раз на модели выполняются все дизъюнкты из S, то по теореме 28.3. $\Rightarrow\forall\vp,\psi\in S\!\!:\mA\vD\res \vp \psi$. Но т.к. $\lot \vp 1 n=\square$ - резолютивный вывод $\Rightarrow\mA\vD\square\Rightarrow$ получаем полный бред, т.к. $\square$ не может выполняться. Теорема доказана.

Эта теорема как раз подтверждает то, что если $S$ - т.л., то с помощью только одного правила резолюции мы можем доказать это. Вопрос состоит только в том, когда процесс доказательства завершится. \\

Остаётся только вопрос стратегии доказательства.\\

\msubsection{Стратегии и виды резолюции}

В ходе доказательства у нас строится семантическое дерево и мы его обходим, выясняя, является ли оно замкнутым или нет. Если замкнуто, то рано или поздно с помощью метода резолюции мы это выясним и докажем т.л.. Но проблема заключается, вновь вспомним, в том, что дерево может быть бесконечным, и мы уйдем в бесконечный перебор. Здесь как раз встаёт вопрос, как искать нам по дереву: идти в глубину или ширину, используя одно или другое и т.п.. Поэтому нужны различные стратегии и алгоритмы.

У нас есть метод резолюции, как мы его будем программировать? На вход подаются дизъюнкты, мы же перебором ищем резольвенты. Рассмотрим самый простой вариант:\\

\bftex{Метод насыщения уровня}

На вход подаётся $S$.

В начале ставим $S_0=S$ и далее строим: 
\\\centr{$S_k=\{\res {\vp_1} {\vp_2}\;|\;\vp_1\in S_0\cup\dots\cup S_{k-1},\;\vp_2\in S_{k-1}\}$}


И так строим, пока не наткнёмся на множество, содержащее пустой дизъюнкт. 

Т.е. в начале мы выводим все возможные резольвенты в $S_0$, составляя $S_1$. Затем строим $S_2$, используя резольвенты из $S_1$ и $S_0$. И так до самого конца..\\

\primer
\begin{wrapfigure}[15]{l}{0.57\textwidth}
\scalebox{0.75}{
\begin{tabular}{|
>{\columncolor[HTML]{34CDF9}}c |c|c|}
\hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_0$} \\ \hline
(1)       & $P\vee Q$                &              \\ \hline
(2)       & $\lnot P\vee Q$          &              \\ \hline
(3)       & $P\vee\lnot Q$           &              \\ \hline
(4)       & $\lnot P\vee\lnot Q$     &              \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_1$} \\ \hline
(5)       & $Q$                      & (1)+(2)      \\ \hline
(6)       & $P$                      & (1)+(3)      \\ \hline
(7)       & $Q\vee\lnot Q$           & (1)+(4)      \\ \hline
(8)       & $P\vee\lnot P$           & (1)+(4)      \\ \hline
(9)       & $Q\vee\lnot Q$           & (2)+(3)      \\ \hline
(10)      & $P\vee\lnot P$           & (2)+(3)      \\ \hline
(11)      & $\lnot P$                & (2)+(4)      \\ \hline
(12)      & $\lnot Q$                & (3)+(4)      \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_2$} \\ \hline
(13)      & $P\vee Q$                & (1)+(7)      \\ \hline
(14)      & $P\vee Q$                & (1)+(8)      \\ \hline
(15)      & $P\vee Q$                & (1)+(9)      \\ \hline
(16)      & $P\vee Q$                & (1)+(10)     \\ \hline
(17)      & $Q$                      & (1)+(11)     \\ \hline
(18)      & $P$                      & (1)+(12)     \\ \hline
(19)      & $Q$                      & (2)+(6)      \\ \hline
\end{tabular}\qquad\begin{tabular}{ccc}
\hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(20)} & \multicolumn{1}{c|}{$\lnot P\vee Q$}      & \multicolumn{1}{c|}{(2)+(7)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(21)} & \multicolumn{1}{c|}{$\lnot P\vee Q$}      & \multicolumn{1}{c|}{(2)+(8)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(22)} & \multicolumn{1}{c|}{$\lnot P\vee Q$}      & \multicolumn{1}{c|}{(2)+(9)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(23)} & \multicolumn{1}{c|}{$\lnot P\vee Q$}      & \multicolumn{1}{c|}{(2)+(10)} \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(24)} & \multicolumn{1}{c|}{$\lnot P$}            & \multicolumn{1}{c|}{(2)+(12)} \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(25)} & \multicolumn{1}{c|}{$P$}                  & \multicolumn{1}{c|}{(3)+(5)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(26)} & \multicolumn{1}{c|}{$ P\vee\lnot Q$}      & \multicolumn{1}{c|}{(3)+(7)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(27)} & \multicolumn{1}{c|}{$ P\vee\lnot Q$}      & \multicolumn{1}{c|}{(3)+(8)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(28)} & \multicolumn{1}{c|}{$ P\vee\lnot Q$}      & \multicolumn{1}{c|}{(3)+(9)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(29)} & \multicolumn{1}{c|}{$ P\vee\lnot Q$}      & \multicolumn{1}{c|}{(3)+(10)} \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(30)} & \multicolumn{1}{c|}{$\lnot Q$}            & \multicolumn{1}{c|}{(3)+(11)} \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(31)} & \multicolumn{1}{c|}{$\lnot P$}            & \multicolumn{1}{c|}{(4)+(5)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(32)} & \multicolumn{1}{c|}{$\lnot Q$}            & \multicolumn{1}{c|}{(4)+(6)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(33)} & \multicolumn{1}{c|}{$\lnot P\vee\lnot Q$} & \multicolumn{1}{c|}{(4)+(7)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(34)} & \multicolumn{1}{c|}{$\lnot P\vee\lnot Q$} & \multicolumn{1}{c|}{(4)+(8)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(35)} & \multicolumn{1}{c|}{$\lnot P\vee\lnot Q$} & \multicolumn{1}{c|}{(4)+(9)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(36)} & \multicolumn{1}{c|}{$\lnot P\vee\lnot Q$} & \multicolumn{1}{c|}{(4)+(10)} \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(37)} & \multicolumn{1}{c|}{$Q$}                  & \multicolumn{1}{c|}{(5)+(7)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(38)} & \multicolumn{1}{c|}{$Q$}                  & \multicolumn{1}{c|}{(5)+(9)}  \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(39)} & \multicolumn{1}{c|}{$\square$}            & \multicolumn{1}{c|}{(5)+(12)} \\ \hline
\multicolumn{1}{l}{}                               & \multicolumn{1}{l}{}                      & \multicolumn{1}{l}{}          \\
\multicolumn{1}{l}{}                               & \multicolumn{1}{l}{}                      & \multicolumn{1}{l}{}         
\end{tabular}
}
\end{wrapfigure}
\;\\
Если мы бы делали это сами, то заметили пустой дизъюнкт гораздо раньше, чем машина. Не трудно догадаться, что этот метод достаточно громоздкий. Здесь достаточно простое $S$ на входе, но в итоге мы тратим очень много времени на вычисления. Что же тогда предлагается? Мы выкидываем т.и. дизъюнкты, т.е., например,\;\; $Q\vee\lnot Q$ и т.п., и потом не используем их в дальнейших вычислениях. \break
\newpage

\opr 

Дизъюнкт $\vp$ \textbf{поглощает} дизъюнкт $\psi$, если существует такая подстановка $\sg$, что $[\vp]^\sg\subseteq\psi$.\\

\primer

Пусть $\vp(x)=P(x)$ и $\psi(x)=P(a)\vee Q(x)$. 

Тогда берём $\sg=\begin{pmatrix}x\\a\end{pmatrix}$ и получаем $[\vp(x)]^\sg\subseteq\psi$, т.е. $\vp$ поглощает $\psi$.\\

\bftex{Стратегия вычеркивания}

Стратегия вычеркивания заключается в вычеркивании из множества $S_k$ дизъюнктов(из метода насыщения), которые либо являются т.и., либо поглощаются ранее выведенными дизъюнктами.

Для примера возьмём предыдущее $S$: 

\begin{wrapfigure}[9]{l}{0.315\textwidth}
\begin{tabular}{|
>{\columncolor[HTML]{34CDF9}}l |c|c|}
\hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_0$}                                                \\ \hline
(1)                                               & $P \vee Q$             & \multicolumn{1}{l|}{} \\ \hline
(2)                                               & $\lnot P \vee Q$       & \multicolumn{1}{l|}{} \\ \hline
(3)                                               & $P \vee \lnot Q$       & \multicolumn{1}{l|}{} \\ \hline
(4)                                               & $\lnot P \vee \lnot Q$ & \multicolumn{1}{l|}{} \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_1$}                                                \\ \hline
(5)                                               & $Q$                    & (1)+(2)             \\ \hline
(6)                                               & $P$                    & (1)+(3)             \\ \hline
\multicolumn{1}{|c|}{\cellcolor[HTML]{34CDF9}(7)} & $\lnot P$              & (2)+(4)             \\ \hline
(8)                                               & $\lnot Q$              & (3)+(4)             \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_2$}                                                \\ \hline
(9)                                               & $\square$              & (5)+(8)             \\ \hline
\end{tabular}
\end{wrapfigure}
\leavevmode\\
Здесь построили $S_1$ и сразу вычеркнули всё, что было т.и. или поглощалось, и более не используем в следующем шаге. После данной оптимизации на $S_2$ сразу выходит пустой дизъюнкт. Но минусом данного алгоритма будет то, что мы затрачиваем время на нахождение поглощаемых и т.и. дизъюнктов. Поэтому данная стратегия тоже не сильно пригодна.

\newpage

\bftex{Стратегия семантической резолюции}

Начнем с примера:

Пусть $S=\{\lnot P(x)\vee\lnot Q(x)\vee R(x),P(x)\vee R(x),Q(x)\vee R(x),\lnot R(x)\}$.

Применим стратегию вычеркивания:

\begin{wrapfigure}[20]{l}{0.41\textwidth}
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[HTML]{34CDF9} 
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_0$}                       \\ \hline
\cellcolor[HTML]{34CDF9}(1)  & $\lnot P \vee \lnot Q \vee R$ &            \\ \hline
\cellcolor[HTML]{34CDF9}(2)  & $ P \vee R$                   &            \\ \hline
\cellcolor[HTML]{34CDF9}(3)  & $Q \vee R$                    &            \\ \hline
\cellcolor[HTML]{34CDF9}(4)  & $\lnot R$                     &            \\ \hline
\rowcolor[HTML]{34CDF9} 
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_1$}                       \\ \hline
\cellcolor[HTML]{34CDF9}(5)  & $\lnot Q \vee R$              & (1)+(2)  \\ \hline
\cellcolor[HTML]{34CDF9}(6)  & $\lnot P \vee R$              & (1)+(3)  \\ \hline
\cellcolor[HTML]{34CDF9}(7)  & $\lnot P \vee \lnot Q$        & (1)+(4)  \\ \hline
\cellcolor[HTML]{34CDF9}(8)  & $P$                           & (2)+(4)  \\ \hline
\cellcolor[HTML]{34CDF9}(9)  & $Q$                           & (3)+(4)  \\ \hline
\rowcolor[HTML]{34CDF9} 
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_2$}                       \\ \hline
\cellcolor[HTML]{34CDF9}(10) & $R$                           & (2)+(6)  \\ \hline
\cellcolor[HTML]{34CDF9}(11) & $\lnot Q$                     & (4)+(5)  \\ \hline
\cellcolor[HTML]{34CDF9}(12) & $\lnot P$                     & (4)+(6)  \\ \hline
\multicolumn{3}{|c|}{и т.д...}                                          \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_3$}                       \\ \hline
\cellcolor[HTML]{34CDF9}(13) & $\square$                     & (4)+(10) \\ \hline
\end{tabular}
\end{wrapfigure}
\leavevmode\\
Стратегию вычеркивания тоже можно улучшить. Заметим, что пустой дизъюнкт вышел из (4) и (10), (10) из (2) и (6), т.е. здесь (5), (7), (8) и (9) были "холостыми"{} ходами. Было бы идеально, если выполнились только ходы (10) и (6) и, соответственно, (13), т.е. выполнился только кратчайший путь. 

Какая идея у семантической резолюции? Предполагается построить модель, на которой некоторые(или все) дизъюнкты из $S$ будут истинными. 

По теореме о логическом следовании если на модели выполняются дизъюнкты, то будут выполняться и их резольвенты. Если всё будет выполняться, то мы к пустому дизъюнкту никогда не придём, т.е. множество, все дизъюнкты которого выполняются на найденной модели, является выполнимым. Поэтому мы берём некоторую модель и если на ней вдруг все выполняется, то алгоритм заканчивается. Иначе же на этой модели часть дизъюнктов выполняется, а другая наоборот не выполняется.

\newpage

Возьмём, например, модель, которую описывает диаграмма:

$D(\mA_H)=\{\lnot P(a),\lnot Q(a),\lnot R(a),\lnot P(f(a)),\dots\}$.

У нас получается, что дизъюнкты $\lnot P(x)\vee\lnot Q(x)\vee R(x)$ и $\lnot R(x)$ будут выполняться на модели, а $P(x)\vee R(x)$ и $Q(x)\vee R(x)$ не будут. Тогда зачем нам использовать резольвенту (1) и (4), если она тоже выполнима? Если будем брать резольвенты выполнимых дизъюнктов, мы никогда не придём к пустому дизъюнкту. Тогда эту резольвенту сразу убираем. Идея семантической резолюции следующая:

\begin{wrapfigure}[19]{l}{0.41\textwidth}
\begin{tabular}{|c|c|c|}
\hline
\rowcolor[HTML]{34CDF9} 
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_0$}                       \\ \hline
\cellcolor[HTML]{FE0000}(1)  & $\lnot P \vee \lnot Q \vee R$ &            \\ \hline
\cellcolor[HTML]{34CDF9}(2)  & $ P \vee R$                   &            \\ \hline
\cellcolor[HTML]{34CDF9}(3)  & $Q \vee R$                    &            \\ \hline
\cellcolor[HTML]{FE0000}(4)  & $\lnot R$                     &            \\ \hline
\rowcolor[HTML]{34CDF9} 
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_1$}                       \\ \hline
\cellcolor[HTML]{FE0000}(5)  & $\lnot Q \vee R$              & (1)+(2)  \\ \hline
\cellcolor[HTML]{FE0000}(6)  & $\lnot P \vee R$              & (1)+(3)  \\ \hline
\rowcolor[HTML]{9B9B9B} 
(7)                          & $\lnot P \vee \lnot Q$        & (1)+(4)  \\ \hline
\rowcolor[HTML]{C0C0C0} 
(8)                          & $P$                           & (2)+(4)  \\ \hline
\rowcolor[HTML]{C0C0C0} 
(9)                          & $Q$                           & (3)+(4)  \\ \hline
\rowcolor[HTML]{34CDF9} 
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_2$}                       \\ \hline
\cellcolor[HTML]{34CDF9}(10) & $R$                           & (2)+(6)  \\ \hline
\rowcolor[HTML]{9B9B9B} 
(11)                         & $\lnot Q$                     & (4)+(5)  \\ \hline
\rowcolor[HTML]{9B9B9B} 
(12)                         & $\lnot P$                     & (4)+(6)  \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{9B9B9B}и т.д...}                                          \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_3$}                       \\ \hline
\cellcolor[HTML]{34CDF9}(13) & $\square$                     & (4)+(10) \\ \hline
\end{tabular}
\end{wrapfigure}
\leavevmode\\
Мы разбиваем $S$ на:\\ 
$S^f\;=\;\;\{P(x)\vee R(x),Q(x)\vee R(x)\}$;\\
$S^t=\{\lnot P(x)\vee\lnot Q(x)\vee R(x),\lnot R(x)\}$ - множества невыполнимых и выполнимых дизъюнктов соответсвенно(здесь выполнимые дизъюнкты помечены красным, а ложные синим). Затем строим резольвенты, беря по одному дизъюнкты из $S^f$ и $S^t$. Все резольвенты, что образованы \underline{только} выполнимыми дизъюнктами, мы убираем, т.е. исключаются (7), (11) и (12) из вычислений. Но у нас остались "холостые"{} (8) и (9). Что с ними делать? Берём наши предикаты $P,Q,R$ и упорядочиваем их любым способом. Упорядочим их, например, следующим образом: первый встретившийся предикат в $S^t$ будет самым старшим, и так по убыванию, т.е. $P>Q>R$. Тогда говорим, что брать резольвенту можем с тем истинным дизъюнктом, у которого есть \underline{старший предикат}. Тогда мы можем вычеркнуть операции (8) и (9), т.к. в них применялся выполнимый дизъюнкт (4), в котором не было предиката $P$, а был лишь $R$. 

Теперь мы вычеркнули все "холостые"{} операции и получили вполне хорошую оптимизацию. У нас вышла лишней операция (5), но она только одна..\\

Давайте проанализируем (5) и (6). Чтобы получить (5), мы резольвируем (1) и (2), оттуда применяем (3) и получаем (10). Чтобы получить (6), мы резольвируем (1) и (3), оттуда применяем (2) и получаем (10). Выходит, что у нас 2 одинаковые, по сути, дороги к получению (10), т.е. мы в одном случае сначала резольвируем (1) и (2), затем резольвируем с (3), а в другом случае (1) и (3), затем с (2). А что нам мешает без всяких (5) и (6) сказать, что нам хватит только (1), (2) и (3), чтобы получить (10)? То есть, если мы поймём, что нам нужны только (1), (2) и (3), то мы можем убрать (5) и (6) операции.

У нас выполняется только дизъюнкт (1), а (2) и (3) - ложные на $\mA_H$, что задали в самом начале. Введём следующее определение:\\

\opr 

Пусть даны $\mA_H$ и упорядочение предикатов $\mathbb P$. Конечное множество дизъюнктов $\{\vp_1,\lot \vp 2 q,\psi\}(q\geqslant 1)$ называется \textbf{$\mathbb P\mA_H$-клашем}, если:

1) $\mA_H\nvDash\vp_1,\dots,\mA_H\nvDash\vp_q$;

2) $\mA_H\nvDash R_{q+1}$, где:

$R_1:=\psi$ и затем $\forall i\in\{1,\dots,q\}\!\!:R_{i+1}:=\res {R_i} {\vp_i}$ при условии, что сокращается литера, содержащая наибольший предикат в $\vp_i$.

Дизъюнкты $\vp_1,\lot \vp 2 q$ называются \textbf{электронами клаша}, дизъюнкт $\psi$ - \textbf{ядро клаша}, дизъюнкт $R_{q+1}$ - \textbf{$\mathbb P\mA_H$-резольвента клаша}.

\teorT{о полноте семантической резолюции}

Если множество дизъюнктов $S$ - т.л., то для любой $\mA_H$ и любого линейного упорядочивания предикатов $\mathbb P$ множества дизъюнктов $S$ существует $\mathbb P\mA_H$-вывод пустого дизъюнкта множества $S$.\\

О чём говорит эта теорема? Мы можем выбрать любую $\mA_H$ - интерпретацию, любое упорядочивание, и если $S$ - т.л., то в рано или поздно мы выведем пустой дизъюнкт. Зависит только от того, какую модель выберем. В одном случае быстрее выведется, в другом случае чуть дольше будет, но принципиально мы всегда найдём решение.

Семантическая резолюция считается хорошей стратегией, но проблема с поиском $\mathbb P\mA_H$-клашей всё равно имеется. Здесь с данной стратегией мы в чем то выигрываем, а в чём то проигрываем.

Рассмотрим следующую стратегию:\\

\bftex{ЛОК-Резолюция}

Суть данной стратегии заключается в том, что мы индексируем не просто предикаты, что имеются в $S$, а индексируем \underline{все вхождения литер из $S$}. Если происходит склейка, получившейся после склейки литере приписывается наименьший индекс литеры, что склеивалась с другой с бОльшим индексом.\\

\opr 

Пусть $\vp=L_1(\lot x 1 n)_{i_1}\vee\dots\vee L_k(\lot x 1 n)_{i_k}\vee\vp'$. Если существует такой \textbf{НОУ}-$\lambda$ такая, что:
\\\centr{$[L_1(\lot x 1 n)_{i_1}]^\lambda=\dots=[L_k(\lot x 1 n)_{i_k}]^\lambda$,}
то дизъюнктом, образовавшегося после склейки, является \\$[L_1(\lot x 1 n)_{\mathbb K}]^\lambda\vee[\vp']^\lambda$, где $\mathbb K=min\{\lot i 1 k\}$, является \textbf{ЛОК-склейкой} дизъюнкта $\vp$.\\

Основная идея ЛОК-резолюции заключается в том, что мы резольвенту можем искать только по литерам, которые имеют \underline{наименьший индекс} в дизъюнкте, в котором они находятся.\\

\opr 

Рассмотрим дизъюнкты $\vp(\lot x 1 n)$ и $\psi(\lot x 1 n)$. Пусть литера $L_1$ имеет в $\vp$ наименьший индекс и литера $L_2$ в $\psi$ имеет наименьший индекс. Тогда если существует такой \textbf{НОУ} $\sg$, что $[L_1]^\sg=[\lnot L_2]^\sg$, то\\ \textbf{ЛОК-резольвентой} называется:
\begin{center}
    $L\res \vp \psi=[\vp']^\sg\backslash[L_1]^\sg\cup[\psi']^\sg\backslash[L_2]^\sg$, 
\end{center}
где либо $\vp'=\vp$ или лок-склейка дизъюнкта $\vp$, и $\psi'=\psi$ или лок-склейка дизъюнкта $\psi$.\\

\primer

\begin{wrapfigure}[11]{l}{0.33\textwidth}
\scalebox{0.9}{
\begin{tabular}{|
>{\columncolor[HTML]{34CDF9}}c |c|c|}
\hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_0$} \\ \hline
(1)    & $P_1 \vee Q_2$               &             \\ \hline
(2)    & $P_3 \vee \lnot Q_4$         &             \\ \hline
(3)    & $\lnot P_6 \vee Q_5$         &             \\ \hline
(4)    & $\lnot P_8 \vee \lnot Q_7$   &             \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_1$} \\ \hline
(5)    & $\lnot P_6$                  & (3)+(4)   \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_2$} \\ \hline
(6)    & $Q_2$                        & (1)+(5)   \\ \hline
(7)    & $\lnot Q_4$                  & (2)+(5)   \\ \hline
\multicolumn{3}{|c|}{\cellcolor[HTML]{34CDF9}$S_3$} \\ \hline
(8)    & $\square$                    & (6)+(7)   \\ \hline
\end{tabular}
}
\end{wrapfigure}
\leavevmode\\
Возьмём те же самые 4 дизъюнкта. Мы их проиндексируем. Здесь они хитро проиндексированы, т.е. нужно тоже рассматривать отдельные стратегии индексации, т.к. от этого тоже зависит время, затраченное на доказательство. Смотрим, (1) и (2) резольвировать не можем, т.к. у $Q$ наибольший индекс. Могут резольвироваться только (3) и (4). Далее резольвируем (1) и (5), (2) и (5), затем (6) и (7) и получаем пустой дизъюнкт. Здесь ЛОК-резолюция показала себя с лучшей стороны. Так же доказывается теорема о полноте ЛОК-резолюции, т.е. данный метод тоже не с потолка взят. А то, как накладывать индексы на литеры - это чуть ли не целая наука.

ЛОК-резолюция очень хорошо срабатывает, если мы хорошо расстанавливаем индексы. Это одновременно плюс и минус данной стратегии. Программирование ЛОК-резолюции достаточно трудное, поэтому более интересной с точки зрения алгоритмов программирования является линейная резолюция.\\

\bftex{Линейная резолюция}

Суть стратегии заключается в том, что мы объявляем некоторый \textit{входной дизъюнкт} и к нему как бы "по линии"{} прибавляем другие дизъюнкты, с которыми можно вывести резольвенту. Затем к резольвенте ищем другой дизъюнкт и так идём до самого пустого дизъюнкта.\\

\opr 

Пусть дано множество дизъюнктов $S$ с выделенным дизъюнктом $\vp_0\in S$. Последовательность дизъюнктов $\lot \vp 1 n$ называется \textbf{линейным выводом} дизъюнкта $\vp_n$ из множества $S$ с верхним дизъюнктом $\vp_0\in S$, если для $\forall i\in\{0,\dots,n-1\}$ имеем:
\\\centr{$\vp_{i+1}=\res {\vp_i}{\psi_i}$,}

где либо $\psi_i\in S$, либо $\psi_i=\vp_j$ для некоторого $j<i$.

Дизъюнкт $\vp_0$ будем называть \textbf{верхним дизъюнктом}, дизъюнкты\\$\lot \vp 1 n$ будем называть \textbf{центральными дизъюнктами}, а дизъюнкты $\lot \psi 1 n$ - \textbf{боковыми дизъюнктами}.\\

\newpage
\primer

Пусть $S=\{P(x)\vee Q(x),\lnot P(x)\vee Q(x),P(x)\vee\lnot Q(x),\lnot P(x)\vee\lnot Q(x)\}$.\\

Тогда линейная резолюция строится следующим образом:

\begin{center}
\scalebox{1.5}{
\begin{tikzpicture}

\draw[color=black, very thick](0, 0) -- (0, -4);
\draw[color=black, very thick](0, -4) -- (1, -3);
\draw[color=black, very thick](0, -3) -- (1, -2);
\draw[color=black, very thick](0, -2) -- (1, -1);
\draw[color=black, very thick](0, -1) -- (1, 0);

\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](0, -3) circle (0.05);
\draw[fill=black, color=black, very thick](0, -4) circle (0.05);
\draw[fill=black, color=black, very thick](1, -3) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, 0) circle (0.05);

\node[scale=0.9] at (-1,0) {$P\vee Q$};
\node[scale=0.9] at (-0.5,-1) {$Q$};
\node[scale=0.9] at (-0.5,-2) {$P$};
\node[scale=0.9] at (-0.65,-3) {$\lnot Q$};
\node[scale=0.9] at (-0.5,-4) {$\square$};

\node[scale=0.9] at (1.4,-3) {$Q$};
\node[scale=0.9] at (2.2,-2) {$\lnot P\vee\lnot Q$};
\node[scale=0.9] at (2.35,-1) {$P\vee\lnot Q$};
\node[scale=0.9] at (2.05,-0) {$\lnot P\vee Q$};

\end{tikzpicture}
}
\end{center}

Здесь верхним дизъюнктом мы объявили $P\vee Q$ и далее ищем для него дизъюнкты, чтобы получить резольвенту. Затем к полученной резольвенте подбираем другой дизъюнкт и так до самого конца. Стоит обратить внимание, что мы на N-м шаге уже подбираем не только дизъюнкты из $S$ для резольвирования, но и \underline{ранее образовавшиеся резольвенты}.\\

\teorT{о полноте линейной резолюции} 

Если множество дизъюнктов $S$ противоречиво, то \textit{существует} линейный вывод пустого дизъюнкта из множества $S$.\\

Проблема данной стратегии заключается в том, какой дизъюнкт взять верхним. При удачном выборе мы достаточно быстро приходим к нашему ответу. В противном случае, если нам сильно не повезёт при выборе, то мы вовсе можем не получить пустой дизъюнт. Фишка теоремы о полноте линейной резолюции заключается в том, что такая ветвь существует, но \underline{не для всех возможных верхних вершин}. В теоремах о полноте предыдущих стратегий говорилось, что для любого чего-то существует вывод. Но данная стратегия немного отличается от предыдущих.\\

На сегодняшний день существует около 50-60 различных стратегий и все они, как правило, комбинируются в современных \textit{резолверах}, но ЛОК-резолю-\;ция, семантическая резолюция и линейная резолюция являются являются "столпами"{} всех этих стратегий, и все трое были придуманы достаточно давно и на их основе строятся новые стратегии. Сейчас обычно комбинация стратегий при доказательстве зависит от самих входных данных, т.е. проверяют всякие вхождения литер и т.д.. Но всё равно все стратегии сводятся к различным методам обхода семантических деревьев. 

Вся загвоздка логического программирования как раз и заключается в том, что все эти обходы неоптимальные и достатоно тяжёлые в разных случаях. Говорят, что язык Prolog сейчас зашёл в тупик как раз из-за того, что все эти стратегии и алгоритмы всё равно являются несовершенными.\\

\msubsection{Язык программирования Prolog}

\opr 

Пусть дан дизъюнкт $\vp=\lnot A_1(\ovl x)\vee\dots\vee\lnot A_n(\ovl x)\vee B_1(\ovl x)\vee\dots\vee B_m(\ovl x)$. 

Тогда:

1) Если $n=0,m=1$, то $\vp$ называется \textbf{фактом};

2) Если $n\neq0,m=1$, то $\vp$ называется \textbf{правилом}.\\

\newpage

Рассмотрим подробней правило:

Пусть правило $\vp=\lnot A_1(\ovl x)\vee\dots\vee\lnot A_n(\ovl x)\vee B(\ovl x)$.

Мы можем вынести отрицание у $A_i(\ovl x)$ наружу, получим:

$\vp=\lnot(A_1(\ovl x)\ampersand\dots\ampersand A_n(\ovl x))\vee B(\ovl x)$.

Заменим на импликацию:

$\vp=(A_1(\ovl x)\ampersand\dots\ampersand A_n(\ovl x))\to B(\ovl x)$.

На языке Prolog данная импликация запишется так:

\begin{lstlisting}[language=Prolog,mathescape,numberstyle=\color{codegray}]
$B(\ovl x)\toPr \lot A 1 n$. /*это правило*/
$B(\ovl x)$. /*это факт*/
\end{lstlisting}\leavevmode

\opr

\textbf{Логической программой} называют конечный набор фактов и правил.\\

\opr

Пусть есть логическая программа $\rho=\{\lot C 1 n\}$, 

Тогда множество положительных литер $G_1(\ovl x),\dots,G_k(\ovl x)$ называется\\ \textbf{запросом к логической программе $\rho$}.

Конъюнкция тех литер $G(\ovl x)=G_1(\ovl x)\ampersand\dots\ampersand G_k(\ovl x)$ называется \textbf{целью}, где $G_i(\ovl x)$ - \textbf{подцель}.\\

Что значит здесь "ответить на запрос"{}?

Чтобы ответить на вопрос, мы должны выяснить, выполняется ли\\ $\rho\vD\exists\ovl x\;G(\ovl x)$. Ответом на запрос будет "выполняется ли это условие?"{}:

1) Если это условие истинно, то надо найти такую подстановку $\theta=\begin{pmatrix}\ovl x\\\ovl t\end{pmatrix}$, чтобы выполнялось $\rho\vD[G(\ovl x)]^\theta$. Тогда ответом на запрос будет "да"{};

2) Если выясняется, что условие ложно, то получаем ответ "нет"{}.

Теперь осталось понять, как ищется ответ на данный вопрос. Это выполняется как раз с помощью резолюции.

Что значит запись $\rho\vD\exists\ovl x\;G(\ovl x)$? 

Распишем подробнее:

$\{\lot C 1 n\}\vD\;\exists\ovl x\;(G_1(\ovl x)\ampersand\dots\ampersand G_k(\ovl x))\Rightarrow\newline\Rightarrow(C_1\ampersand\dots\ampersand C_n)\to\exists\ovl x\;(G_1(\ovl x)\ampersand\dots\ampersand G_k(\ovl x))$.

Если утверждение $\rho\vD\exists\ovl x\;G(\ovl x)$ верно, то формула выше является т.и.. Тогда её отрицание является т.л., т.е.

$\!\!\!\lnot((C_1\ampersand\dots\ampersand C_n)\to\exists\ovl x\;(G_1(\ovl x)\ampersand\dots\ampersand G_k(\ovl x)))\sim\newline\sim\;\;\;\;C_1\ampersand\dots\ampersand C_n\ampersand\forall\ovl x\;(\lnot G_1(\ovl x)\vee\dots\vee\lnot G_k(\ovl x))$.

Проверяем т.л. формулы путём проведения \textbf{скулемизации}(приведению к $\vp_{sko}$) и построения множества дизъюнктов 

$S=\{C_1',\dots, C_n',\;\lnot G_1(\ovl x)\vee\dots\vee \lnot G_k(\ovl x)\}$, где $C_i'=C_i$ с переименованным переменными, т.к. мы выносили $\forall\ovl x$ наружу и надо было избежать коллизий имён.

Если $S$ - т.л., то утверждение верное и мы получаем на выходе программы "да"{}. В ходе доказательства в классическом Prolog используется стратегия \underline{линейной резолюции}.\\

\primerT 1(на псевдокоде)
\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
Блок фактов:
Мама("Наташа","Даша"). /*здесь говорится о том, что Наташа - мама Даши*/
Мама("Даша","Маша").

Блок запросов:
Мама("Наташа", "Даша"). - "да" /*здесь мы спросили, является ли Наташа мамой Даши?*/
Мама("Наташа", "Маша"). - "нет"
Мама(x, "Даша"). - "Наташа" /*здесь мы выясняем, кто является мамой Даши*/
Мама("Наташа", y). - "Даша" /*и наоборот*/
Мама(x, y). - "Наташа - мама Даши и Даша - мама Маши" /*делаем перебор фактов*/
Мама(x, _). - "Наташа, Даша" /*выясняем, кто является мамой*/
Мама(_, y). - "Даша, Маша" /*и наоборот*/
\end{lstlisting}\leavevmode\\
Код на Prolog для примера 1:\\
\href{https://rextester.com/l/prolog}{\underline{Можете проверить работу программы здесь:)}}
\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
mother('Natalya', 'Darya').
mother('Darya', 'Maria').

?-mother('Natalya', 'Darya'),write("1st goal is true"),nl.
?-mother('Darya', 'Natalya'),write("2st goal is true"),nl.
?-mother(X, 'Darya'),write(X),nl,fail.
?-mother('Darya', Y),write(Y),nl,fail.
?-mother(X, Y),write(X),write(" is the mother "), write(Y),nl,fail.
?-mother(X, _),write(X),nl,fail.
?-mother(_, Y),write(Y),nl,fail.
\end{lstlisting}\leavevmode\\
\primerT 2\\
Давайте немного усложним программу:

Введем новое правило. Давайте для фактов из 1го примера обозначим бабушку, тогда правило будет выглядеть так:
\begin{center}
    Баб(x,y) $\toPr$ Мама(x,z),Мама(z,y).
\end{center}

И теперь мы можем спрашивать, кто является бабушкой из приведенных людей, а так же, кто является внучкой.\\

Давайте сделаем запрос:
\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
?-bab('Natalya', X),write('granddaughter is '),write(X),nl,fail.
\end{lstlisting}\leavevmode\\
Что же выполняется под капотом? Здесь верхним дизъюнктом Prolog берёт $\lnot\text{Баб}(H,x)$ и далее выполняет:

Для краткой записи обозначим: Н - Наташа, Д - Даша, М - Маша и\\М($x,y$) - Мама($x,y$). 

Тогда дерево будет выглядеть так:

\begin{flushleft}
\scalebox{1.5}{
\begin{tikzpicture}

\draw[color=black, very thick](0, 0) -- (0, -3);
\draw[color=black, very thick](0, -3) -- (1, -2);
\draw[color=black, very thick](0, -2) -- (1, -1);
\draw[color=black, very thick](0, -1) -- (1, 0);

\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](0, -3) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, 0) circle (0.05);

\node[scale=0.65] at (-1.2,0) {$\lnot\text{Баб}(H,x)$};
\node[scale=0.65] at (4.2, 0) {$[\text{Баб}(x,y)\vee\lnot M(x,z)\vee\lnot M(z,y)]^{\sg_1}$};
\node[scale=0.65] at (-2.3,-1) {$[\lnot M(H,z)\vee\lnot M(z,x)]^{\sg_2}$};
\node[scale=0.65] at (3.6,-1) {$M(H,\textbf{Д})$(взяли из фактов)};
\node[scale=0.65] at (-1.3,-2) {$[\lnot M(\text{Д},x)]^{\sg_3}$};
\node[scale=0.65] at (2,-2) {$M(\text{Д}, M)$};
\node[scale=0.65] at (-0.4,-3) {$\square$};

\end{tikzpicture}
}
\end{flushleft}
где:

$\sg_1=\begin{pmatrix}x\;y\\H\;x\end{pmatrix},\;\sg_2=\begin{pmatrix}z\\\text{Д}\end{pmatrix},\;\sg_3=\begin{pmatrix}x\\M\end{pmatrix}$.

Как мы увидели, ответ существует, т.к. мы пришли к пустому дизъюнкту. Ответом на наш вопрос будет следующим:

Мы хотели узнать $x$, так смотрим его замены $x\!\!:x\to\text{Маша}$(см. подстановки). Выходит, ответом на запрос будет ($x=$"Маша"{}).\\

Но стоит переписать правило бабушки подобным образом: 
\begin{center}
    Баб(x,y) $\toPr$ Мама(z,y),Мама(x,z).
\end{center}

Дизъюнкт в $S$ в итоге остаётся тем же самым, но когда исполняется программа, то расчёты изменятся(из-за алгоритма поиска \textbf{НОУ}):
\begin{flushleft}
\scalebox{1.5}{
\begin{tikzpicture}

\draw[color=black, very thick](0, 0) -- (0, -2);
\draw[color=black, very thick](0, -2) -- (1, -1);
\draw[color=black, very thick](0, -1) -- (1, 0);

\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, 0) circle (0.05);

\node[scale=0.65] at (-1.2,0) {$\lnot\text{Баб}(H,x)$};
\node[scale=0.65] at (4.2, 0) {$[\text{Баб}(x,y)\vee\lnot M(z,y)\vee\lnot M(x,z)]^{\sg_1}$};
\node[scale=0.65] at (-2.3,-1) {$[\lnot M(z,x)\vee\lnot M(H,z)]^{\sg_2}$};
\node[scale=0.65] at (2,-1) {$M(H,\textbf{Д})$};
\node[scale=0.65] at (-1,-2) {$\lnot M(H,H)$};
\node[scale=0.65] at (0.1,-2.5) {тупик...};
\end{tikzpicture}
}
\end{flushleft} \leavevmode
где:

$\sg_1=\begin{pmatrix}x\;y\\H\;x\end{pmatrix},\;\sg_2=\begin{pmatrix}z\;\;x\\H\;\text{Д}\end{pmatrix}$.

Тупиковый вывод произошёл из-за такой подстановки - это проблема алгоритма \textbf{НОУ}. В этом случае Prolog делает \underline{откат доказательства на шаг назад} и ищет уже другие варианты боковых дизъюнктов, чтобы избежать тупикового вывода, т.е.:

\begin{center}
\scalebox{1.5}
{
$
\begin{matrix}
\begin{matrix}
\begin{tikzpicture}
\draw[color=black, very thick](0, 0) -- (0, -1);
\draw[color=black, very thick](0, -1) -- (1, 0);

\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, 0) circle (0.05);

\node[scale=0.45] at (-1.6,0) {$[\lnot M(z,x)\vee\lnot M(H,z)]^{\sg_2}$};
\node[scale=0.65] at (2,0) {$M(H,\textbf{Д})$};
\node[scale=0.65] at (-1,-1) {$\lnot M(H,H)$};
\end{tikzpicture}
\end{matrix}

\begin{matrix}
\to
\end{matrix}

\begin{matrix}
\begin{tikzpicture}
\draw[color=black, very thick](0, 0) -- (0, -2);
\draw[color=black, very thick](0, -2) -- (1, -1);
\draw[color=black, very thick](0, -1) -- (1, 0);

\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](1, 0) circle (0.05);

\node[scale=0.45] at (-1.6,0) {$[\lnot M(z,x)\vee\lnot M(H,z)]^{\sg_2}$};
\node[scale=0.65] at (2,0) {$M(\textbf{Д},M)$};
\node[scale=0.65] at (-1,-1) {$\lnot M(H,\text{Д})$};
\node[scale=0.65] at (2,-1) {$M(H, \text{Д})$};
\node[scale=0.65] at (-0.4,-2) {$\square$};
\end{tikzpicture}
\end{matrix}
\end{matrix}
$
}
\end{center}\leavevmode
Здесь $\sg_2$ изменилась на $\begin{pmatrix}z\;\;x\\\text{Д}\;M\end{pmatrix}$. Ответ остался прежним ($x=$"Маша"{}).

Код примера 2:
\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
mother('Natalya', 'Darya').
mother('Darya', 'Maria').

bab(_X,_Y):-mother(_X,_Z),mother(_Z,_Y).

?-bab('Natalya', X),write('granddaughter is '),write(X),nl,fail.
\end{lstlisting}\leavevmode

В следующем примере мы рассмотрим логическое ветвление программы.\\

\primerT 3

Давайте попробуем посравнивать числа. Реализуем процедуру поиска максимального из 2х двух элементов.

Код поиска $max(x,y)$ на Prolog:
\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
max(X,Y,X):- X>Y,!.
max(X,Y,Y).

?-max(1,5,Max),write(Max).
\end{lstlisting}\leavevmode\\

\newpage
Прежде чем объяснять поведение данной программы, следует определить следующее:
\begin{center}
    $\overset{\text{это голова правила}}{\overbrace{max(x,y,x)}}\toPr\overset{\text{это тело правила}}{\overbrace{x>y}}$
\end{center}

Давайте рассмотрим строки кода 1 и 2:

Допустим, мы ввели запрос:
\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
?-max(1,5,Max),write(Max).
\end{lstlisting}
Тогда:
Если $x > y$(выполняется строка 1), то прерываем выполнение следующих команд(из-за оператора !) и записываем $Max=x$(см. запрос).
Иначе $Max = y$. Затем печатаем после выполнения условий $Max$ в консоль. Если бы в третий аргумент в 1й или 2й строке мы написали что-то другое, то $Max$ приравнялся бы к ним, т.е.:

\begin{lstlisting}[language=Prolog,mathescape,basicstyle=\ttfamily\footnotesize]
max(X,Y,3):- X>Y,!./*Max=3, если X>Y, и не выплняем 2ю строку*/
max(X,Y,9)./*Max=9, иначе*/

?-max(1,5,Max),write(Max)./*Если X>Y, выводим 3, иначе 9*/
\end{lstlisting}

Если бы "!"{}(\textbf{оператор отсечения)} не стоял после сравнения, то мы бы \underline{продолжили после 1й строки выполнять 2ю}.

Но откуда 2я строка знает, какие переменные мы передавали в 1ю строку? Введём определение:\\

\opr 

Набор правил, у которых одинаковая голова, называется \textbf{процедурой}.
Процедура пишется в одном месте(т.е. все команды стоят вместе в одной части программы) и никак иначе. Переменные с одинаковыми именами в процедуре являются общими(дикая \textit{отсебятина}, но на практике так вышло).\\

Т.е. в нашем листинге строки 1 и 2 вместе образуют \textit{процедуру}. Если не выполнился предикат первой строки, то будет выполняться 2й в нашем случае. В итоге мы все равно получим нужный ответ.

Если бы мы хотели сравнивать не числа, а слова, то тогда бы нам пришлось вводить факты, гласящие о том, какое слово больше другого, а знак "$>$"{} в листинге примера заменили на предикат, проверяющий истинность от X и Y(см. пример 1).\\

Примерно вот так работает Prolog - на языке фактов, правил и запросов. Стоит отметить, что в Prolog нет циклов - есть только рекурсии.\\

\bftex{Приятный эпилог данной главы}

\textbf{Яхъяева Г.Э.}:

Почему Prolog связывают с ИИ, когда речь о нём заходит? Думаю, вам известен тест Тьюринга. Суть теста заключается в том, что если машина будет общаться с нами и мы того не заметим, то машина прошла тест. Но уже данный тест машины смогли пройти. 

Первой машиной, что пыталась имитировать человеческий диалог, была система \href{https://ru.wikipedia.org/wiki/\%D0\%AD\%D0\%BB\%D0\%B8\%D0\%B7\%D0\%B0_(\%D0\%BF\%D1\%80\%D0\%BE\%D0\%B3\%D1\%80\%D0\%B0\%D0\%BC\%D0\%BC\%D0\%B0)}{\underline{Элиза}}. Она была изобретена в 66м году. \href{http://www.manifestation.com/neurotoys/eliza.php3}{\underline{Система имитировала диалог}} психотерапевта путём методики \textit{отзеркаливания}, т.е. машине что-то писал человек, а машина задавала ему вопросы его же словами. В итоге человек сам с собой говорит-говорит, и рано или поздно он сам себя успокаивает(такой метод используется в психологии). В системе написано огромное количество правил на построение вопросов или ответов к "пациенту"{}, так же система запоминала факты, сказанные ранее человеком, и применяла их в будущих вопросах. Так система и работала успешно. Люди тогда были огромном восторге от этой системы. 

Дальнейшей ветвью развития были экспертные системы - системы, что имитировали экспертов определённой области. Классический пример - медицинская экспертная система. Там по симптомам как раз строился диагноз. В те времена был \textit{большой бум} логического программирования, ведь люди делали столь удивительные вещи, задавая лишь факты и правила. Prolog тогда был на взлёте и многие были уверенны, что Prolog скоро станет обыденностью. Но сейчас это всё пришло в упадок из-за того, что модель, созданная на Prolog, не может сама обучаться и приспосабливаться к новым вещам своей предметной среды. Но это могут делать нейросети, из-за чего они сейчас пользуются огромной популярностью.

Prolog нынче не сильно востребован, но до сих пор встречается где-то и, возможно, он когда нибудь воскреснет и будет его дальнейшее активное развитие. Всем же известна система $W\!ol\!fram$? Некоторая часть её кода написана на Prolog. Возможно, после \textit{бума} нейросетей вновь вернется логическое программирование. Чем плохи нейросети? Их знания крайне тяжело интерпретировать, т.е. обучили мы модель и не можем понять, как именно она поняла освоенный набор данных для обучения. Если нейросеть будет врачом, то никто не поймёт, почему она рекомендовала такое лекарство, для нас он - черный ящик. Это не проблема, но тоже доставляет трудности при тестировании.

И если логическое программирование когда нибудь вернётся, то вы сможете в нём продолжить разбираться далее. Поэтому данные знания и данная глава так нужны в этом курсе:)


\newpage

\msection{Лямбда-исчисление}
\setcounter{spar}{0}
\stepcounter{par}
\setcounter{zap}{1}
\addcontentsline{toc}{subsection}{\S \thepar. Лямбда-исчисление}

Лямбда-исчисление важно в функциональном программировании. Давайте рассмотрим его.\\

\opr 

\textbf{Множеством лямбда-термов $\lmb$} является:

1) $x_i\in\lmb$ - переменная;

2) $c\in\lmb$ - константа;

3) $s,t$ - $\lm$-термы, то их \textbf{комбинация} $st$ тоже $\lm$-терм;

4) $s$ - $\lm$-терм, то $\lm x.s$ - $\lm$-терм. 

Здесь $\lm$ перед $x$ - \textbf{абстрактор}, а процесс \textit{навешивания} $\lm$ на $x$ - \textbf{абстракция}.\\

\primerT 1

Пусть $x$ - переменная. Тогда:

1) $xx$ - терм;

2) $\lm x.xx$ - терм.

Так же принято считать, что кортеж $\ovl x = \lot x 1 n$. 

Тогда $\lm \ovl x.s=\lm \lod x 1 n.s=\underset{n\text{ раз}}{\underbrace{\lm x_1.(\lm x_2.(\lm x_3\dots(\lm x_n.}}s)\dots)$ - так же является термом.

Обозначим $\ovl s=\lod s 1 n$. 

Тогда $t\ovl s=t\lod s 1 n=\underset{n\text{ раз}}{\underbrace{(\dots(}}t s_1)s_2)\dots s_{n-1})s_n$ - терм.\\

\primerT 2

Пусть дан $\lm$-терм $s=\lm xy.yx(\lm z.z)$.

Здесь подразумевается, что действие лямбды $\lm xy$ \textbf{распространено} на \underline{всю правую часть} выражения.

Так же $s$ можно переписать так: $s=\lm x\lm y.yx(\lm z.z)=\lm x.(\lm y.(yx)(\lm z.z))$.

А если мы расставим по другому скобки? 

Рассмотрим $s_1=(\lm xy.yx)\lm z.z=(\lm x\lm y.yx)\lm z.z=(\lm x.(\lm y.yx))\lm z.z$.

Здесь уже действие лямбды $\lm xy$ \underline{ограничено скобками}, в которых она лежит.

Если заметить, то здесь действие абстрактора во многом похоже на действие кванторов из логики предикатов.\\

Откуда вообще пошло $\lm$-исчисление? Буква $\lm$ была взята без особого смысла, просто так исторически сложилось. По факту это \textbf{исчисление функций}. Здесь у нас понятия формулы как таковой не существует, существуют только функции и термы. 

Изначально формулу с аргументами мы писали как \textbf {$t(x)$}. Алонзо Чёрч же предложил такую запись $\hat x.t$, что обозначало вычисление $t$ при подстановке переменных $x$. Когда начали печатать книги, они не смогли напечать $\hat x$ и просто печатали \scalebox{0.6}{$\wedge$}$x$. Позже это медленно перешло в $\lm x$. Поэтому эти исчисления назвали $\lm$-исчислениями.

В чем основная идея $\lm$-исчисления? Идея заключается в том, чтобы свести все выражения к \textit{функтам}, т.е. сводить все функции в примитивную запись в строку(в чём-то аналогия с польской обратной нотацией, вспоминай калькулятор). С точки зрения программирования, этот синтаксис легко обрабатывается и считается компьютером. Можно почитать про это еще \href{https://habr.com/ru/post/215807/}{\underline{здесь}}, хорошо дополняет понимание этого чудо-аппарата.\\
\newpage

\opr 

Переменная $x$ \textbf{входит свободно} в $t$, если не находится в области действия абстрактора $\lm x$. 

Переменная $x$ \textbf{входит связанно} в $t$, если находится в области действия абстрактора $\lm x$.

Так же определяются \textbf{свободная} и \textbf{связанные} переменные.\\

\opr 

\textbf{Множеством свободных переменных} терма $s$ $FV(s)$ обозначают:

1) $s=x\!:\;FV(x)=\{x\}$;

2) $s=c\!:\;FV(c)=\varnothing$;

3) $s=t_1 t_2\!:\;FV(s)=FV(t_1)\cup FV(t_2)$;

4) $s=\lm x.t\!:\;FV(\lm x.t)=FV(t)\;\backslash\;\{x\}$.\\

\opr 

\textbf{Множеством связанных переменных} терма $s$ $BV(s)$ обозначают:

1) $s=x\!:\;BV(x)=\varnothing$;

2) $s=c\!:\;BV(c)=\varnothing$;

3) $s=t_1 t_2\!:\;BV(s)=BV(t_1)\cup BV(t_2)$;

4) $s=\lm x.t\!:\;BV(\lm x.t)=BV(t)\cup\{x\}$.\\

\opr

$\lm$-терм, не имеющий свободных переменных, называется \textbf{замкнутым термом} или \textbf{комбинатором}.\\

\zam 

Для $\forall\lm$-терма $t\!:BV(t)$ и $FV(t)$ - конечны.

\primer

Пусть $s=(\lm xy.x)(\lm x.zx)$, тогда $FV(s)=\{z\},\;BV(s)=\{x,y\}$.

\msubsection{Подстановки}

\opr

Запись вида $s[x:=t]$ будем называть \textbf{подстановкой} терма $t$ вместо $x$ в терме $s$.

Правила подстановки следующие:

1) $x[x:=t]=t$;

2) $y[x:=t]=y$, если $y\neq x$, т.е. тут пытаемся поменять то, чего нет в терме;

3) $c[x:=t]=c$;

4) $s_1 s_2[x:=t]=s_1[x:=t]s_2[x:=t]$;

5) $\lm x.s[x:=t]=\lm x.s$, т.е. нельзя заменить связную переменную;

6) $(\lm y.s)[x:=t]=\lm y.(s[x:=t])$, если $x\neq y$ и ($x\notin FV(s)$ или $y\notin FV(t)$).

В случае 6, если бы мы не поставили такое громоздкое условие, могли бы образоваться захваты переменных, т.е., например, $\lm y.xy[x:=y]=\lm y.yy$. Тогда такая замена могла \textit{сломать} выражение. Поэтому ставится условие непринадлежности к свободным переменным терма. Грубо говоря, это правило подразумевает, что если мы и хотим заменить на переменную, чьё имя уже занято в терме, то её стоит переименовать. 

Или же здесь, чтобы избежать захвата, можно переименовать переменную в терме, на которую хотим заменить другую переменную, т.е. 
\begin{center}
    $(\lm y.s)[x:=t]=\lm z.((s[y:=z])[x:=t]),\;z\notin FV(s)\cup FV(t)$.
\end{center}

По факту, вся эта \textit{суматоха} с переменными только из-за того, чтобы избежать их \textit{коллизий}.

Так же важно понимать, что мы можем заменять только \underline{переменные на} \underline{термы}.\\

\msubsection{Редукция лямбда-исчисления}

Над термами мы можем проводить преобразования, что во многом похожи на \textit{эквивалентные преобразования} в логике высказываний. \\

\opr 

Всего существует 3 главные преобразования(редукции):

1) \textbf{$\alpha$-преобразование}: $\lm x.s\underset{\alpha\text{ преоб.}}{\longrightarrow}\lm y.s[x:=y],\;y\notin FV(s),\;x\sim y$;

2) \textbf{$\beta$-преобразование}: $(\lm x.s)t\underset{\beta\text{ преоб.}}{\longrightarrow}s[x:=t]$;

3) \textbf{$\eta$-преобразование}: $\lm x.sx\underset{\eta\text{ преоб.}}{\longrightarrow}s$.

Чтобы лучше понять 2е преобразование, можно привести следующий пример: пусть есть некоторое исчисление, где есть сложение элементов и некоторые константы. Тогда например:
\\\centr{$(\lm x.x+x)2\underset{\beta}{\longrightarrow}2+2=4$}

\primer

$\lm x.(\lm z.zx)\reda\lm y.(\lm z.zy)$;

$\lm x.zyx\rede zy$.

Приведём несколько примеров $\beta$-редукции:

1) $(\lm x.xy)(\lm z.zx)\redb(\lm z.zx)y$;

2) $(\lm x.\underset{s}{\underbrace{xxx}})\underset{t}{\underbrace{(\lm x.xxx)}}\redb(\lm x.\underset{s}{\underbrace{xxx}})\underset{t}{\underbrace{(\lm x.xxx)}}(\lm x.xxx)\redb\newline\redb(\lm x.xxx)(\lm x.xxx)(\lm x.xxx)(\lm x.xxx)$;\\
И так этот терм можно редуцировать до бесконечности. 

3) $(\lm x.x)a\redb a$;

4) $(\lm x.y)a\redb y$;

5) $(\lm x.\underset{s}{\underbrace{xx}})\underset{t}{\underbrace{(\lm y.y)}}z\redb(\lm y.y)(\lm y.y)z\redb(\lm y.y)z\redb z$.\\

\teor

$(\lm\ovl x.s)\ovl x\redb s$, где $\ovl x=\lod x 1 n$.

\dok 

Индукция по $n$:

\underline{$n = 1$}$:\;(\lm x.s)x\redb s[x:=x]=s$; 

\underline{$n = 2$}$:\;(\lm x_1 x_2.s)x_1 x_2=((\lm x_1.(\lm x_2.s))x_1)x_2\redb(\lm x_2.s[x_1:=x_1])x_2=\newline=(\lm x_2.s)x_2\redb s[x_2:=x_2]=s$; 

\underline{$<n\to n$}$:\;(\lm\ovl x_{n+1}.s)\ovl x_{n+1}=\underset{n+1\text{ раз}}{\underbrace{(\dots(\lm x_1.(\dots(\lm x_n.(\lm x_{n+1}}}.s))x_1)\dots)x_{n+1}\redb\;\redb\underset{n\text{ раз}}{\underbrace{(\dots(\lm x_2.(\dots(\lm x_n.(\lm x_{n+1}}}.s[x_1:=x_1]))x_2)\dots)x_{n+1}\xrightarrow[n\;\beta\text{-преобр-й}]{}\newline\xrightarrow[n\;\beta\text{-преобр-й}]{}s[x_{n+1}:=x_{n+1}]=s$. 

Теорема доказана.\\

Таким образом, в программировании самым важным является $\beta$-преобразо-\;\;вание, т.к. $\alpha$- и $\eta$-преобразования являются по сути техническими и используются, как правило, только в доказательствах.\\

\oprT{отношение редукции}

Говорят, что из терма $s$ \textbf{редуцируется} терм $t\;(s\to t)\Leftrightarrow\newline\Leftrightarrow\exists\lot u 1 n\!:\;s\xrightarrow[\epsilon_1]{}u_1\xrightarrow[\epsilon_2]{}u_2\xrightarrow[\epsilon_3]{}\dots\xrightarrow[\epsilon_{n}]{}u_n\xrightarrow[\epsilon_{n+1}]{}t$, где $\epsilon_i\in\{\alpha,\beta,\eta\}$. \\\\

\predlT{свойства редукции} 

Для $\forall s,t,u\in\lmb\!:$

1) $t\to t$;

2) $(s\to t\text{ и }t\to u)\Rightarrow s\to u$;

3) $s\to t\Rightarrow su\to tu$;

4) $s\to t\Rightarrow us\to ut$;

5) $s\to t\Rightarrow\lm x.s\to\lm x.t $.\\

\opr

Говорят, что терм $s$ \textbf{подобен} терму $t\;(s\sim t)\Leftrightarrow s\to t$ или $t\to s$.

Причём подобие может задаваться и так:
\begin{center}
    $
\begin{matrix}
\begin{matrix}
s_1\to t\\s_2\to t
\end{matrix}\;\;
\begin{matrix}
\Rightarrow
\end{matrix}\;\;
\begin{matrix}
s_1\sim t\\s_2\sim t
\end{matrix}\;\;
\begin{matrix}
\Rightarrow
\end{matrix}\;\;
\begin{matrix}
s_1\sim s_2.
\end{matrix}
\end{matrix}
$
\end{center}
\leavevmode

\opr

Пусть $R\subseteq \lmb^2$ - бинарное отношение, определённое на множестве $\lm$-термов.

Тогда отношение $\redr$ называется \textbf{одношаговой $R$-редукцией}, если $\newline\forall t, s, u  \in \lmb$ верно:

1) $(t, s)\in R\Rightarrow t\redr s$;

2) $t\redr s\Rightarrow ut\redr us$;

3) $t\redr s\Rightarrow tu\redr su$;

4) $t\redr s\Rightarrow \lm x.t \redr \lm x.s$.\\

\opr

Пусть $s\redr t$. Тогда терм $s$ называется \textbf{$R$-редексом} (\underline{red}ucible \underline{ex}pression), а терм $t$ - \textbf{$R$-свёрткой}.\\

\opr

\textbf{Многошаговая $R$-редукция} - отношение $\redrm$, которое является рефлексивным транзитивным замыканием $\beta$-редукции, т. е. $\forall s, t, u\in\lmb$ верны следующие условия:

1) $t\redr s\Rightarrow t\redrm s$;

2) $t\redrm t$;

3) $(t\redrm s\;\&\;s\redrm u)\Rightarrow t\redrm u$.\\

\opr

\textbf{Редукционный граф} терма $t\in\lmb$ - псевдоорграф $G_\beta(t) = (T, \twoheadrightarrow)$, где $T = \{s\in\lmb\;|\;t\twoheadrightarrow s\}$.

\primerT{1}

Редукционный граф для $t=(\lm xy.xy)uv$:

\begin{center}
\scalebox{1.5}
{
\begin{tikzpicture}

\draw[-latex,color=black,very thick](1,0) to[bend right=30] (4,0);
\draw[-latex,color=black,very thick](4,0) to[bend right=30] (7,0);

\draw[fill=black, color=black,very thick](1,0) circle (0.05);
\draw[fill=black, color=black,very thick](4,0) circle (0.05);
\draw[fill=black, color=black,very thick](7,0) circle (0.05);

\draw[-latex,color=black,very thick](1,0) arc (-5:-355:0.4);
\draw[latex-,color=black,very thick](4,0) arc (-85:265:0.4);
\draw[-latex,color=black,very thick](7,0) arc (-175:175:0.4);

\draw[-latex,color=black,very thick](1,0) to[bend left=30] (7,0);

\node[scale=0.6] at (1,-0.5) {$(\lm xy.xy)uv$};
\node[scale=0.6] at (4,-0.5) {$(\lm y.uy)v$};
\node[scale=0.6] at (7,-0.5) {$uv$};
\end{tikzpicture}
}
\end{center}
\leavevmode

\primerT{2}

Редукционный граф для $t=(\lm x.x)((\lm x.x)x)$:

\begin{center}
\scalebox{1.5}
{
\begin{tikzpicture}

\draw[-latex,color=black, very thick](1,0) to[bend left=20] (4,0);
\draw[-latex,color=black, very thick](1,0) to[bend right=20] (4,0);

\draw[fill=black, color=black, very thick](1,0) circle (0.05);
\draw[fill=black, color=black, very thick](4,0) circle (0.05);

\draw[-latex,color=black,very thick](1,0) arc (-5:-355:0.4);
\draw[-latex,color=black,very thick](4,0) arc (-175:175:0.4);

\node[scale=0.6] at (1,-0.6) {$(\lm x.x)((\lm x.x)x)$};
\node[scale=0.6] at (4,-0.6) {$(\lm x.x)x$};
\end{tikzpicture}
}
\end{center}
\leavevmode

Наличие двух дуг из первой вершины во вторую обусловлено тем, что мы можем получить один и тот же терм редукциями по разным переменным.

\newpage

\opr 

$\lm$-терм $t$ имеет \textbf{нормальную форму}, если к нему применимо либо только $\alpha$-преобразование, либо вообще ничего нельзя применить.\\

Основная цель наших преобразований состоит в том, чтобы привести терм к \textbf{н.ф.}. Для этого существуют две основные стратегии: нормальная и аппликативная.\\

\opr

1) При \textbf{нормальной стратегии} мы сокращаем самый левый \underline{внешний} редекс.

2) При \textbf{аппликативной стратегии} мы сокращаем самый левый \underline{внутрен}-\underline{ний} редекс.\\

\primer

Пусть дан терм $s=(\lm x.y)((\lm x.xxx)(\lm x.xxx))$.

Здесь всё зависит от того, как мы будем преобразовывать. Если мы станем преобразовывать внутренние правые скобки в $s$, то терм только расширится и мы не сможем так получить \textbf{н.ф.}.

Но можем сделать преобразование следующим образом:

$(\lm x.\underset{s}{\underbrace{y}})\underset{t}{\underbrace{((\lm x.xxx)(\lm x.xxx))}}\redb y$.

Тогда мы получим \textbf{н.ф.}, т.к. с $y$ мы уже ничего сделать не сможем.\\

Наша задача - преобразовывать терм так, чтобы получать \textbf{н.ф.}, т.к. применять $\beta$-редукцию мы можем \underline{разными способами}.

\newpage

\teor 

Если $s\to t$ и $t$ имеет \textbf{н.ф.}, то нормальная стратегия всегда успешно приведёт $s$ к \textbf{н.ф.}.

\bezdok\\

Тогда зачем нам аппликативная стратегия, если она, в отличие от нормальной, не всегда приводит терм к \textbf{н.ф.}? При нормальной стратегии зачастую приходится подставлять огромные выражения, это проще показать на примере.

\primer

Приведём к \textbf{н.ф.} терм $t=(\lm xy.yx)\;((\lm x.xx)\;b)\;((\lm x.cxb)\;(fgh))$.

Применим нормальную стратегию:

$t\redb((\lm x.cxb)\;(fgh))\;\;((\lm x.xx)\;b)\redb(c(fgh)b)\;(bb)$.

Теперь применим аппликативную стратегию:

$t\redb(\lm xy.yx)\;(bb)\;(c(fgh)b)\redb(c(fgh)b)\;(bb)$.

С другой стороны, при нормальной стратегии мы не считаем ничего лишнего.\\

\teorT{Чёрча-Россера или правило ромба}

Если $t\to s_1$ и $t\to s_2\Rightarrow\exists u\!:s_1\to u$ и $s_2\to u$.

\bezdok

Если показать графически эту теорему, то она будет выглядеть так:
\begin{center}
\begin{tikzpicture}
\node[scale=1.3,rotate=-135] at (-0.6,-0.39) {$\longrightarrow$};
\node[scale=1.3,rotate=-45] at (0.55,-0.46) {$\longrightarrow$};
\node[scale=1.2] at (0,0.15) {$t$};

\node[scale=1.2] at (-0.85,-1.25) {$s_1$};
\node[scale=1.2] at (0.93,-1.25) {$s_2$};

\node[scale=1.3,rotate=-45] at (-0.6,-2.06) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (0.56,-2) {$\longrightarrow$};
\node[scale=1.2] at (0,-2.8) {$u$};
\end{tikzpicture}
\end{center}

\newpage

\sled

$t_1\sim t_2\Rightarrow\exists u\!:t_1\to u$ и $t_2\to u$.

Графически это следствие будет выглядеть так:

\begin{center}
\begin{tikzpicture}
\node[scale=1.2] at (-0.1,0.15) {$t_1$};
\node[scale=1.3,rotate=-45] at (0.55,-0.48) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (1.55,-0.4) {$\longrightarrow$};
\node[scale=1.2] at (2.35,0.15) {$s_1$};
\node[scale=1.3,rotate=-45] at (3.1,-0.48) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (4.1,-0.4) {$\longrightarrow$};
\node[scale=1.2] at (3.7,0.15) {$\dots$};
\node[scale=1.2] at (4.9,0.15) {$s_n$};
\node[scale=1.3,rotate=-45] at (5.6,-0.48) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (6.6,-0.4) {$\longrightarrow$};
\node[scale=1.2] at (7.4,0.15) {$t_2$};
%next level%
\node[scale=1.3,rotate=-45] at (1.55,-1.48) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (3.1,-1.4) {$\longrightarrow$};
\node[scale=1.3,rotate=-45] at (4.1,-1.48) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (5.6,-1.4) {$\longrightarrow$};
\node[scale=1.2] at (3.7,-2.15) {$\dots\dots\dots\dots$};
\node[scale=1.3,rotate=-45] at (2.95,-2.78) {$\longrightarrow$};
\node[scale=1.3,rotate=-135] at (4.25,-2.7) {$\longrightarrow$};
\node[scale=1.2] at (3.65,-3.35) {$u$};
\end{tikzpicture}
\end{center}\leavevmode
Давайте вспомним, как строится подобие термов? Либо из $t_1$ редуцируется $t_2$, либо наоборот. Что значит редуцируется? Значит, что есть набор термов, что являются \textit{шагами} редукции одного $t$ к другому. Этим набором как раз является $\lot s 1 n$. Применяем к $t_1,t_2,\lot s 1 n$ конечное число раз \textit{правило ромба} и получаем такую пирамидку вывода.\\

\sled 

Если $t\sim t_1$ и $t\sim t_2$, $t_1$ и $t_2$ имеют \textbf{н.ф.}, то $t_1$ и $t_2$ \textbf{равны с точностью до $\alpha$-преобразования}, т.е. с точностью до переименования переменных.

\dok 

$(t\sim t_1\text{ и }t\sim t_2)\to t_1\sim t_2\Rightarrow\exists u\!\!:t_1\reda u\text{ и }t_2\reda u$, поскольку $t_1$ и $t_2$ имеют \textbf{н.ф.}, т.е. их можно только переименовать $\Rightarrow$ $t_1$ и $t_2$ равны с точностью до $\alpha$-преобразования.

Следствие доказано.\\

О чём эти следствия говорят? О том, что если у терма и есть \textbf{н.ф.}, то она \underline{единственная}.

\msubsection{Комбинаторы}

Еще раз вспомним, что \textbf{комбинатором} называется терм без свободных переменных, т.е. все переменные связаны абстракциями. С логической точки зрения, для программирования вполне достаточно комбинаторов
$\ki,\;\kk,\;\ks$, т.е. из них можно всё вывести. Остальные же комбинаторы используются для каких-либо иных целей. \\

\opr 

Основными комбинаторами являются:

1) $\ki:=\lm x.x$ - \textbf{тождественный комбинатор};

2) $\kb:=\lm xyz.x(yz)$ - \textbf{композитор};

3) $\kc:=\lm xyz.xzy$ - \textbf{пермутатор};

4) $\kk:=\lm xy.x$ - \textbf{канцелятор};

5) $\ks:=\lm xyz.(xz)(yz)$ - \textbf{коннектор};

6) $\kw:=\lm xy.xyy$ - \textbf{дупликатор};

7) $\omega:=\lm x.xx$;

8) $\Omega:=\omega\omega=(\lm x.xx)(\lm x.xx)$.\\

\predl 

$\forall s,t,u\in\lmb\!:$

1) $\ki s\sim s$;

2) $\kb stu\sim s(tu)$;

3) $\kc stu\sim sut$;

4) $\kk st\sim s$;

5) $\ks stu\sim (su)(tu)$;

6) $\kw st\sim stt$.

\dok

Применяем $\beta$-редукцию и успешно сокращаем. 

Предложение доказано.\\

\teor 

Для $\forall\lm$-терма $t$, не содержащего $\lm$-абстракции, существует $\lm$-терм $u$, который так же не содержит $\lm$-абстракции и представляется собой композицию комбинаторов $\ki,\kk,\ks$ и переменных и $u\sim\lm x.t$.

\bezdok\\

\sled

Для $\forall\lm\text{-терма }t\;\exists t'\!\!:\;t'$ - композиция $\ki,\kk$ и переменных такая, что\\ $FV(t')=FV(t)$ и $t'\sim t$.

\bezdok

В чём идея следствия? Пусть, допустим, у нас существует огромный терм, но мы его можем преобразовать в такой вид, что в нём будут составляющие только того вида, что обозначены в следствии.

\msubsection{Выражения $\lm$-исчисления}

Теперь у нас есть возможность определить конкретные арифметические и логические операции, а также рекурсию.\\

\opr

\textbf{Комбинаторами истинности} являются:

1) $true = \lm tf.t$

2) $false = \lm tf.f$\\

Нетрудно заметить, что комбинаторы истинности действуют как канцеляторы с той лишь разницей, что они "отменяют"\;разные входные параметры.\\

\opr

\textbf{Логические конструкции} $\lm$-исчисления:

1) $\lfunction{if} \;A\;\lfunction{then}\;B\;\lfunction{else}\;C = \lm bxy.bxy$;

2) $\lfunction{not}=\lfunction{if}\;p\;\lfunction{then}\;false\;\lfunction{else}\;true=\lm b.\;false\;true$;

3) $\lfunction{and}=\lfunction{if}\;p\;\lfunction{then}\;q\;\lfunction{else}\;false=\lm xy.xy\;false$;

4) $\lfunction{or}=\lfunction{if}\;p\;\lfunction{then}\;true\;\lfunction{else}\;q=\lm xy.x\;true\;y$.\\

\primerT {1 с $\lfunction{not}$}

$\lfunction{not}\;false=\lfunction{if}\;false\;\lfunction{then}\;false\;\lfunction{else}\;true =\newline=(\lm bxy.bxy)false\;false\;true\redb false\;false\;true=\newline=(\lm tf.f)false\;true\redb (\lm f.f)\;true\redb
true$.\\

\primerT {2 с $\lfunction{and}$}

$\lfunction{and}\;true\;false = (\lm xy.xy\;false)\;true\;false\redb true\;false\;false =\newline= (\lm tf.t)\;false\;false\redb false$.

В $\lfunction{or}$ аргументы подставляются так же, как и в $\lfunction{and\\}$.\\

\opr

1) $\lfunction{pair}=\lm xyf.fxy$ - \textbf{упорядоченная пара};

2) $\lfunction{fst}=\lm p.p\;true$ - \textbf{операция проекции на первый элемент};

3) $\lfunction{snd}=\lm p.p\;false$ - \textbf{операция проекции на второй элемент}.\\

\newpage

\primer

$\lfunction{snd}(\lfunction{pair}\;AB) = \lfunction{snd}((\lm xyf.fxy)\;AB) \redb (\lm p.p\;false)(\lm f.fAB)\redb\newline\redb (\lm f.fAB)(\lm tf.f)\redb (\lm tf.f)AB\redb B$.\\

\opr

\textbf{Числами} или \textbf{нумералами Чёрча} являются:

$\churchnum{0}=\lm sz.z$;

$\churchnum{1}=\lm sz.sz$;

$\churchnum{2}=\lm sz.s(sz)$;

$\churchnum{3}=\lm sz.s(s(sz))$;

...

$\churchnum{n}=\lm sz.s^nz$.

Обратите внимание, что \churchnum{0} с точностью до переменных похож на комбинатор $false$, но последний является логическим, а не арифметическим комбинатором.

\opr

В $\lm$-исчислении существуют следующие \textbf{операции над числами}:

1) $\lfunction{succ}=\lm nsz.s(nsz)$ - увеличение числа на 1;

2) $\lfunction{iszro}=\lm n.n(\lm x.false)\;true$ - проверка числа на равество нулю;

3) $\lfunction{plus}=\lm mnsz.ms(nsz)$ - сумма чисел;

4) $\lfunction{mult}=\lm mnsz.m(ns)z$ - произведение чисел.\\

\predl

Данные арифметические операции корректно определены.

\dok

1) $\lfunction{succ}\;\;\churchnum{n}=(\lm nsz.s(nsz))\;(\lm sz.s^nz)\redb\lm sz.s((\lm sz.s^nz)sz)\redb\newline\redb\lm sz.s(s^nz)=\lm sz.s^{n + 1}z=\churchnum{n + 1}$.

2) Рассмотрим 2 случая:

\underline{Сл.1.} Пусть $\churchnum{n} = \churchnum{0}$, тогда $\lfunction{iszro}\;\churchnum{0}\redb (\lm sz.z)\;(\lm x.false)\;true\redb true$.

\underline{Сл.2.} Пусть $\churchnum{n}>\churchnum{0}$, тогда $\lfunction{iszro}\;\churchnum{n}\redb (\lm sz.s^nz)\;(\lm x.false)\;true=\newline=(\lm sz.s(s^{n-1}z))\;(\lm x.false)\;true\redb (\lm x.false)((\lm x.false)
^{n-1}true))\redb\newline\redb false$.

3) $\lfunction{plus}\;\churchnum{m}\;\churchnum{n}\redb\lm sz.(\lm sz.s^mz)s\;((\lm sz.s^nz)sz)\redb\newline\redb\lm sz.(\lm sz.s^mz)\;s\;(s^nz)\redb\lm sz.(s^m\;(s^nz))\redb\lm sz.s^{m + n}z=\churchnum{m + n}$.

4) Доказывается на семинарах.

Предложение доказано.\\

\opr

Введём следующие вспомогательные функции:

$\lfunction{zp}=\lfunction{pair}\;\churchnum{0}\;\churchnum{0}$;

$\lfunction{sp}=\lm\msP .\lfunction{pair}\;(\lfunction{snd}\;\msP)\;(\lfunction{succ}\;(\lfunction{snd}\;\msP))$.

Вторая функция работает так:

$\lfunction{sp}\;(\lfunction{pair}\;\churchnum{i}\;\churchnum{j}) = \lfunction{pair}\;\churchnum{j}\;\;\churchnum{j + 1}$

$\lfunction{sp}^0\;(\lfunction{zp})=\lfunction{pair}\;\churchnum{0}\;\;\churchnum{0}$

$\lfunction{sp}^m\;(\lfunction{zp})=\lfunction{pair}\;\churchnum{m - 1}\;\;\churchnum{m}$

Определим \textbf{функцию предыдущего числа} для всех $\msM >\mzero$:

$\lfunction{pred}=\lm \msM .\lfunction{fst}\;(\msM\;\lfunction{sp}\;\lfunction{zp})$.\\

\predl

Функция предыдущего числа корректно определена.\\

Функция предыдущего числа позволяет реализовывать в лямбда-исчисле- нии рекурсию, так как в нём \underline{нет циклов}. Рекурсия реализуется через так называемые неподвижные точки.\\

\teorT{о неподвижной точке}

$\forall F \in \lmb$ существует неподвижная точка $X$ такая, что $FX \redb X$.

\dok

Введём $W=\lm x.F(xx) \text{ и } X=WW$. Тогда $X=WW=\newline=(\lm x.F(xx))W\redb F(WW)=FX$.

Теорема доказана.\\

\teorT{о комбинаторе неподвижной точки}

Существует комбинатор неподвижной точки $\ky$ такой, что $\forall F\in\lmb$ выполнено $F(\ky F)\redb\ky F$.

\dok

Введём $\ky = \lm f.(\lm x.f(xx))(\lm x.f(xx))$. Тогда для любого $F$ имеем:

$\ky F\redb (\lm x.F(xx))(\lm x.F(xx))\redb F(\underset{\ky F}{\underbrace{(\lm x.F(xx))(\lm x.F(xx)}})=F(\ky F).$

Теорема доказана.\\

\oprT{комбинаторы неподвижной точки}

1) $\ky=\lm f.(\lm x.f(xx))(\lm x.f(xx))$ - \textbf{комбинатор Карри};

2) $\Theta=(\lm xy.y(xxy))(\lm xy.y(xxy))$ - \textbf{комбинатор Тьюринга}.\\

\opr

Определим функцию факториала "как есть":

$\lfunction{fac}=\lm n.\lfunction{if}\;(\lfunction{iszro}\; n)\;\lfunction{then}\;\churchnum{1}\;\lfunction{else}\;(\lfunction{mult}\;n\;(\lfunction{fac}\;(\lfunction{pred}\;n)))$.

Такое определение факториала плохо тем, что наличие $\lfunction{fac}$ внутри тела функции сделает $\lm$-терм бесконечным. Но мы можем завести новую переменную и вынести $\lfunction{fac}$ изнутри $\beta$-редукцией наоборот:

$\lfunction{fac}=\underset{fac'}{\underbrace{(\lm fn.(\lfunction{if}\;(\lfunction{iszro}\; n)\;\lfunction{then}\;\churchnum{1}\;\lfunction{else}\;(\lfunction{mult}\;n\;(f\;(\lfunction{pred}\;n))))}}\;\lfunction{fac}$.

Отсюда видно, что $\lfunction{fac}$ - неподвижная точка вспомогательной функции $fac'$, и по теореме о комбинаторе неподвижной точки мы сможем записать определение функции так:

$\lfunction{fac} = \ky\;fac'$ - \textbf{функция факториала}.\\

\primer

Найдём факториал от пяти.

1) Для $\churchnum{n}=\churchnum{0}$ верно

$\lfunction{fac}\;\churchnum{0}=\ky\;fac'\;\churchnum{0}=fac'\;(\ky\;fac')\;\churchnum{0}=\newline=(\lm fn.(\lfunction{if}\;(\lfunction{iszro}\; n)\;\lfunction{then}\;\churchnum{1}\;\lfunction{else}\;(\lfunction{mult}
\;n\;(f\;(\lfunction{pred}\;n))))\;(\ky\;fac')\;\churchnum{0}\redb\newline\redb\lfunction{if}\;(\underset{true}{\underbrace{\lfunction{iszro}\; \churchnum{0}}})\;\lfunction{then}\;\churchnum{1}\;\lfunction{else}
\;(\lfunction{mult}\;\churchnum{0}\;((\ky\;fac')\;(\lfunction{pred}\;\churchnum{0})))\redb\churchnum{1}$.

2) $\forall\;\churchnum{n}>\churchnum{0}$ верно

$\lfunction{fac}\;\churchnum{n}=\ky\;fac'\;\churchnum{n}=fac'\;(\ky\;fac')\;\churchnum{n}=\newline=(\lm fn.(\lfunction{if}\;(\lfunction{iszro}\; n)\;\lfunction{then}\;\churchnum{1}\;\lfunction{else}\;(\lfunction{mult}
\;n\;(f\;(\lfunction{pred}\;n))))\;(\ky\;fac')\;\churchnum{n}\redb\newline\redb\lfunction{if}\;(\underset{false}{\underbrace{\lfunction{iszro}\; \churchnum{n}}})\;\lfunction{then}\;\churchnum{1}\;\lfunction{else}
\;(\lfunction{mult}\;\churchnum{n}\;((\ky\;fac')\;(\lfunction{pred}\;\churchnum{n})))\redb\newline\redb\lfunction{mult}\;\churchnum{n}\;(\ky\;fac'\;\churchnum{n - 1})$.

3) Теперь факториалы для положительных $\churchnum{n}$ легко находятся:

$\lfunction{fac}\;\churchnum{1}=\ky\;fac'\;\churchnum{1}\redb\lfunction{mult}\;\churchnum{1}\;(\ky\;fac'\;\churchnum{0})=\churchnum{1}$;

$\lfunction{fac}\;\churchnum{2}=\ky\;fac'\;\churchnum{2}\redb\lfunction{mult}\;\churchnum{2}\;(\ky\;fac'\;\churchnum{1})=\churchnum{2}$;

$\lfunction{fac}\;\churchnum{3}=\ky\;fac'\;\churchnum{3}\redb\lfunction{mult}\;\churchnum{3}\;(\ky\;fac'\;\churchnum{2})=\churchnum{6}$;

$\lfunction{fac}\;\churchnum{4}=\ky\;fac'\;\churchnum{4}\redb\lfunction{mult}\;\churchnum{4}\;(\ky\;fac'\;\churchnum{3})=\churchnum{24}$;

$\lfunction{fac}\;\churchnum{5}=\ky\;fac'\;\churchnum{5}\redb\lfunction{mult}\;\churchnum{5}\;(\ky\;fac'\;\churchnum{4})=\churchnum{120}$.\\

Хотелось бы отметить, что для вычисления $5!$ потребовалось бы применить 66066 $\beta$-редукций, если их делать по одной, а не как в примере выше.\\

При помощи помощи этих и многих других функций мы можем записать практически любое выражение. На этом заканчивается обзор $\lm$-исчисления.\\

\msection{Модальная логика}
\setcounter{spar}{0}
\stepcounter{par}
\setcounter{zap}{1}
\addcontentsline{toc}{subsection}{\S \thepar. Модальная логика}

Историки считают, что модальностью еще начинал заниматься Аристотель, однако строго модальная логика возникла только в прошлом столетии и получила довольно широкое приложение.

Например, у нас есть логика высказываний, а там есть высказывания, предложения, в которых можем утвержать "\textit{истинно ли что-то или ложно?}"{}.

Возьмём высказывание "\textit{Александр Македонский завтра выиграет сражение}"{}. Истинно ли это? Когда завтра наступит, мы узнаем, но пока нам неизвестен исход. Но мы можем предположить два исхода: "\textit{он выиграет}"{} или "\textit{он проиграет}"{}. Мы можем рассмотреть все возможные миры, где как раз получаем ответ на данный вопрос: Макендонский победит или проиграет. И мы говорим, что "возможно"{} он победит - это значит, что существует тот мир, где данное событие произошло, или наоборот. А можем сказать, что он "необходимо"{} победит, т.е. во всех возможных мирах он побеждает в данном событии, или наоборот. Т.е. здесь следующий день рассматриваем как некоторое множество миров, где может что-то произойти. В данном ключе мы будем рассуждать всю следующую тему.

"Необходимое событие"{} или "возможное событие"{} - это и является \textbf{модальностью}.

Сначала мы будем рассматривать пропозициональную модальную логику, где нет никаких кванторов.\\

\opr 

Обозначим набор пропозициональных переменных как множество\\\centr{$\sg=\{A_1,A_2,\dots\}$.} 

Данное множество может быть конечным или бесконечным.

Так же обозначим набор модальностей \\\centr{$\modal=\{m_1,m_2,\dots\}$.}

Существуют разные модальности, и пара $(\sg,\modal)$ задаёт \textbf{модальную логику}.\\

Дополнительное объяснение модальной логики находится \href{https://ru.wikipedia.org/wiki/\%D0\%9C\%D0\%BE\%D0\%B4\%D0\%B0\%D0\%BB\%D1\%8C\%D0\%BD\%D0\%B0\%D1\%8F_\%D0\%BB\%D0\%BE\%D0\%B3\%D0\%B8\%D0\%BA\%D0\%B0}{\underline{здесь}}.
Далее введём понятие формулы.\\

\opr 

\textbf{Формулой модальной логики $(\sg,\modal)$} являются:

1) $\forall A_i\in\sg$ - формула;

2) $\vp,\psi$ - формулы $\Rightarrow(\vp\ampersand\psi),\;(\vp\vee\psi),\;(\vp\to\psi),\;\lnot\vp,\;\lnot\psi$ - формулы;

3) $\vp$ - формула и $m$ - модальность, то $\langle m\rangle\vp,[m]\vp$ - формулы;

4) Других формул нет.\\

\opr 

Если $||\modal||=1$, то $(\sg,\modal)$ является \textbf{унимодальной логикой}, иначе \textbf{полимодальной логикой}.\\

Мы будем рассматривать только унимодальную логику. Т.к. у нас только одна модальность, то то формулы с модальностями будем писать так:

$\langle m\rangle\vp\Rightarrow\may\vp$(возможно $\vp$);

$[m]\vp\Rightarrow\need\vp$(необходимо $\vp$).

В области искуственного интеллекта используется логика описания(descrip-\;\;\;\;tion logic), что тоже является полимодальной логикой. Т.е. это всё же имеет смысл изучать. \\

\opr

Подмножество пропозициональных переменных $w\subseteq\sg$ является \textbf{миром}.
Всего всевозможных миров в унимодальной логике равно $2^{||\sg||}$.\\

\opr 

\textbf{Структурой Крипке} является пара $\langle W,R\rangle$, где:

$W$ - множество миров;

Бинарное отношение $R\subseteq W^2$ является \textbf{отношением достижимости}.\\

\primer

Покажем пример структуры Крипке на примере с Македонским.

\begin{center}
\begin{tikzpicture}

\draw[color=black, very thick](-2, -1) -- (0, 0);
\draw[color=black, very thick](-2, -1) -- (0, -2);
\draw[color=black, very thick](0, 0) -- (2, -1);
\draw[color=black, very thick](0, -2) -- (2, -1);

\draw[fill=black, color=black, very thick](-2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);

\node[scale=1.1] at (-2.5,-1) {$w_1$};
\node[scale=1.1] at (0,0.3) {$w_2$};
\node[scale=1.1] at (0,-2.4) {$w_3$};
\node[scale=1.1] at (2.5, -1) {$w_4$};
\end{tikzpicture}
\end{center}

Здесь мы находимся в мире $w_1$ и рассуждаем, что произойдёт завтра. И у нас есть два исхода: победа(в $w_2$) или поражение(в $w_3$). А потом уже, если мы в какой-то мир из $w_2$ или $w_3$ в итоге попали, то дальше, предположим, эти исходы слились и на следующий день он уже гарантированно победил. А может наоборот случиться и события ещё сильнее разветвлятся, т.е. появится еще больше различных миров. Здесь отношение $R$ - как раз соединения миров.\\

\opr 

\textbf{Моделью Крипке} будем обозначать набор $\mM=\langle W,R,V\rangle$, где $\langle W,R\rangle$ - структура Крипке и $V\!\!:\sg\to W$ - означивание, где 
\begin{center}
    $\forall A_i\in\sg\!:\;V(A_i)=\{w\in W\;|\;A_i\in w\}$.
\end{center}

Здесь уже, помимо информации о том, какие есть миры и как они связаны, так же появляется некоторая информация об этих мирах, где какие \underline{истинные переменные}.

Еще раз рассмотрим пример с Македонским:

\begin{wrapfigure}[4]{l}{0.35\textwidth}
\begin{tikzpicture}

\draw[color=black, very thick](-2, -1) -- (0, 0);
\draw[color=black, very thick](-2, -1) -- (0, -2);
\draw[color=black, very thick](0, 0) -- (2, -1);
\draw[color=black, very thick](0, -2) -- (2, -1);

\draw[fill=black, color=black, very thick](-2, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](2, -1) circle (0.05);

\node[scale=1.1] at (-2.5,-1) {$w_1$};
\node[scale=1.1] at (0,0.5) {$w_2(A)$};
\node[scale=1.1] at (0,-2.5) {$w_3(\lnot A)$};
\node[scale=1.1] at (3, -1) {$w_4(A)$};
\end{tikzpicture}
\end{wrapfigure}
\leavevmode

Здесь $A$ - победа Македонского и 

$V(A)=\{w_2,w_4\}$. Допустим, он вновь 

победил в $w_4$.\\\\

\opr 

Пусть есть модель Крипке $\mM=\langle W,R,V\rangle$ и\\$w\in W$. Тогда пара $(\mM,w)$ называется \textbf{структурой мира $w$} в $\mM$.\\

\opr 

Пусть дана модель Крипке $\mM=\langle W,R,V\rangle$ и $w\in W$.

Определим \textbf{истинность формулы на модели Крипке}:

1) $\mM,w\vD A_i\Leftrightarrow w\in V(A_i)$;

2) $\mM,w\vD\vp_1\ampersand\vp_2\Leftrightarrow\mM,w\vD\vp_1$ и $\mM,w\vD\vp_2$;

3) $\mM,w\vD\vp_1\vee\vp_2\Leftrightarrow\mM,w\vD\vp_1$ или $\mM,w\vD\vp_2$;

4) $\mM,w\vD(\vp_1\to\vp_2)\Leftrightarrow\mM,w\nvDash\vp_1$ или $\mM,w\vD\vp_2$;

5) $\mM,w\vD\lnot\vp\Leftrightarrow\mM,w\nvDash\vp$;

6) $\mM,w\vD\may\vp\Leftrightarrow\exists v\in W\!\!:((w,v)\in R\text{ и }\mM,v\vD\vp)$;

7) $\mM,w\vD\need\vp\Leftrightarrow\forall v\in W\!\!:((w,v)\in R\Rightarrow\mM,v\vD\vp)$.

В 7м пункте важно учесть, что "$\Rightarrow$"{} \underline{сопоставима с импликацией}.\\

\opr 

$\mM\vD\vp\Leftrightarrow\vp$ истинно в каждом мире из модели $\mM$.

Формула $\vp$ истинна на структуре Крипке, если она истинна \underline{на любой моде}-\underline{ли} с данной структурой.\\

\predl 

$\vp$ - т.и. в логике высказываний $\Leftrightarrow\vp$ - т.и. в модальной логике.\\ 

\predl 

Следующие формулы т.и. в модальной логике:

1) $\need(A\to B)\to(\need A\to\need B)$;

2) $\need(A\ampersand B)\leftrightarrow(\need A\ampersand\need B)$;

3) $\may(A\vee B)\leftrightarrow(\may A\vee\may B)$;

4) $(A\to\may(B\to C))\leftrightarrow\may(B\to(A\to\may C))$.

\dok

1) Докажем от противного. 

Пусть $\exists\mM\;\exists w\!:\;\mM,w\nvDash(\need(A\to B)\to(\need A\to\need B))\Leftrightarrow\newline\Leftrightarrow\mM,w\vD\need(A\to B)$ и $\mM,w\vD\lnot(\need A\to\need B)\Leftrightarrow\newline\Leftrightarrow\mM,w\vD\need(A\to B)$ и $\mM,w\vD(\need A\ampersand\lnot\need B)\Leftrightarrow\newline\Leftrightarrow\mM,w\vD\need(A\to B)$ и $\mM,w\vD\need A$ и $\mM,w\vD\lnot\need B\Leftrightarrow\newline\Leftrightarrow\forall v\in W\!\!:(w,v)\in R\Rightarrow\mM,v\vD A\to B\Leftrightarrow\newline\Leftrightarrow\forall v\in W\!\!:(w,v)\in R\Rightarrow\mM,v\vD A,\;\mM,w\vD\lnot\need B\Rightarrow\newline\Rightarrow\forall v\in W\!\!:(w,v)\in R\Rightarrow\mM,v\vD B$ и $\mM,w\vD\lnot\need B\Rightarrow\newline\Rightarrow\mM,w\vD\need B$ и $\mM,w\vD\lnot\need B$. Получаем противоречие $\Rightarrow$ 1я формула т.и.

Остальное по похожей схеме...

Предложение доказано.\\

\opr 

$\vp$ - выполнима на $\mM\Leftrightarrow\exists w\in W\!\!:\;\mM,w\vD\vp$.\\

\predl

Следующие формулы выполнимы:

1) $\need A\to A$;

2) $\need A\to\need\need A$;

3) $\need(A\vee B)\to(\need A\to\need B)$.\\

\opr

$\vp\sim\psi$(формулы $\vp$ и $\psi$ эквивалентны) $\Leftrightarrow\forall\mM=\langle W,R,V\rangle,\;\forall w\in W\!\!:\newline:\mM,w\vD\vp\Leftrightarrow\mM,w\vD\psi$.\\

\predl

Следующие формулы эквивалентны:

1) $\may\vp\sim\lnot\need\lnot\vp$;

2) $\need\vp\sim\lnot\may\lnot\vp$.\\

\newpage

\msubsection{Бисимуляция}

\opr

Пусть есть модели $\mM=\langle W,R,V\rangle$ и $\mM'=\langle W',R',V'\rangle,\;w\in W,\;w'\in W'$. Тогда:

1) $w\equiv w'$(\textbf{атомарно эквивалентны}) $\Leftrightarrow\newline\Leftrightarrow\forall A\in\sg\!:\;\mM,w\vD A\Leftrightarrow\mM',w'\vD A$; 

2) $w\approx w'$(\textbf{модально эквивалентны}) $\Leftrightarrow\newline\Leftrightarrow\forall\vp\in F(\sg)\!:\;\mM,w\vD\vp\Leftrightarrow\mM',w'\vD\vp$.

Стоит отметить, что из атомарной эквивалентности модальная эквивалентность \underline{не следует}.\\

Если у нас есть одинаковые миры, то это еще не значит, что на них сработает любая формула.

\primerT 1

Рассмотрим миры $s$ и $t$ в моделях $\mM,\mM'$ соответственно:

\begin{wrapfigure}[5]{l}{0.4\textwidth}
\begin{tikzpicture}

\draw[latex-,color=black, very thick](-1, 0) -- (-1, -2);
\draw[latex-,color=black, very thick](-1,-2) to[bend left=50] (1, -2);
\draw[-latex,color=black, very thick](-1,-2) to[bend right=50] (1, -2);
\draw[-latex,color=black, very thick](1,-2) -- (1, -4);

\draw[fill=black, color=black, very thick](-1, 0) circle (0.05);
\draw[fill=black, color=black, very thick](-1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -4) circle (0.05);

\draw[latex-,color=black, very thick](3, 0) -- (3, -2);
\draw[latex-,color=black, very thick](3,-2) to[bend left=50] (5, -2);
\draw[-latex,color=black, very thick](3,-2) to[bend right=50] (5, -2);
\draw[-latex,color=black, very thick](3,-2) -- (3, -4);

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](3, -2) circle (0.05);
\draw[fill=black, color=black, very thick](5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -4) circle (0.05);

\node[scale=1.1] at (1.3,-2) {$s$};
\node[scale=1.1] at (1.45,-4) {$s_1$};
\node[scale=1.1] at (-1.4,-2) {$s_2$};
\node[scale=1.1] at (-1.4,0) {$s_3$};

\node[scale=1.1] at (2.7,-2) {$t$};
\node[scale=1.1] at (2.65,-4) {$t_1$};
\node[scale=1.1] at (2.6,0) {$t_3$};
\node[scale=1.1] at (5.4,-2) {$t_2$};

\node[scale=1.1] at (4.15,-4.5) {$\mM'$};
\node[scale=1.1] at (0, -4.5) {$\mM$};
\end{tikzpicture}
\end{wrapfigure}

Пусть $s\equiv t$. Рассмотрим формулу 

$\vp=\need(\need0\vee\may\need0)$, где 0 - т.л. формула.

Если $\mM,s\vD\vp\Rightarrow\mM,s_1\vD\need0\vee\may\need0$ и 

$\mM,s_2\vD\need0\vee\may\need0\Leftrightarrow$

$\Leftrightarrow\begin{cases}\mM,s_1\vD\need0$ или $\mM,s_1\vD\may\need0\\
\mM,s_2\vD\need0$ или $\mM,s_2\vD\may\need0\end{cases}$\\

Давайте рассмотрим это подробней. У нас получается, что в системе в мире $s_1$ выполнится только формула $\need0$, поскольку нет выходящих из $s_1$ миров, тогда импликация для истинности необходимости выполняется(см. истинности модальностей). Для $s_2$ выполнится $\may\need0\Rightarrow$ на $s$ истинно $\vp$.

Рассмотрим для $t\!:$

$\mM',t\vD\vp\Leftrightarrow\begin{cases}\mM',t_1\vD\need0$ или $\mM',t_1\vD\may\need0\\
\mM',t_2\vD\need0$ или $\mM',t_2\vD\may\need0\\
\mM',t_3\vD\need0$ или $\mM',t_3\vD\may\need0\end{cases}$

В $t_1$ и $t_3$ всё выполнится, но в $t_2$ - нет $\Rightarrow$ внешняя необходимость не выполнится для мира $t\Rightarrow s\not\approx t$. 

Т.е. нам и не потребовалось знать, какие формулы истинны на $s$ или $t$, мы просто взяли т.л. формулу и через неё показали, что из атомарной эквивалетности не следует модальная эквивалентность.

\primerT 2

Построим модель с миром $p\!:$

\begin{wrapfigure}[5]{l}[-2cm]{0.1\textwidth}
\begin{tikzpicture}

\draw[latex-,color=black, very thick](0,-1) arc (-85:265:0.5);
\draw[-latex,color=black, very thick](0, -1) -- (0, -3);

\draw[fill=black, color=black, very thick](0, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -3) circle (0.05);

\node[scale=1.1] at (0.3,-1.4) {$p$};

\node[scale=1.1] at (0, -3.5) {$\mM''$};
\end{tikzpicture}
\end{wrapfigure}
\leavevmode\\
Здесь $s\equiv p$ и $\mM'',p\vD\vp$. Выходит, несмотря на различные модели $\mM$ и $\mM''$, миры модально и атомарно эквивалентны. Так же мы можем сказать, что модели бисимулируют, т.е. у них есть \textit{эквивалентные} миры.

Осталось записать определение \textit{бисимуляции}.\\

\opr 

Пусть даны модели $\mM=\langle W,R,V\rangle$ и $\mM'=\langle W',R',V'\rangle$. Отношение \\$E\subseteq W\times W'$ называется \textbf{бисимуляцией между моделями $\mM$ и $\mM'$},\\$E\neq\varnothing$, если для $\forall w\in W\;\forall w'\in W'\!\!:(w,w')\in E$ выполняется только тогда, когда выполняются:

1) $w\equiv w'$ - \textit{атомарная гармония};

2) "\textit{Зиг}":

\qquad$\forall v\in W\!\!:((w,v)\in R\Rightarrow\exists v'\in W'\!\!:((w',v')\in R'$ и $(v,v')\in E))$;

3) "\textit{Заг}":

\qquad$\forall v'\in W'\!\!:((w',v')\in R'\Rightarrow\exists v\in W\!\!:((w,v)\in R$ и $(v,v')\in E))$.

Здесь так же важно учесть, что "$\Rightarrow$"{} \underline{сопоставима с импликацией}.\\

Т.е. что эти условия значат? Если для каждого мира $w$ из $W$ найдётся такой мир $w'$ из $W'$, с которым он атомарно эквивалентен(\textit{атомарная гармония}) и при этом для всех миров, выходящих из $w$, найдутся выходящие миры из $w'$, с которыми они будут совпадать(\textit{Зиг}), а так же для всех миров, выходящих из $w'$, найдутся выходящие миры из $w$, с которыми они будут совпадать(\textit{Заг}).\\ 

\primer

Давайте рассмотрим бисимуляцию на нашем предыдущем примере:

\begin{wrapfigure}[7]{l}{0.35\textwidth}
\begin{tikzpicture}

\draw[latex-,color=black, very thick](0,-1.5) arc (-85:265:0.5);
\draw[-latex,color=black, very thick](0, -1.5) -- (0, -3.5);

\draw[fill=black, color=black, very thick](0, -1.5) circle (0.05);
\draw[fill=black, color=black, very thick](0, -3.5) circle (0.05);

\node[scale=1.1] at (0.3,-1.9) {$p$};
\node[scale=1.1] at (0.4,-3.4) {$p'$};

\draw[latex-,color=black, very thick](3, 0) -- (3, -2);
\draw[latex-,color=black, very thick](3,-2) to[bend left=50] (5, -2);
\draw[-latex,color=black, very thick](3,-2) to[bend right=50] (5, -2);
\draw[-latex,color=black, very thick](5,-2) -- (5, -4);

\draw[fill=black, color=black, very thick](3, 0) circle (0.05);
\draw[fill=black, color=black, very thick](3, -2) circle (0.05);
\draw[fill=black, color=black, very thick](5, -2) circle (0.05);
\draw[fill=black, color=black, very thick](5, -4) circle (0.05);

\node[scale=1.1] at (5.3,-2) {$s$};
\node[scale=1.1] at (5.45,-4) {$s_1$};
\node[scale=1.1] at (2.55,-2) {$s_2$};
\node[scale=1.1] at (2.55,0) {$s_3$};

\node[scale=1.1] at (4, -4.8) {$\mM$};
\node[scale=1.1] at (0.2, -4.8) {$\mM''$};

%bisimulation
\draw[color=black, dashed, very thick](0,-1.5) to[bend left=-95] (3, -2);
\draw[color=black, dashed, very thick](0,-1.5) to[bend left=50] (5, -2);

\draw[color=black, dashed, very thick](0,-3.5) .. controls (0,-4.67) and (4.5,-4).. (5, -4);

\draw[color=black, dashed, very thick](3,0) .. controls (2.25,-1.6) and (0.6,-1.6).. (0, -3.5);

\end{tikzpicture}
\end{wrapfigure}
\leavevmode\\
Здесь пунктиром как раз выступает $E$. Рассмотрим миры $p,s_2$ и $s$. О чём говорит бисимуляция? Если из $p$ выходит "тупиковый"{} мир, то и из $s2$ и $s$ \underline{тоже должны выходить тупиковые}. Выходит, что $p'$ "совпадает"{} с $s_1$ и $s_3$. Сами же миры $p,s$ и $s_2$ совпадают, т.к. $s$ и $s_2$ "схлопываются"{} в один мир, поскольку существуют отношения $(p,s_2)$ и $(p,s)$. Так же $s_3$ и $s_1$ "схлопываются"{} в $p'$. Отсюда выходит, что модели $\mM$ и $\mM''$ бисимулируют.\\

\opr

Будем говорить, что модели \textbf{бисимулируют}, т.е. $\mM\rightleftarrows\mM'\Leftrightarrow\exists$ бисимуляция $E$.

Структура мира $w$ бисимулирует со структурой мира $w'$, т.е.\\ $(\mM,w)\rightleftarrows(\mM',w')\Leftrightarrow\exists$ бисимуляция $E\!:(w,w')\in E$.\\
\newpage
\teor

Пусть есть модели $\mM=\langle W,R,V\rangle$ и $\mM'=\langle W',R',V'\rangle,\;w\in W,\;w'\in W'$. 
Тогда $(\mM,w)\rightleftarrows(\mM',w')\Rightarrow(\mM,w)\approx(\mM',w')$.

\dok

Докажем индукцией по длине формулы $\vp$:

1) $\vp=A_i\in\sg\!:(\mM,w)\rightleftarrows(\mM',w')\Rightarrow w\equiv w'\Rightarrow\mM,w\vD A_i\Leftrightarrow\newline\Leftrightarrow\mM',w'\vD A_i\Rightarrow(\mM,w)\approx(\mM',w')$;

2) $\vp=\vp_1\ampersand\vp_2\!:$ По инд. предположению $\begin{rcases}\mM,w\vD\vp_1\Leftrightarrow\mM',w'\vD\vp_1\\\mM,w\vD\vp_2\Leftrightarrow\mM',w'\vD\vp_2\end{rcases}\Rightarrow\newline\newline\Rightarrow\mM,w\vD\vp_1\ampersand\vp_2\Leftrightarrow\mM',w'\vD\vp_1\ampersand\vp_2\Rightarrow(\mM,w)\approx(\mM',w')$;\\

Таким же образом доказывается и для $\vee,\to,\lnot..$.

6) $\vp=\may\vp_1\!\!:$

Пусть $\mM,w\vD\may\vp_1\Leftrightarrow\exists v\in W\!\!:((w,v)\in R$ и $\mM,v\vD\vp_1)\Rightarrow\newline\Rightarrow\exists v'\in W'\!\!:((w',v')\in R'$ и $(v,v')\in E)\xRightarrow{\text{инд.пр.}}\exists v'\in W'\!\!:((w',v')\in R$ и $\mM',v'\vD\vp_1\Leftrightarrow\mM',w'\vD\may\vp_1\Rightarrow(\mM,w)\approx(\mM',w')$;

7) $\vp=\need\vp_1\!\!:$

Пусть $\mM,w\vD\need\vp_1\Leftrightarrow\mM,w\vD\lnot\may\lnot\vp_1\Leftrightarrow\mM,w\nvDash\may\lnot\vp_1\xLeftrightarrow{6)\text{ пункт}}\mM',w'\nvDash\;\nvDash\may\lnot\vp_1\Leftrightarrow\mM',w'\vD\lnot\may\lnot\vp_1\Leftrightarrow\mM',w'\vD\need\vp_1\Rightarrow(\mM,w)\approx(\mM',w')$.

Теорема доказана.\\

\teor

Пусть модели $\mM=\langle W,R,V\rangle$ и $\mM'=\langle W',R',V'\rangle$ - конечные, и \\$w\in W,\;w'\in W'$.

Тогда $(\mM,w)\rightleftarrows(\mM',w')\Leftrightarrow(\mM,w)\approx(\mM',w')$.

\dok

$\rightdok$ Предыдущая теорема.

$\leftdok$ Пусть $(\mM,w)\approx(\mM',w')$. Зададим бисимуляцию $E\subseteq W\times W'$.

Покажем, что $(w,w')\in E\Leftarrow(\mM,w)\approx(\mM',w')$.

Проверим выполнимость условий:

\boxed{1) \text{ Атомарная гармония:}}

Тогда $\mM,w\vD A_i\Leftrightarrow\mM',w'\vD A_i$.

\boxed{2)\;"\textit{Зиг}"{}:}

Рассмотрим два случая:

\underline{Сл.1.} Пусть $w$ - тупиковый мир, т.е. $\lnot\exists v\in W\!\!:(w,v)\in R$. Импликация в условии "\textit{Зиг}"{} выполняется $\Rightarrow$ "\textit{Зиг}"{} выполняется.

\underline{Сл.2.} Пусть $w$ - не тупиковый и $\exists v\in W\!\!:(w,v)\in R$. Докажем от противного и предположим, что "\textit{Зиг}"{} не выполняется.

Тогда выходит по условию, что $\forall v'\in W'\!\!:(w',v')\in R'\!\!:(v,v')\notin E$.

Рассмотрим множество $S'=\{v'\in W'\;|\;(w',v')\in R'\}$. Покажем, что данное множество не пустое.

Поскольку мы взяли нетупиковый мир $w$, то у него точно есть выход в другой мир, и будет выполняться $\mM,w\vD\may1$. А т.к. по условию\\ $(\mM,w)\approx(\mM',w')\Rightarrow\mM',w'\vD\may1\Rightarrow w'$ - не тупиковый $\Rightarrow S'\neq\varnothing$. 

С другой стороны, $S'$ - конечно. Тогда $S'=\{v'_1,\lot {v'} 2 n\}$. Поскольку "\textit{Зиг}"{} не выполняется $\Rightarrow\forall v'_i\in S'\!\!:(v,v'_i)\notin E\Rightarrow(\mM,v)\not\approx(\mM',v'_i)\Rightarrow\newline\Rightarrow\exists\vp_i\!:\mM,v\vD\vp_i$ и $\mM',v'_i\nvDash\vp_i$.

Т.е. у нас для каждого такого мира есть своя формула, что ломает модальную эквивалентность. Тогда давайте рассмотрим формулу $\vp=\vp_1\ampersand\dots\ampersand\vp_n$. Тогда $\mM,w\vD\may\vp$ и $\mM',w'\nvDash\may\vp\Rightarrow(\mM,w)\not\approx(\mM',w')$. Получили противоречие с начальными условиями $\Rightarrow$ "\textit{Зиг}"{} выполняется.

\boxed{3)\;"\textit{Заг}"{}:} Аналогичное доказательство с "\textit{Зиг}"{}.

Теорема доказана.\\

Стоит отметить, что утверждение теоремы верно и для бесконечных моделей, если в этих моделях для каждого содержащегося в них мира \underline{не больше} \underline{конечного числа} последующих из них миров.\\

\msubsection{Бисимулятивное сокращение}

\opr 

Пусть $\mM=\langle W,R,V\rangle,w,v\in W$. Тогда миры \textbf{эквивалентны}, т.е. \\$w\sim v\Leftrightarrow(\mM,w)\approx(\mM,v)$. Здесь $\sim$ - отношение эквивалентности.\\

\opr 

Определим \textbf{множество классов эквивалентности} \\\centr{$W_\sim=\{[w]_\sim\;|\;w\in W\}$.}

Модель $\mM_\sim=\langle W_\sim,R_\sim,V_\sim\rangle$ называется \textbf{бисимулятивным сокращением модели $\mM$}, если:

1) $([w]_\sim,[v]_\sim)\in R_\sim\Leftrightarrow\exists w'\in[w]_\sim\;\exists v'\in[v]_\sim\!:(w',v')\in R$;

2) $V_\sim(A)=\{[w]_\sim\in W_\sim\;|\;w\in V(A)\}$.\\

\teor 

Пусть $\mM=\langle W,R,V\rangle$ - конечная.

Тогда $\mM\rightleftarrows\mM_\sim$.

\dok

Зададим бисимуляцию $E\subseteq W\times W_\sim\!:\forall w\in W\!\!:(w,[w]_\sim)\in E$.

Проверим выполнимость условий бисимуляции:

\boxed{1) \text{ Атомарная гармония:}}

$\mM,w\vD A\Leftrightarrow w\in V(A)\Leftrightarrow[w]_\sim\in V_\sim(A)\Leftrightarrow\mM_\sim,[w]_\sim\vD A$.

\boxed{2)\;"\textit{Зиг}"{}:}

Рассмотрим два случая:

\underline{Сл.1.} Пусть $w$ - тупиковый мир. Очевидно.

\underline{Сл.2.} Пусть $w$ - не тупиковый. Тогда $\exists v\in W\!\!:(w,v)\in R$. Но $w\in[w]_\sim$ и $v\in[v]_\sim\Rightarrow([w]_\sim,[v]_\sim)\in R_\sim$.

По определению отношения $E$ выполняется $(v,[v]_\sim)\Rightarrow$ "\textit{Зиг}"{} выполняется.

\boxed{3)\;"\textit{Заг}"{}:} Аналогичное доказательство с "\textit{Зиг}"{}.

Теорема доказана.\\

Для чего нам нужно бисимулятивное сокращение? 

\primer

\begin{center}
\begin{tikzpicture}

\node[scale=1.1,rotate=-45] at (-3.25,-0.7) {$\dots$};
\draw[latex-,color=black, very thick](-3, -1) -- (-2, -2);
\draw[latex-,color=black, very thick](-2, -2) -- (-1, -3);
\draw[latex-,color=black, very thick](-1, -3) -- (0, -4);

\node[scale=1.1] at (-1.2,-3.4) {$p$};
\node[scale=1.1] at (-2.2,-2.4) {$p$};
\node[scale=1.1] at (-3.2,-1.4) {$p$};

\node[scale=1.1,rotate=45] at (4.3,0.35) {$\dots$};
\draw[latex-,color=black, very thick](4, 0) -- (3, -1);
\draw[latex-,color=black, very thick](3, -1) -- (2, -2);
\draw[latex-,color=black, very thick](2, -2) -- (1, -3);
\draw[latex-,color=black, very thick](1, -3) -- (0, -4);

\node[scale=1.1] at (0,-4.3) {$s$};
\node[scale=1.1] at (1.2,-3.4) {$t$};
\node[scale=1.1] at (2.2,-2.4) {$s$};
\node[scale=1.1] at (3.2,-1.4) {$t$};
\node[scale=1.1] at (4.2,-0.4) {$s$};

\draw[-latex,color=black, very thick](5, -2) -- (7, -2);

\draw[fill=black, color=black, very thick](-2, -2) circle (0.05);
\draw[fill=black, color=black, very thick](-1, -3) circle (0.05);
\draw[fill=black, color=black, very thick](0, -4) circle (0.05);

\draw[fill=black, color=black, very thick](3, -1) circle (0.05);
\draw[fill=black, color=black, very thick](2, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -3) circle (0.05);

%new model
\draw[latex-,color=black, very thick](9, -3) -- (10, -4);
\draw[latex-,color=black, very thick](9.05,-3) arc (-82:275:0.5);

\draw[fill=black, color=black, very thick](9, -3) circle (0.05);

\draw[latex-,color=black, very thick](11, -3) -- (10, -4);
\draw[latex-,color=black, very thick](12, -2) -- (11, -3);

\draw[-latex,color=black, very thick](12,-2) to[bend right=90,bend left=-120,in looseness=1.5,out looseness=1.5] (11, -3);

\draw[fill=black, color=black, very thick](11, -3) circle (0.05);
\draw[fill=black, color=black, very thick](9, -3) circle (0.05);
\draw[fill=black, color=black, very thick](12, -2) circle (0.05);

\node[scale=1.1] at (10,-4.3) {$s$};
\node[scale=1.1] at (11.2,-3.4) {$t$};
\node[scale=1.1] at (12.2,-2.4) {$s'$};

\node[scale=1.1] at (8.8,-3.4) {$p$};

\node[scale=1.1] at (10.2,-5.4) {$\mM_\sim$};
\node[scale=1.1] at (0,-5.4) {$\mM$};
\end{tikzpicture}
\end{center}
\leavevmode

Рассмотрим модель $\mM$. Мы видим, что миры $s$ и $t$ чередуются и каждый мир $s$ модально эквивалентен следующему $s$. Это же будет выполняться и с мирами $p$ и $t$.

Здесь видно, что мы можем сократить нашу модель до модели $\mM_\sim$ - нашего бисимулятивного сокращения. Здесь из $t$ мы не можем вернуться $s$, т.к. $s'$ и $s$ не являются модально эквивалентными, т.к. из $s$ можно попасть в $p$, а из $s'$ нельзя. Здесь классов эквивалентностей будет 4: класс эквивалентности $p$, класс $s$, класс $s'$ и класс $t$.

Данное сокращение упрощает работу с моделью, что как раз показал нам пример.\\

\msubsection{Модельные конструкции}

\opr

Пусть даны модели $\mM=\langle W,R,V\rangle$ и $\mM'=\langle W',R',V'\rangle$.\\Тогда $\mM,\mM'$ - \textbf{непересекающиеся}, если $W\cap W'=\varnothing$.\\

\opr 

Пусть есть множество моделей $\mM_i=\langle W_i,R_i,V_i\rangle,\;i\in\ki$.\\ Тогда модель $\mM=\langle W,R,V\rangle$ называется \textbf{дизъюнктным объединением}, если $\mM=\underset{i\in\ki}{\bigs\biguplus}\mM_i$, где:

1) $W=\underset{i\in\ki}{\bigs\bigvee}W_i$;

2) $R=\underset{i\in\ki}{\bigs\bigvee}R_i$;

3) $V(A)=\underset{i\in\ki}{\bigs\bigvee}V_i(A),\;\forall A\in\sg$.\\

\opr 

Пусть дана модель $\mM=\langle W,R,V\rangle$ и есть подмножество $W'\subseteq W$. Тогда модель $\mM'=\langle W',R',V'\rangle$ называется \textbf{сужением модели $\mM$}, где:

1) $R'=R\cap(W'\times W')$;

2) $V'(A)=V(A)\cap W'$.\\

\newpage
\primer

\begin{center}
\scalebox{1.5}
{
\begin{tikzpicture}

\draw[-latex,color=black, very thick](-1, -1) -- (-1, 0);
\draw[-latex,color=black, very thick](-1, 0) -- (1, 0);
\draw[-latex,color=black, very thick](-1, -1) -- (1, -1);
\draw[-latex,color=black, very thick](0, -2) -- (-1, -1);
\draw[-latex,color=black, very thick](1, -1) -- (0, -2);
\draw[-latex,color=black, very thick](1, -1) -- (2.3, -1.4);

\draw[fill=black, color=black, very thick](-1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](-1, 0) circle (0.05);
\draw[fill=black, color=black, very thick](-1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -1) circle (0.05);

\draw[color=black, dashed, very thick](0,-0.5) circle [x radius=1.5cm, y radius=10mm];

\node[scale=1] at (1,-0.7) {$w$};
\node[scale=1] at (0,-2.3) {$v$};
\node[scale=1] at (2.45,-1.5) {$u$};

\end{tikzpicture}
}
\end{center}
\leavevmode

Рассмотрим нашу модель и обведём наше подмножество $W'$. И получается, что модель внутри нашего кружка и будет являться \textit{сужением}, миры $v$ и $u$ не войдут в новую модель.

Если нам дано $n$ миров, то $2^n$ различных сужений мы сможем построить.\\

\opr 

Сужение модели является \textbf{сгенерированной подмоделью}, если оно замкнуто относительно отношения достижимости, т.е. если $R'$ замкнуто.

Замкнутость говорит о том, что если какой-то мир принадлежит сужению, то \underline{и из него последующий мир так же должен быть в сужении}.\\

Т.е. наш пример сужения выше не является сгенерированной подмоделью, ибо замкнутость нарушает мир $w$.\\

\opr

Пусть $\mM'$ - сгенерированная подмодель $\mM$. Рассмотрим подмножество $S\subseteq W'$, удолетворяющее следующим условиям:

$\forall w'\in W'\;\exists s\in S\;\exists\lot v 1 n\in W'\!\!:(s,v_1)\in R',(v_1,v_2)\in R',\dots\dots\newline\dots,(v_{n-1},v_n)\in R',(v_n,w')\in R'$.

Если $S$ выполняет это условие, то оно называется \textbf{порождающим} и модель $\mM'$ \textbf{порождается} множеством миров $S$.

Т.е. $S$ - это множество миров, из которых мы можем попасть в любой другой мир.

\primer

\begin{center}
\scalebox{1.5}
{
\begin{tikzpicture}

\draw[-latex,color=black, very thick](0, 0) -- (0.5, 0.5);
\draw[-latex,color=black, very thick](-1, -1) -- (0, 0);
\draw[-latex,color=black, very thick](-1, -1) -- (0, -2);
\draw[-latex,color=black, very thick](0, 0) -- (0, -2);
\draw[-latex,color=black, very thick](0, -2) -- (1, -1);
\draw[-latex,color=black, very thick](0, 0) -- (1, -1);

\draw[fill=black, color=black, very thick](0, 0) circle (0.05);
\draw[fill=black, color=black, very thick](-1, -1) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -1) circle (0.05);

\draw[color=black, dashed, very thick](0.3,-0.8) circle [x radius=10mm, y radius=15mm];

\node[scale=0.8] at (0.3,0) {$s$};
\end{tikzpicture}
}
\end{center}
\leavevmode

Здесь $\mM'$ в круге, а \textit{порождающим множеством} будет мир $s$.\\

\opr

Пусть даны модели $\mM=\langle W,R,V\rangle$ и $\mM'=\langle W',R',V'\rangle$. Тогда отображение $f\!\!:W\to W'$ называется \textbf{ограниченным морфизмом}, если выполняются следующие условия:

1) \textit{Атомарная гармония}: $w\in V(A)\Leftrightarrow f(w)\in V'(A)$;

2) \textit{Морфизм}:
\\\centr{$\forall w,v\in W\!\!:((w,v)\in R\Rightarrow(f(w),f(v))\in R')$;}

3) "\textit{Заг}":
\\\centr{$\forall w\in W\;\forall v'\in W'\!\!:(f(w),v')\in R'\Rightarrow\exists v\in W\!\!:(f(v)=v'\text{ и }(w,v)\in R)$.}\\

Условие "\textit{Зиг}"{} просто перешёл в "\textit{Морфизм}"{}. Здесь так же важно учесть, что "$\Rightarrow$"{} \underline{сопоставима с импликацией}.\\

Данное выше определение очень сильно похоже на бисимуляцию. В чём различие? Если в бисимуляции могло так сложиться, что один мир переходит в два других мира на иной модели, а те два мира с другой модели в один мир(см. пример после 38.2.), то ограниченный морфизм не позволит из одного мира попасть в два, только в один мир. Т.е. получается, что ограниченный морфизм - это бисимуляция с \textit{навешенной} функциональностью и для любого мира существует только \underline{единственный} образ в иной модели. Т.е. $f$ - отношение бисимуляции, обладающее функциональностью.\\

\opr 

Если $f$ является \textit{сюрьекцией}, то $\mM'$ - \textbf{ОМ-образ модели $\mM$} (модель $\mM'$ из прошлого определения).\\

\teor

Для $\forall\vp$ выполняется:

1) Пусть $\mM=\underset{i\in\ki}{\bigs\biguplus}\mM_i$. Тогда для $\forall w\in W_i\;\forall i\in\ki\!\!:\mM,w\vD\vp\Leftrightarrow\mM_i,w\vD\vp$;

2) Пусть $\mM'$ - сгенерированная подмодель $\mM$.\\Тогда для $\forall w\in W'\!\!:\mM,w\vD\vp\Leftrightarrow\mM',w\vD\vp$;

3) Если $\mM'$ - \textbf{ОМ}-образ $\mM$. Тогда для $\forall w\in W'\!\!:\mM,w\vD\vp\Leftrightarrow\mM',w\vD\vp$.\\

\msubsection{Разрешимость классов структур Крипке}

Вспомним, что структура Крипке - это 

$F=(W,R)$ - пара из множества миров и отношения достижимости.

Если $F\vD\vp$, то $\vp$ истинная в любой модели с данной структурой.\\

В данном параграфе мы будем рассматривать $K=\{F_i\;|\;i\in \ki\}$ - \textbf{класс структур Крипке}.\\\\

\predl

$K\vD\vp\Leftrightarrow\forall F_i\in K\!\!:F_i\vD\vp$.\\

\opr 

Класс структур $K$ является \textbf{разрешимым}, если
\\\centr{$\exists\vp\forall F\!\!: F\vD\vp\Leftrightarrow F\in K$.}\\

\teor 

Класс всех структур Крипке $K_{frame}$ разрешим.

\dok

Возьмём формулу $\xi=\need(\vp\to\psi)\to(\need\vp\to\need\psi)$. Данная формула является т.и. $\Rightarrow$ она истинна везде $\Rightarrow$ класс всех структур Крипке разрешим.

Теорема доказана.\\

Далее мы будем искать классы, на которых истинна некоторая известная нам формула.\\

\teor

Пусть некоторая формула $\vp$ - выполнима и опровержима. Тогда:

1) $\need\vp\to\vp$ \textbf{определяет класс} рефлексивных структур
\\\centr{$K_1=\{F=(W,R)\;|\;\forall w\in W,(w,w)\in R\}$}

2) $\vp\to\need\vp$ определяет класс структур изолированных рефлексивных миров
\qquad\qquad\qquad\;$K_2=\{F\;|\;\forall w\forall v\!:(w,v)\in R\Rightarrow w=v\}$

3) $\need0$ определяет класс структур изолированных иррефлексивных миров
\\\centr{$K_3=\{F\;|\;\forall w\forall v\!:(w,v)\notin R\}$}

4) $\vp\to\need\may\vp$ определяет класс симметричных структур
\\\centr{$K_4=\{F\;|\;\forall w\forall v\!:(w,v)\in R\Rightarrow (v,w)\in R\}$}

5) $\need\vp\to\need\need\vp$ определяет класс транзитивных структур 
\\\centr{$K_5=\{F\;|\;\forall w\forall v\forall y\!:(w,v)\in R,(v,y)\in R\Rightarrow(w,y)\in R\}$}

6) $\may\vp\to\need\may\vp$ определяет класс структур, у которых отношение достижимости $R$ - отношение эквивалентности.

\dok

1) Пусть $F\vD(\need\vp\to\vp)\Leftrightarrow F\in K,F=(W,R)$.

$\rightdok$ Докажем от противного. Пусть $F\vD(\need\vp\to\vp)$ и $F\notin K_1\Rightarrow\newline\Rightarrow\exists w\in W\!\!:(w,w)\notin R$.

Зададим модель $\mM=(W,R,V)$ следующим образом: $\mM,w\nvDash\vp$ и\\$\mM,w\vD\need\vp\Rightarrow\mM,w\nvDash(\need\vp\to\vp)$.

\begin{wrapfigure}[6]{l}{0.25\textwidth}
\begin{tikzpicture}
\draw[-latex,color=black, very thick](0, -2) -- (0, 0);
\draw[-latex,color=black, very thick](0, -2) -- (1, 0.5);
\draw[-latex,color=black, very thick](0, -2) -- (2, 1);
\draw[-latex,color=black, very thick](0, -2) -- (3, 1.5);

\draw[fill=black, color=black, very thick](0, -2) circle (0.05);

\node[scale=1.1] at (0,-2.3) {$w(\lnot\vp)$};

\node[scale=1.1] at (0,0.3) {$\vp$};
\node[scale=1.1] at (1,0.8) {$\vp$};
\node[scale=1.1] at (2,1.3) {$\vp$};
\node[scale=1.1] at (3,1.8) {$\vp$};
\end{tikzpicture}
\end{wrapfigure}
\leavevmode\\
Объясним этот шаг: здесь $w$ иррефлексивен и будет выглядеть следующим образом. Поэтому у нас получается, что в мире $w$ ложна формула $\need\vp\to\vp$, откуда мы получаем противоречие с начальными условиями.\\

$\leftdok$ Докажем вновь от противного. 

Пусть $F\in K_1$ и $F\nvDash(\need\vp\to\vp)\Rightarrow\forall w\in W\!\!:F,w\vD\need\vp$ и $F,w\nvDash\vp$.

Из того, что $F,w\vD\need\vp$ и $F\in K_1\Rightarrow(w,w)\in R\Rightarrow F,w\vD\vp$. Получаем противоречие.

Другие пункты будут разобраны на семинаре...

Теорема доказана.\\
\newpage
\msubsection{Неразрешимость классов структур Крипке}

Не все классы разрешимые. В данном параграфе как раз разберём их.\\

\opr 

1) Пусть $\{ F_i\;|\;i\in\ki\}$ - семейство непересекающихся структур Крипке. Тогда $\underset{i\in\ki}{\bigs\biguplus}F_i$ - \textbf{дизъюнктное объединение}; 

Данное объединение дано для структур, в прошлый раз давали объединение именно для моделей.

2) Пусть даны структуры $F=\langle W,R\rangle,\;F'=\langle W',R'\rangle$. Будем говорить, что $F'$ - \textbf{подструктура $F$}, т.е. $F'\sqsubseteq F$, если каждая модель структуры \\$F'$ - сгенерированная подмодель некоторой модели структуры $F$;

3) Пусть даны структуры $F=\langle W,R\rangle,\;F'=\langle W',R'\rangle$. Будем говорить, что $F'$ - \textbf{ОМ-образ структуры $F$}, если каждая модель структуры \\$F'$ - \textbf{ОМ}-образ некоторой модели структуры $F$.\\

\predl

Для любой формулы $\vp$ справедливы следующие условия:

1) Пусть $\{ F_i\;|\;i\in\ki\}$ - семейство непересекающихся структур Крипке. Тогда $\forall i\in\ki\!\!:F_i\vD\vp\Rightarrow\underset{i\in\ki}{\bigs\biguplus}F_i\vD\vp$;

2) Пусть $F'\sqsubseteq F$. Тогда $F'\vD\vp\Rightarrow F\vD\vp$;

3) Пусть $F'$ - \textbf{ОМ}-образ $F$. Тогда $F'\vD\vp\Rightarrow F\vD\vp$.\\

\sled

Если класс структур Крипке не замкнут относительно дизъюнктного объединения или выделения подструктуры или формирования \textbf{ОМ}-образа, то он \textbf{неразрешим}.

Это следствие как раз нам и нужно для определения неразрешимости. Что значит неразрешимость? Это значит, что не существует формулы, что определяла бы эти классы.\\

\sled

Следующие классы структур Крипке неразрешимы:

1) Класс линейных структур;

2) Класс антисимметричных структур;

3) Класс иррефлексивных структур;

4) Класс не рефлексивных и не иррефлексивных структур.

\dok

а) \begin{wrapfigure}[6]{l}{0.35\textwidth}
\begin{tikzpicture}

\draw[-latex,color=black, very thick](0, -4) -- (1, -3);
\draw[-latex,color=black, very thick](1, -3) -- (2, -2);
\draw[-latex,color=black, very thick](2, -2) -- (3, -1);
\draw[-latex,color=black, very thick](3, -1) -- (4, 0);

\draw[fill=black, color=black, very thick](0, -4) circle (0.05);
\draw[fill=black, color=black, very thick](1, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -1) circle (0.05);

\node[scale=1.1] at (0,-4.5) {$F_1$};

\draw[-latex,color=black, very thick](2, -4) -- (3, -3);
\draw[-latex,color=black, very thick](3, -3) -- (4, -2);
\draw[-latex,color=black, very thick](4, -2) -- (5, -1);
\draw[-latex,color=black, very thick](5, -1) -- (6, 0);

\draw[fill=black, color=black, very thick](2, -4) circle (0.05);
\draw[fill=black, color=black, very thick](3, -3) circle (0.05);
\draw[fill=black, color=black, very thick](4, -2) circle (0.05);
\draw[fill=black, color=black, very thick](5, -1) circle (0.05);

\node[scale=1.1] at (2,-4.5) {$F_2$};
\end{tikzpicture}
\end{wrapfigure}\leavevmode\\
Возьмём их дизъюнктное объединение $F_1\biguplus F_2$. Получается ли в итоге линейная структура? Нет. Класс линейных структур не замкнут относительно дизъюнктного объединения. У нас говорится, что если формула истинна на некоторой структуре, то она истинна и на дизъюнктном объединении. Но из-за этого свойства нарушается и линейность, т.е. дизъюнктное объединение нелинейное.

\begin{wrapfigure}[6]{l}{0.42\textwidth}
\begin{tikzpicture}
\node[scale=1] at (0,0) {\text{б)}};

\draw[-latex,color=black, very thick](0, -4) -- (1, -3);
\draw[-latex,color=black, very thick](1, -3) -- (2, -2);
\draw[-latex,color=black, very thick](2, -2) -- (3, -1);
\draw[-latex,color=black, very thick](3, -1) -- (4, 0);

\draw[fill=black, color=black, very thick](0, -4) circle (0.05);
\draw[fill=black, color=black, very thick](1, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, 0)  circle (0.05);

\node[scale=1.1] at (0,-4.5) {$s$};
\node[scale=1.1] at (1,-3.5) {$t$};
\node[scale=1.1] at (2,-2.5) {$s$};
\node[scale=1.1] at (3,-1.5) {$t$};
\node[scale=1.1] at (3.9,-0.5) {$s$};
\node[scale=1.1,rotate=45] at (4.4,0.45) {$\dots$};
\node[scale=1.1,rotate=45] at (-0.3,-4.35) {$\dots$};

\node[scale=1.1] at (0,-5.5) {$F_1$};

%Second structure

\draw[fill=black, color=black, very thick](5, -4) circle (0.05);
\draw[fill=black, color=black, very thick](7, -2) circle (0.05);

\draw[-latex,color=black, very thick](5,-4) to[bend right=0,bend left=-40] (7, -2);
\draw[-latex,color=black, very thick](7, -2) to[bend right=0,bend left=-40] (5,-4);

\node[scale=1.1] at (5,-4.4) {$s$};
\node[scale=1.1] at (7.1,-1.5) {$t$};

\node[scale=1.1] at (5,-5.5) {$F_2$};

%Lines

\draw[dashed, color=black, very thick](0,-4)  to (5, -4);
\draw[dashed, color=black, very thick](1, -3) to (7, -2);
\draw[dashed, color=black, very thick](2, -2) to (5, -4);
\draw[dashed, color=black, very thick](3, -1) to (7, -2);
\draw[dashed, color=black, very thick](4, 0)  to (5, -4);
\end{tikzpicture}
\end{wrapfigure}\leavevmode\\
Здесь мы видим, что $F_2$ есть \textbf{ОМ}-образ $F_1$, но она уже не является антисимметричной структурой $\Rightarrow$ класс антисимметричных структур не замкнут относительно формирования \textbf{ОМ}-образа.

в) \vspace*{-0.55cm}\begin{wrapfigure}[8]{l}{0.42\textwidth}
\begin{tikzpicture}

\draw[-latex,color=black, very thick](0, -4) -- (1, -3);
\draw[-latex,color=black, very thick](1, -3) -- (2, -2);
\draw[-latex,color=black, very thick](2, -2) -- (3, -1);
\draw[-latex,color=black, very thick](3, -1) -- (4, 0);

\draw[fill=black, color=black, very thick](0, -4) circle (0.05);
\draw[fill=black, color=black, very thick](1, -3) circle (0.05);
\draw[fill=black, color=black, very thick](2, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -1) circle (0.05);
\draw[fill=black, color=black, very thick](4, 0)  circle (0.05);

\node[scale=1.1] at (0,-4.5) {$s$};
\node[scale=1.1] at (1,-3.5) {$s$};
\node[scale=1.1] at (2,-2.5) {$s$};
\node[scale=1.1] at (3,-1.5) {$s$};
\node[scale=1.1] at (3.9,-0.5) {$s$};
\node[scale=1.1,rotate=45] at (4.4,0.45) {$\dots$};
\node[scale=1.1,rotate=45] at (-0.3,-4.35) {$\dots$};

\node[scale=1.1] at (0,-5.5) {$F_1$};

%Second structure

\draw[fill=black, color=black, very thick](6, -3) circle (0.05);

\draw[latex-,color=black, very thick](6,-3.08) arc (-170:180:0.5);

\node[scale=1.3] at (5.75,-3.4) {$s$};

\node[scale=1.1] at (6,-5.5) {$F_2$};

%Lines

\draw[dashed, color=black, very thick](0,-4)  to (6, -3);
\draw[dashed, color=black, very thick](1, -3) to (6, -3);
\draw[dashed, color=black, very thick](2, -2) to (6, -3);
\draw[dashed, color=black, very thick](3, -1) to (6, -3);
\draw[dashed, color=black, very thick](4, 0)  to (6, -3);
\end{tikzpicture}
\end{wrapfigure}\leavevmode\\
Здесь та же история с \textbf{ОМ}-образом. $F_2$ есть \textbf{ОМ}-образ $F_1$, но она уже не является иррефлексивной структурой.\newline\leavevmode\newline\leavevmode\newline\newline

г) \vspace*{-1cm}\begin{wrapfigure}[7]{l}{0.28\textwidth}
\hspace*{1cm}  
\begin{tikzpicture}

\draw[fill=black, color=black, very thick](0, -1.3)    circle (0.05);
\draw[fill=black, color=black, very thick](0.5, -0)    circle (0.05);
\draw[fill=black, color=black, very thick](1.5, -0.5)  circle (0.05);

\draw[fill=black, color=black, very thick](1.2, -2) circle (0.05);
\draw[-latex,color=black, very thick, scale=0.7](1.7,-2.8) arc (-185:170:0.5);

\draw[latex-,color=black, very thick, scale=0.7](1.4,-4.5) arc (-82:275:0.5);
\draw[fill=black, color=black, very thick](0.95, -3.15) circle (0.05);

\draw[color=black, dashed, very thick,rotate=-45](2.7,-0.7) circle [x radius=10mm, y radius=14mm];
\draw[color=black, dashed, very thick](1,-1.8) circle [x radius=20mm, y radius=25mm];

\node[scale=1.1] at (1,-4.8) {$F$};
\node[scale=1] at (-0.25,-2.8) {$F'$};
\end{tikzpicture}
\end{wrapfigure}\leavevmode\\
В этом классе есть структуры с иррефлексивными и рефлексивными мирами. Рассмотрим такую структуру $F$. Так давайте выделим подструктуру $F'$, что содержит только рефлексивные миры. \\\\
Тогда $F'\sqsubseteq F$, но $F$ не рефлексивная $\Rightarrow$ класс структур не рефлексивных и не иррефлексивных структур не замкнут относительно выделения подструктуры.

Следствие доказано.\\

\sled

Каждый разрешимый класс структур либо обладает свойством рефлексивности, либо содержится в классе изолированных иррефлексивных миров.\\

\newpage
\msubsection{Стандартная трансляция модальной логики в Л.П.}

В самом начале главы, когда вводили понятие модальной логики, мы обозначили множество пропозициональных переменных \\\centr{$\sg=\{A_1,\lot A 2 n\}$.} 

В этой главе мы научимся транслировать модальную логику в логику предикатов. Для этого введём новую сигнатуру \\\centr{$\sg^*=\{P_1^{(1)},\dots,P_n^{(1)},R^{*(2)}\}$.}\\

\opr 

Будем называть отображение $\st x\!\!:F(\sg)\to F(\sg^*)$ \textbf{стандартной трансляцией в логику предикатов}, если выполняются следющие условия:

1) $\forall A_i\in\sg\!:\st x(A_i)=P_i(x)$;

2) $\st x(1)=1,\;\st x(0)=0$;

3) $\st x(\vp\ampersand\psi)=\st x(\vp)\ampersand\st x(\psi)$;

4) $\st x(\vp\vee\psi)=\st x(\vp)\vee\st x(\psi)$;

5) $\st x(\vp\to\psi)=\st x(\vp)\to\st x(\psi)$;

6) $\st x(\lnot\vp)=\lnot\st x(\vp)$;

7) $\st x(\need\vp)=\forall y(R^*(x,y)\to\st y(\vp))$;

8) $\st x(\may\vp)=\exists y(R^*(x,y)\ampersand\st y(\vp))$.

Здесь переменные $x,y$ являеются как раз теми мирами, которыми мы пользовались в модальной логике.\\

\primer

Пусть $\vp=A_1\ampersand\need(A_2\to\may A_3)$. Тогда 

$\st x(\vp)=\st x(A_1\ampersand\need(A_2\to\may A_3))\sim\newline\sim\st x(A_1)\ampersand\st x(\need(A_2\to\may A_3))\sim\newline\sim P_1(x)\ampersand\forall y(R^*(x,y)\to\st y(A_2\to\may A_3))\sim\newline\sim P_1(x)\ampersand\forall y(R^*(x,y)\to(\st y(A_2)\to\st y(\may A_3)))\sim\newline\sim P_1(x)\ampersand\forall y(R^*(x,y)\to(P_2(y)\to\exists z(R^*(y,z)\ampersand P_3(z))))$.

Стоит отметить, что единственной свободной переменной в полученной формуле предикатов будет только $x$, т.е. тот мир, с которого мы транслировали формулу. И что бы мы не делали, мы всё равно получим после трансляции формулу логики предикатов \underline{только с одной свободной переменной}. Так же отметим, что не всякой произвольной формуле логики предикатов мы сможем найти эквивалентную формулу модальной логики.\\

Мы отображаем наши формулы модальной логики в логику предикатов, однако как нам транслировать саму модель Крипке в логику предикатов? Или как её там интерпретировать? Введём следующее определение.\\

\opr 

Модель логики предикатов, \textbf{интерпретирующая модель Крипке}\\$\mM=\langle W,R,V\rangle$, является $\mM^*=\langle W,\sg^*\rangle$, удолетворяющая следующим условиям:

1) $\mM^*\vD R^*(w,v)\Leftrightarrow(w,v)\in R$, где $R^*\in\sg^*$;

2) $\mM^*\vD P_i(w)\Leftrightarrow w\in V(A_i)$, где $A_i\in\sg,\;P_i\in\sg^*$.\\

В конце можно заметить, что модальная логика по сути является \underline{сужением} \underline{логики предикатов}. Модальная логика \textit{шире}, чем логика высказываний(поско-\;\;льку в ЛВ нет модальностей), но она \textit{уже}, чем логика предикатов. Но логика предикатов неразрешима.. Но мы можем выделить малую часть предикатов - модальную логику, где всё разрешимо, но при этом она меньше, но там лучше реализовываются некоторые вещи из предикатов.

Мы рассмотрели только самую простую модальную логику с одной модальностью. Но конечно же можно рассмотреть более сложные логики! Обычно стараются сделать более \textit{объёмные} модальные логики, но при этом разрешимыми.

\msubsection{Модальная логика первого порядка}

Данная логика редко где используется, однако не повредит знать этого \textit{дикого зверя}.

Когда мы рассматривали модальную логику высказываний(прошлые параграфы), там сигнатура состояла только из пропозициональных переменных. В логике первого порядка будет самая обычная сигнатура, а в узлах структур будут лежать обычные модели логики предикатов. У всех моделей будет \underline{одна и та же сигнатура}. Получается более богатая формализация модальной логики.

Мы не будем рассматривать сигнатуры, в которых есть функциональные символы, иначе опять будут пляски с бесконечными множествами, как во 2й главе. Будем рассматривать только предикатную сигнатуру\\\centr{$\sg=\{P_1^{(n_1)}, P_2^{(n_2)},\dots\}$.}

Так же обозначим счётное множество переменных \\\centr{$X=\{x_1,x_2,\dots\}$.}

Поскольку у нас здесь нет констант и функциональных символов, то $X=T(\sg)$, т.е. $X$ равно множеству термов $\sg$.\\

\newpage

\opr 

Определение \textbf{формулы модальной логики первого порядка}:

1) $\forall x_i,x_j\in X\!\!:\;(x_i=x_j)$ - формула;

2) $\forall P^{(n)}\in\sg\;\forall\lot x 1 n\in X\!\!:\;P(\lot x 1 n)$ - формула;

3) Пусть $\vp,\psi$ - формулы, тогда:
\\\centr{$(\vp\ampersand\psi),(\vp\vee\psi),(\vp\to\psi),\lnot\vp,\forall x\vp,\exists x\vp,\need\vp,\may\vp$ - формулы;}

4) Других формул нет.\\

Что же у нас тогда будет моделью в этой логике? Введём следующее определение.\\

\opr

\textbf{Моделью Крипке постоянной предметной области} мы будем называть $\mM=\langle W,R,D,\{V_w\}_{w\in W}\rangle$, где:

1) $W$ - множество миров;

2) $R\subseteq W^2$ - отношение достижимости;

3) $D\neq\varnothing$ - \textbf{область квантификации};

4) $V_w(P^{(n)})\subseteq D^n$ - множество означивания предиката $P^{(n)}$ в мире $w$.\\

Зачем нам вообще это всё? Если в модальной логике высказываний на узлах в мирах задавалась истинность переменных, то теперь здесь задаётся \underline{истинность предикатов}. Как именно? Через означивание $V_w(P^{(n)})$. $D$ - некоторая фиксированная область, с которой мы работаем при определении истинности формул, отсюда понятие модели \textit{с постоянной предметной областью}.

В начале главы мы говорили, что на узлах теперь будут модели логики предикатов. Это будут как раз модели $\mB=\langle D,\sg\rangle$, где истинность предикатов на модели задаётся через $V_w(P^{(n)})$. 

Давайте рассмотрим более подробно истинность формулы на модели модальной логики первого порядка.\\

\opr

Пусть дана модель $\mM=\langle W,R,D,\{V_w\}_{w\in W}\rangle$.

Определим \textbf{истинность формулы на модели Крипке постоянной предметной области}. Пусть нам дано означивание $\gamma\!:X\to D$. Тогда:

1) $\mM,w\vD(x_i=x_j)[\gamma]\Leftrightarrow\gamma(x_i)=\gamma(x_j)$;

2) $\mM,w\vD P(\lot x 1 n)[\gamma]\Leftrightarrow\langle\gamma(x_1),\dots,\gamma(x_n)\rangle\in V_w(P^{(n)})$;

3) $\mM,w\vD(\vp\ampersand\psi)[\gamma]\Leftrightarrow\mM,w\vD\vp[\gamma]$ и $\mM,w\vD\psi[\gamma]$;

4) $\mM,w\vD(\vp\vee\psi)[\gamma]\Leftrightarrow\mM,w\vD\vp[\gamma]$ или $\mM,w\vD\psi[\gamma]$;

5) $\mM,w\vD(\vp\to\psi)[\gamma]\Leftrightarrow\mM,w\nvDash\vp[\gamma]$ или $\mM,w\vD\psi[\gamma]$;

6) $\mM,w\vD\lnot\vp[\gamma]\Leftrightarrow\mM,w\nvDash\vp[\gamma]$;

7) $\mM,w\vD\forall x\vp(x)[\gamma]\Leftrightarrow\forall a\in D\!:\mM,w\vD\vp(a)[\gamma]$;

8) $\mM,w\vD\exists x\vp(x)[\gamma]\Leftrightarrow\exists a\in D\!:\mM,w\vD\vp(a)[\gamma]$;

9) $\mM,w\vD\need\vp[\gamma]\Leftrightarrow\forall v\in W\!\!:((w,v)\in R\Rightarrow\mM,v\vD\vp[\gamma])$;

10) $\mM,w\vD\may\vp[\gamma]\Leftrightarrow\exists v\in W\!\!:((w,v)\in R$ и $\mM,v\vD\vp[\gamma])$.\\

Так же определим следующее:

1) $\mM\vD\vp\Leftrightarrow\forall w\in W\!\!:\mM,w\vD\vp$;

2) $\mM,w\vD\vp\Leftrightarrow\forall \gamma\!:\mM,w\vD\vp[\gamma]$.\\

Данная логика называется на иностранном \textbf{QK}. Давайте рассмотрим её аксиоматику.\\\\

\opr

\textbf{Исчисление QK}=$K+N\!D+B$. 

Её аксиоматика состоит из следующих аксиом:

1) Аксиомы Гильбертовского исчисления высказываний, то есть:

\quad1. $(\varphi\to(\psi\to\varphi))$;

\quad2. $((\varphi\to\psi)\to((\varphi\to(\psi\to\xi))\to(\vp\to\xi)))$;

\quad3. $((\varphi\ampersand\psi)\to\varphi)$;

\quad4. $((\varphi\ampersand\psi)\to\psi)$;

\quad5. $((\varphi\to\psi)\to((\varphi\to\xi)\to(\varphi\to(\psi\ampersand\xi))))$;

\quad6. $(\varphi\to(\varphi\vee\psi))$;

\quad7. $(\psi\to(\varphi\vee\psi))$;

\quad8. $((\varphi\to\xi)\to((\psi\to\xi)\to((\varphi\vee\psi)\to\xi)))$;

\quad9. $((\varphi\to\psi)\to((\varphi\to\lnot\psi)\to\lnot\varphi))$;

\quad10. $(\lnot\lnot\varphi\to\varphi)$.

2) $(K)\;\;\need(\vp\to\psi)\to(\need\vp\to\need\psi)$;

3) $(R)\;\;x=x$;

4) $(S)\;\;(x=y\ampersand[\vp]^z_x)\to[\vp]^z_y$;

5) $(A)\;\;\forall x\vp\to[\vp]^x_y$;

6) $(N\!D)\;\;(x\neq y)\to\need(x\neq y)$;

7) $(B)\;\;\forall x\need\vp\to\need\forall x\vp$ (Баркан).\\

Правила вывода:

$\displaystyle\frac{\vp,\vp\to\psi}{\psi}(modus\; ponens),\qquad\displaystyle\frac{\vp\to[\psi]^x_y}{\vp\to\forall x\vp},\qquad\displaystyle\frac{\vp}{\need\vp}$.

Этих аксиом и правил вывода достаточно, чтобы полностью задать модальную логику первого порядка.

Важно понимать, что аксиомы $K,N\!D,B$ задают \textit{модальность} логике, а все остальные аксиомы, взятые из логик высказывания и предикатов, задают иные свойства обозреваемой логики.\\

\predl

В логике \textbf{QK} доказуема обратная формула Баркан $\need\forall x\vp\to\forall x\need\vp\;(C\!B)$. 

\dok

Строим дерево секвенций:\\
\\\centr{$\displaystyle\frac{\overset{\displaystyle\forall x\vp\to\vp}{\overline{\need(\forall x\vp\to\vp)}},\qquad\need(\forall x\vp\to\vp)\to(\need\forall x\vp\to\need\vp)}{\displaystyle\frac{\need\forall x\vp\to\need\vp}{\need\forall x\vp\to\forall x\need\vp}}$}\\

Отсюда следует, что $\need\forall x\vp\to\forall x\need\vp$ доказуема.

Предложение доказано.\\

Мы рассмотрели модель Крипке с фиксированной предметной областью. В этой модели во всех узлах будут модели логики предикатов с одинаковым универсумом $D$ и одинаковой сигнатурой $\sg$. Но а если нам потребуется, чтобы универсумы на разных моделях в узлах были соответственно разными, т.е. модели с переменной предметной областью? Для этого введём следующее определение.\\

\opr

\textbf{Моделью Крипке переменной предметной области} мы будем называть $\mM=\langle W,R,D,\{\delta_w\}_{w\in W},\{V_w\}_{w\in W}\rangle$, где:

1) $W$ - множество миров;

2) $R\subseteq W^2$ - отношение достижимости;

3) $D\neq\varnothing$ - область квантификации;

4) $\delta_w\subseteq D$ - \textbf{область квантификации в мире $w$}; 

5) $V_w(P^{(n)})\subseteq (\delta_w)^n$ - множество означивания предиката $P^{(n)}$ в мире $w$.\\

Здесь ничего почти не изменилось за исключением того, что теперь все модели в узлах могут быть с разными универсумами $\delta_w$ и разными истинностями предикатов $V_w(P^{(n)})$. \\

\opr

Определим \textbf{истинность формулы на модели Крипке переменной предметной области}. Пусть нам дано означивание $\gamma\!:X\to D$. Тогда:

1) $\mM,w\vD(x_i=x_j)[\gamma]\Leftrightarrow\gamma(x_i)=\gamma(x_j)$;

2) $\mM,w\vD P(\lot x 1 n)[\gamma]\Leftrightarrow\langle\gamma(x_1),\dots,\gamma(x_n)\rangle\in V_w(P^{(n)})$;

3) $\mM,w\vD(\vp\ampersand\psi)[\gamma]\Leftrightarrow\mM,w\vD\vp[\gamma]$ и $\mM,w\vD\psi[\gamma]$;

4) $\mM,w\vD(\vp\vee\psi)[\gamma]\Leftrightarrow\mM,w\vD\vp[\gamma]$ или $\mM,w\vD\psi[\gamma]$;

5) $\mM,w\vD(\vp\to\psi)[\gamma]\Leftrightarrow\mM,w\nvDash\vp[\gamma]$ или $\mM,w\vD\psi[\gamma]$;

6) $\mM,w\vD\lnot\vp[\gamma]\Leftrightarrow\mM,w\nvDash\vp[\gamma]$;

7) $\mM,w\vD\forall x\vp(x)[\gamma]\Leftrightarrow\forall a\in \delta_w\!:\mM,w\vD\vp(a)[\gamma]$;

8) $\mM,w\vD\exists x\vp(x)[\gamma]\Leftrightarrow\exists a\in \delta_w\!:\mM,w\vD\vp(a)[\gamma]$;

9) $\mM,w\vD\need\vp[\gamma]\Leftrightarrow\forall v\in W\!\!:((w,v)\in R\Rightarrow\mM,v\vD\vp[\gamma])$;

10) $\mM,w\vD\may\vp[\gamma]\Leftrightarrow\exists v\in W\!\!:((w,v)\in R$ и $\mM,v\vD\vp[\gamma])$.\\

Так же сохраняются истинности формулы в мире и на модели.\\

Рассмотрим так же истинность формулы Баркан $\forall x\need\vp(x)\to\need\forall x\vp(x)$ на модели переменной п.о.. Будет ли формула истинной?

Подберём формулу для Баркан $\vp(x)=$"\textit{Студент $x$ хорошо учится}"{}. Проверим истинность получившейся формулы.

Если сейчас в мире $w$ это выполняется, то в следующем мире $v$ уже \underline{другая} \underline{предметная область}. Тогда формула в следующем мире может быть ложной, поскольку мог поменяться универсум. 

Если в нашей формуле Баркан говорилось, что: 
\\\centr{\textit{Любой сегодняшний студент потом будет хорошо учиться}}
\\\centr{\textit{\textsc{СЛЕДУЕТ}}}
\\\centr{\textit{в будущем все студенты будут хорошо учиться}}

то не факт, что все \underline{будущие студенты} будут хорошо учиться, так как мог прийти троечник из академа и начать понижать статистику потоку. У нас могли хорошо учиться текущие студенты, но насчёт будущих мы ничего сказать не можем. Поэтому формула Баркан не является истинной на модели Крипке переменной предметной области.

А что насчёт обратной формулы Баркан $\need\forall x\vp(x)\to\forall x\need\vp(x)$?

Она так же не будет выполняться, поскольку если в будущем все студенты будут хорошо учиться, то нет никакого гаранта, что \underline{все сегодняшние} будут хорошо учиться, ибо кого-то из сегодняшних могут отчислить. Поэтому обратный Баркан так же невыполним на модели Крипке переменной п.о..\\

Т.е. если область у модели Крипке переменная, то аксиома Баркан ломается. Но мы будем рассматривать только два крайних случая:

1) Область у последующих миров не увеличивается;

2) Область у последующих миров не сужается.

В случае 1) будет выполняться простая формула Баркан, а в случае 2) - обратная формула Баркан.

Отсюда можно сделать интересные выводы: 

1) Если на модели Крипке выполняется формула обратного Баркан, то области последующих миров в модели не сужаются;

2) Если на модели Крипке выполняется формула Баркан, то области последующих миров в модели не увеличиваются; 

3) Если на модели Крипке выполняется обратная и простая формулы Баркан, то модель с постоянной п.о.;

4) В ином случае, когда никакая из формул Баркан не выполняется, мы ничего сказать не можем, т.к. предметные области у миров переменные.

Запишем это в более строгом виде.\\

\opr

Пусть дана модель Крипке переменной п.о. $\mM=\langle W,R,D,\{\delta_w\}_{w\in W},\newline\{V_w\}_{w\in W}\rangle$, тогда:

1) $\mM$ - \textbf{модель расширяющейся предметной области}, если 
\\\centr{$\forall w,v\in W\!\!:(w,v)\in R\Rightarrow\delta_w\subseteq\delta_v$;}

2) $\mM$ - \textbf{модель сужающейся предметной области}, если 
\\\centr{$\forall w,v\in W\!\!:(w,v)\in R\Rightarrow\delta_v\subseteq\delta_w$.}\\

\predl

$\mM$ - модель расширяющейся п.о. $\Leftrightarrow\mM\vD C\!B$ (обратный Баркан).

$\mM$ - модель сужающейся п.о. $\Leftrightarrow\mM\vD B$ (Баркан).\\

\zam

$\mM\vD B$ и $\mM\vD C\! B\Leftrightarrow\mM$ - модель Крипке постоянной п.о..

Если не выполняются $B$ и $C\!B$, то модель с переменной п.о..\\

Помимо аксиомы Баркан, если продолжаем работать с переменной областью, у нас так же есть проблемы и с аксиомой $A$ - $\forall x\vp\to[\vp]^x_y$. Мы могли заменить $x$ на $y$, которого просто нет в области квантификации мира. Тогда могут выйти случаи, когда после замены изменится истинность формулы, что очень нехорошо. Для этого придумали одну хитрость.\\

\predl

Зададим формулу $E(y)=\exists z(z=y)$. 

Тогда $\gamma(y)\in\delta_w\Leftrightarrow\mM,w\vD E(y)[\gamma]$.

И чтобы в будущем избежать проблем с аксиомой $A$, мы её \underline{заменим} на аксиому $AE$ - $(\forall x\vp\ampersand E( y))\to[\vp]^x_y.$\\

На основе того, что мы сейчас выяснили насчёт аксиом, мы можем определить новые логики:

1) $K+N\!D+E+B$ - модальная логика первого порядка для моделей Крипке сужающейся п.о.;

2) $K+N\!D+E+C\!B$ - модальная логика первого порядка для моделей Крипке расширяющейся п.о.;

3) $K+N\!D+E$ - модальная логика первого порядка для того случая, когда нам не нужно фиксировать сужение или увеличение предметной области у моделей Крипке.\\

На этой ноте мы заканчиваем данный параграф. Краем глаза заметил в какой-то статье, что модальную логику первого порядка где-то используют в автоматизации доказательств, как во 2й главе. 

Есть еще достаточно великое количество подвидов модальной логики, и один из этих подвидов будет рассматриваться в следующем параграфе.\\

\msubsection{Пропозиционально временная логика}
\begin{flushright}
- \textit{А в этой логике можно описать релятивизм?}

- \textit{Понятия не имею... Не знаю..}

\textit{2019}
\end{flushright}
Иногда её \textbf{} именуют \textbf{темпоральной логикой}.

Временная логика - частный случай модальной логики, когда цепь миров интерпретируется как линия времени и событий. Используется для описания последовательностей явлений и их взаимосвязи по временной шкале. Данная логика широко используется в интеллектуальных системах реального времени, системах верификации программного кода или отдельных различных систем.\\

\opr

Пара $\langle T,<\rangle$ называется \textbf{потоком времени}, если:

1) $T\neq\varnothing$;

2) Отношение $"{}\!\!<\!"{}\;\subseteq T^2$ иррефлексивно и транзитивно.\\

\opr 

Поток времени $\langle T,<\rangle$ называется \textbf{линейным потоком времени}, если: 
\\\centr{$\forall t,s\in T\!:(t=s)\vee(t<s)\vee(s<t)$.}

\primer

Линейными потоками могут быть: $\langle\mathbb N,<\rangle,\langle\mathbb Q,<\rangle,\langle\mathbb R,<\rangle.$\\

\opr 

Поток времени $\langle T,<\rangle$ называется \textbf{древовидным потоком времени}, \\если\qquad$\forall t,s,u\in T\!:((s<t)\ampersand(u<t))\to((u=s)\vee(s<u)\vee(u<s))$.

\newpage

\begin{wrapfigure}[4]{l}{0.35\textwidth}
\scalebox{1.3}
{
\begin{tikzpicture}

\draw[-latex,color=black, very thick](0, -2) -- (1, -2);
\draw[-latex,color=black, very thick](1, -2) -- (2, -2);
%tree after t
\draw[-latex,color=black, very thick](2, -2) -- (2.5, -1.5);
\draw[-latex,color=black, very thick](2, -2) -- (3, -3);
\draw[-latex,color=black, very thick](3, -3) -- (3.5, -2.5);
\draw[-latex,color=black, very thick](3, -3) -- (3.7, -3.5);
%false tree 1
\draw[-latex,color=black, very thick](0, -2) -- (0.5, -1);
\draw[-latex,color=black, very thick](0, -2) -- (0.5, -3);
\node[scale=1.3,rotate=50] at (0.25,-1.5) {$\times$};
\node[scale=1.3,rotate=30] at (0.25,-2.5) {$\times$};
%false tree 2
\draw[-latex,color=black, very thick](1, -2) -- (1.5, -3);
\node[scale=1.3,rotate=50] at (1.25,-2.5) {$\times$};
%symbols
\node[scale=1.2] at (2,-1.65) {$t$};
\node[scale=1.2] at (1,-1.65) {$s$};
\node[scale=1.2] at (-0.3,-2) {$u$};

\node[scale=1.4] at (4,-2) {$\dots$};


\draw[fill=black, color=black, very thick](0, -2) circle (0.05);
\draw[fill=black, color=black, very thick](1, -2) circle (0.05);
\draw[fill=black, color=black, very thick](2, -2) circle (0.05);
\draw[fill=black, color=black, very thick](3, -3) circle (0.05);
\end{tikzpicture}
}

\end{wrapfigure}\leavevmode\\О чём говорится в последнем определении? Здесь речь о том, что прошлое \underline{обязательно срав}-\newline\underline{нимо между собой}, а будущее еще не определено, следовательно, оно может быть древовидным. Обычно за мир $t$ обозначают сегодняшний день, значит до него все события уже свершились и никаких других ответвлений до $t$ \underline{уже быть не может}. Но $t$ - сегодняшний день, и мы не знаем, что будет впереди, следовательно возможны некоторые варианты дальнейших ответвлений. После выбора прошлое фиксируется и другие ответвления пропадают. Таким образом задаётся древовидная структура потока.\\

Исследуется огромное количество различных потоков, но древовидный и линейный потоки пользуются большой поопулярностью по очевидным причинам. Исследовали еще цикличные потоки, когда временной промежуток повторяется раз за разом. Рассмотрим её.\\

\opr

Поток времени $\langle T,<\rangle$ называется \textbf{цикличным потоком времени}, \\если выполняются следующие условия:

1) $(t=s)\vee(t<s)\vee(s<t)$ - линейность;

2) $\lnot((t<s)\ampersand(s<t))$ - антисимметричность;

3) $((t<s)\ampersand(t<u)\ampersand(t<v)\ampersand(s<u)\ampersand(u<v))\to(s<v)$ - транзитивность будущего;

4) $((s<t)\ampersand(u<t)\ampersand(v<t)\ampersand(s<u)\ampersand(u<v))\to(s<v)$ - транзитивность прошлого;

5) $\exists a,b,c\in T\!:(a<b)\ampersand(b<c)\ampersand(c<a)$.

Зададим понятие модели Крипке временной логики.\\

\opr

\textbf{Моделью временной логики} называется $\mM=\langle T,<,h\rangle,$ где \\$h\!:\sg\to\rho(T)$ - означивание пропозициональных переменных.\\

В зависимости от того, какие будем рассматривать модальности, у нас будут получаться различные формулы. Рассмотрим самые классические модальности.\\

\opr

\textbf{Модальностями Приота} называют модальности:

1) $\langle F\rangle$ - "возможно в будущем"{}, т.е. 
\\\centr{$\mM,t\vD F\vp\Leftrightarrow\exists s\in T\!:(t<s\ampersand\mM,s\vD\vp)$;}

2) $\langle P\rangle$ - "возможно в прошлом"{}, т.е. 
\\\centr{$\mM,t\vD P\vp\Leftrightarrow\exists s\in T\!:(s<t\ampersand\mM,s\vD\vp)$;}

3) $[G]$ - "необходимо в будущем"{}, т.е. 
\\\centr{$\mM,t\vD G\vp\Leftrightarrow\forall s\in T\!:(t<s\Rightarrow\mM,s\vD\vp)$;}

4) $[H]$ - "необходимо в прошлом"{}, т.е. 
\\\centr{$\mM,t\vD H\vp\Leftrightarrow\forall s\in T\!:(s<t\Rightarrow\mM,s\vD\vp)$.}\\

Следующие модальности дополняют первый набор. Это набор модальностей относительно сегодняшнего или вчерашнего дня.\\
\newpage
\opr

Введём модальности относительно дня:

1) $X$ - "возможно завтра"{}, т.е.
\\\centr{$\mM,t\vD X\vp\Leftrightarrow\exists s\in T\!:(t<s\ampersand\lnot\exists u(t<u\ampersand u<s)\ampersand\mM,s\vD\vp)$;}

2) $[X]$ - "необходимо завтра"{}, т.е.
\\\centr{$\mM,t\vD [X]\vp\Leftrightarrow\forall s\in T\!:((t<s\ampersand\lnot\exists u(t<u\ampersand u<s))\Rightarrow\mM,s\vD\vp)$;}

3) $Y$ - "возможно вчера"{}, т.е.
\\\centr{$\mM,t\vD Y\vp\Leftrightarrow\exists s\in T\!:(t>s\ampersand\lnot\exists u(t>u\ampersand u>s)\ampersand\mM,s\vD\vp)$;}

4) $[Y]$ - "необходимо вчера"{}, т.е.
\\\centr{$\mM,t\vD [Y]\vp\Leftrightarrow\forall s\in T\!:((t>s\ampersand\lnot\exists u(t>u\ampersand u>s))\Rightarrow\mM,s\vD\vp)$.}\\

Учтём, что если поток времени линейный, то "возможно завтра"{} и "необходимо завтра"{} совпадают, так же и для вчерашнего дня. 

Если у нас поток \textit{непрерывен}, т.е. $T=\mathbb R$, тогда понятия вчерашнего или завтрашнего дня нет по понятным причинам. Тогда модальности относительно дней не работают. Они работают, когда поток \textit{дискретный}, т.е. $T=\mathbb N$ или $T=\mathbb Z$ например.\\

Существует еще третий вид модальностей, который так же часто используют - это "$U\!ntil$"{} и "$Since$"{}.\\

\opr

Модальности "$U\!ntil$"{} и "$Since$"{}:

1) $U(\vp,\psi)=$"До тех пор, пока не выполнится $\vp$, будет выполняться и $\psi$"{}, т.е. 

$\mM,t\vD U(\vp,\psi)\Leftrightarrow\exists s\!:(t<s\ampersand\mM,s\vD\vp\ampersand\forall u((t<u\ampersand u<s)\Rightarrow\newline\Rightarrow\mM,u\vD\psi))$;

2) $S(\vp,\psi)=$"С тех пор, как выполняется $\vp$, выполняется и $\psi$"{}, т.е. 

$\mM,t\vD S(\vp,\psi)\Leftrightarrow\exists s\!:(t>s\ampersand\mM,s\vD\vp\ampersand\forall u((t>u\ampersand u>s)\Rightarrow\newline\Rightarrow\mM,u\vD\psi))$.\\

В данном параграфе рассматривались только самые ходовые модальности. Важно понимать, что мы сами можем придумать разные модальности. Если открыть какую нибудь книгу по временным логикам, то там для описания реальности придумывают собственные модальности, т.е. записывают шаблонные предложения, затем описание их истинности на модели. На этом закончим обзор временной логики и рассмотрим её трансляцию в логику предикатов. 

\msubsection{Стандартная трансляция временной логики в Л.П.}

Идея данной трансляции не сильно отличается от предыдущей, но меняется из-за специфики временной логики. 

Вспомним сигнатуру, которую ввели в начале модальной логики:
\\\centr{$\sg=\{A_1,A_2,\dots\}$.}

Введём сигнатуру, которую будем использовать при трансляции:
\\\centr{$\sg^*=\{P_1^{(1)},P_2^{(1)},\dots,<\}$.}\\

\opr 

Будем называть отображение $\st x\!\!:F(\sg)\to F(\sg^*)$ \textbf{стандартной трансляцией в логику предикатов}, если выполняются следющие условия:

1) $\forall A_i\in\sg\!:\st x(A_i)=P_i(x)$;

2) $\st x(1)=1,\;\st x(0)=0$;

3) $\st x(\vp\ampersand\psi)=\st x(\vp)\ampersand\st x(\psi)$;

4) $\st x(\vp\vee\psi)=\st x(\vp)\vee\st x(\psi)$;

5) $\st x(\vp\to\psi)=\st x(\vp)\to\st x(\psi)$;

6) $\st x(\lnot\vp)=\lnot\st x(\vp)$;

7) $\st x(F\vp)=\exists y(x<y\ampersand\st y(\vp))$;

8) $\st x(G\vp)=\forall y(x<y\to\st y(\vp))$;

9) $\st x(P\vp)=\exists y(x>y\ampersand\st y(\vp))$;

10) $\st x(H\vp)=\forall y(x>y\to\st y(\vp))$;

11) $\st x(X\vp)=\exists y(x<y\ampersand\lnot\exists z(x<z\ampersand z<y)\ampersand\st y(\vp))$;

12) $\st x([X]\vp)=\forall y((x<y\ampersand\lnot\exists z(x<z\ampersand z<y))\to\st y(\vp))$;

13) $\st x(Y\vp)=\exists y(x>y\ampersand\lnot\exists z(x>z\ampersand z>y)\ampersand\st y(\vp))$;

14) $\st x([Y]\vp)=\forall y((x>y\ampersand\lnot\exists z(x>z\ampersand z>y))\to\st y(\vp))$;

15) $\st x(U(\vp,\psi))=\exists y(x<y\ampersand\st y(\vp)\ampersand\forall z((x<z\ampersand z<y)\to\st z(\psi))$;

16) $\st x(S(\vp,\psi))=\exists y(x>y\ampersand\st y(\vp)\ampersand\forall z((x>z\ampersand z>y)\to\st z(\psi))$.\\

\opr 

Пусть дана модель временной логики $\mM=\langle T,<,h\rangle$. Тогда будем говорить, что $\mM^*=\langle T,\sg^*\rangle$ \textbf{интерпретирует} $\mM$, если $\forall t,s\in T$ выполняется:

1) $\mM^*\vD(t<s)\Leftrightarrow t<s$;

2) $\forall A_i\in\sg\;\forall P_i\in\sg^*\!\!:\;\mM^*\vD P_j(t)\Leftrightarrow t\in h(A_i)$.\\

В дальнейшем нам надо разобрать, как работать с формулами в потоках времени. Для этого выделяются классы потоков с некоторыми одинаковыми свойствами.\newpage

\msubsection{Классы потоков времени}

\opr 

\textbf{Классом потоков времени} мы будем называть множество 
\\\centr{$C=\{\langle T_i,<_i\rangle\;|\;i\in\ki\}$.}\\

\opr

Пусть даны $\vp(x),\psi(x)\in F(\sg^*)$. Тогда $\vp(x)$ и $\psi(x)$ \textbf{эквивалентны над классом потоков $C$}, т.е. $\vp(x)\sim_c\psi(x)$, если выполняется:
\\\centr{$\forall\langle T,<\rangle\!\in\!C\;\forall\mM=\langle T,<,h\rangle\;\forall t\in T\!:\;\mM\vD(\vp(t)\leftrightarrow\psi(t))$,}\\
где $\sg^*$ из \underline{прошлого параграфа}.\\

\opr 

Пусть дан класс $C=\{\langle T_i,<_i\rangle\;|\;i\in\ki\}$. Пусть $\alpha\in F(\sg),\vp(x)\in F(\sg*)$.
\\Тогда $\alpha\sim_c\vp(x)\Leftrightarrow\forall t\in T\!:\st t(\alpha)\sim_c\vp(t)$.\\

\opr 

Пусть дана модальная логика $M\!L=(\sg,\{\lot m 1 n\})$ и класс \\$C=\{\langle T_i,<_i\rangle\;|\;i\in\ki\}$. Тогда $M\!L$ \textbf{выразительно полна над классом потоков} $C$, если $\forall\vp(x)\in F(\sg^*)\;\exists\alpha\in F(\sg)\!:\alpha\sim_c\vp(x)$.\\

Здесь мы сами задаём модальную логику, задавая набор модальностей. Зачем? Читай продолжение.\\

\teor

Не существует временной логики с конечным набором модальностей, выразительно полной над классом \underline{всех потоков времени}, т.е. класс\\$C=\{\langle T_i,\alpha_i\rangle\;|\;i\in\ki\}$, где $\alpha$ - некоторое отношение между мирами, то есть, например, отношение для древовидных потоков, линейных и всяких других экзотических потоков.

\bezdok\\

\opr

Пусть дан класс $C=\{\langle T_i,<_i\rangle\;|\;i\in\ki\}$ и $\alpha\in F(\sg)$. Тогда:

1) $\alpha$ \textbf{описывает прошлое над классом} $C$, если выполняется условие:
\\\centr{$\forall\langle T_i,<_i\rangle\in C\;\forall\mM_1=\langle T_i,<_i,h_1\rangle\;\forall\mM_2=\langle T_i,<_i,h_2\rangle\;\forall t\in T$:}
\\\centr{:$\forall u(u<t\ampersand(\mM_1,u)\approx(\mM_2,u))\Rightarrow(\mM_1,t\vD\alpha\Leftrightarrow\mM_2,t\vD\alpha)$.}

2) $\alpha$ \textbf{описывает будущее над классом} $C$, если выполняется условие:
\\\centr{$\forall\langle T_i,<_i\rangle\in C\;\forall\mM_1=\langle T_i,<_i,h_1\rangle\;\forall\mM_2=\langle T_i,<_i,h_2\rangle\;\forall t\in T$:}
\\\centr{:$\forall u(t<u\ampersand(\mM_1,u)\approx(\mM_2,u))\Rightarrow(\mM_1,t\vD\alpha\Leftrightarrow\mM_2,t\vD\alpha)$.}

3) $\alpha$ \textbf{описывает настоящее над классом} $C$, если выполняется условие:
\\\centr{$\forall\langle T_i,<_i\rangle\in C\;\forall\mM_1=\langle T_i,<_i,h_1\rangle\;\forall\mM_2=\langle T_i,<_i,h_2\rangle\;\forall t\in T$:}
\\\centr{:$\mM_1,t\vD\alpha\Leftrightarrow\mM_2,t\vD\alpha$.}

4) $\alpha$ является \textbf{разделяемой над классом} $C$, если она является булевой комбинацией формул($\ampersand,\vee,\lnot,\to$), описывающих либо прошлое, либо будущее, либо настоящее.

5) Логика $M\!L$ \textbf{разделима над классом $C$}, если для каждой её формулы найдётся эквивалентная ей разделяемая формула над $C$, т.е. 
\\\centr{$\forall\beta\in F(\sg)\;\exists\alpha\in F(\sg)\!:\beta\sim_c\alpha,\;\alpha$ - разделяемая.}\\

\primer

$S(A_1,A_2)\ampersand FA_1$ - разделима, но $S(A_1,A_2)$ - нет.\newpage

\teor

Пусть $C$ - класс линейных потоков. Пусть $M\!L$ содержит модальности Приота(опр. 45.6.), тогда $M\!L$ - разделима над $C\Leftrightarrow M\!L$ - выразительно полна.\\

\teor

Пусть $M\!L$ содержит модальности Приота и модальности "$U\!ntil$"{} и "$Since$"{}. Тогда $M\!L$ - разделима над $\langle\mathbb N,<\rangle$.\\

\opr

Модальность $Stavi(\vp,\psi)$="\textit{$\psi$ истинно в настоящее время, вплоть до некоторого времени, после которого через некоторое время $\psi$ становится ложной и $\vp$ становится истинной}"{}, т.е.

$Stavi(P_1,P_2)=\exists s\Big(t<s\ampersand\exists u\big(t<u<s\ampersand\lnot P_2(u)\big)\ampersand\newline\ampersand\exists u\big(t<u<s\ampersand\forall v(t<v<u\to P_2(v))\big)\ampersand\newline\ampersand\forall u\big(t<u<s\to\big[\exists v(u<v\ampersand\forall w(t<w<v\to P_2(w)))\big]\vee\newline\vee\big[\forall v(u<v<s\to P_1(v))\ampersand\exists v(t<v<u\ampersand\lnot P_2(v))\big]\!\big)\!\!\Big)$.\\

\teor

Логика $M\!L$, содержащая модальности Приота, "$U\!ntil$"{}, "$Since$"{} и "$Stavi$"{} разделима над классом всех линейных потоков.\\

Т.е. зачем нам нужны данные свойства модальной логики? Важно понимать, что здесь под модальной логикой имеется ввиду некоторая \underline{временная} \underline{логика}. И чтобы описать, например, все линейные потоки в логике, нам достаточно, например, иметь в $M\!L$ модальности Приота, "$U\!ntil$"{}, "$Since$"{} и "$Stavi$"{}. Описав эту логику с линейными потоками, там мы дальше можем исследовать некоторые свойства формул и линейных порядков.\newpage

\msection{Нечёткая логика}
\msubsection{Многозначные логики}

Многозначная логика — тип формальной логики, в которой допускается более двух истинностных значений для высказываний. В настоящее время существует очень много других систем многозначной логики, которые в свою очередь могут быть сгруппированы по классам. Важнейшими из таких классов являются частичные логики и нечёткие логики.\\

Первым, кто разработал многозначную логику высказываний, был Лукасевич в 1920 году. В качестве исходных логических связок берутся отрицание $\lnot$ и импликация $\rightarrow$.\\

\oprT{Истинности логики Лукасевича} 

1 - "\textit{True}"{}, 

0 - "\textit{False}"{}, 

1/2 - "\textit{Безразлично(Unknown)}"{}.\\

\oprT{истинность логических связок в логике Лукасевича}

Определим истинность отрицания и импликации в логике Лукасевича $L_3$:

1) Отрицание: $\lnot 1/2=1/2$.

2) Импликация: $1\rightarrow 1/2=1/2\rightarrow 0=1/2$, $\newline 0\rightarrow 1/2=1/2\rightarrow 1/2=1/2\rightarrow 1=1$;

3) При аргументаeх из множества $\{0,\;1\}$ используются значения из классической (двузначной) логики.\\

Доопределим остальные логические связки:

1) $x\vee y:=(x\rightarrow y)\rightarrow y$ - дизъюнкция;

2) $x\ampersand y:=\lnot(\lnot x\vee \lnot y)$ - конъюнкция;

3) $x\leftrightarrow y:=(x\rightarrow y)\ampersand(y\rightarrow x)$ - эквиваленция.

Таблицы истинности в данной логике задаются следующим образом:

\begin{center}
\begin{tabular}{|c|c|llll|c|c|c|c|}
\cline{1-2} \cline{7-10}
\textbf{NOT} & & & & & & \textbf{$\rightarrow$} & \textbf{0} & \textbf{1/2} & \textbf{1} \\
\cline{1-2} \cline{7-10}
\textbf{0} & 1 & & & & & \textbf{0} & 1 & 1 & 1 \\
\cline{1-2} \cline{7-10}
\textbf{1/2} & 1/2 & & & & & \textbf{1/2} & 1/2 & 1 & 1 \\
\cline{1-2} \cline{7-10}
\textbf{1} & 0 & & & & & \textbf{1} & 0 & 1/2 & 1 \\
\cline{1-2} \cline{7-10}
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|c|llll|c|c|c|c|llll|c|c|c|c|}
\cline{1-4} \cline{9-12} \cline{17-20}
\textbf{OR} & \textbf{0} & \textbf{1/2} & \textbf{1} & & & & & \textbf{AND} & \textbf{0} & \textbf{1/2} & \textbf{1} & & & & & \textbf{EQ} & \textbf{0} & \textbf{1/2} & \textbf{1} \\
\cline{1-4} \cline{9-12} \cline{17-20} 
\textbf{0} & 0 & 1/2 & 1 & & & & & \textbf{0} & 0 & 0 & 0 & & & & & \textbf{0} & 1 & 1/2 & 0 \\ 
\cline{1-4} \cline{9-12} \cline{17-20} 
\textbf{1/2} & 1/2 & 1/2 & 1 & & & & & \textbf{1/2} & 0 & 1/2 & 1/2 & & & & & \textbf{1/2} & 1/2 & 1 & 1/2 \\ 
\cline{1-4} \cline{9-12} \cline{17-20} 
\textbf{1} & 1 & 1 & 1 & & & & & \textbf{1} & 0 & 1/2 & 1 & & & & & \textbf{1} & 0 & 1/2 & 0 \\ 
\cline{1-4} \cline{9-12} \cline{17-20} 
\end{tabular}
\end{center}

\opr

Формула $\varphi$ называется \textbf{тождественно истинной}, если она приминает значение 1 при любых значениях входящих переменных.\\

\predl

$\varphi$ т. и. в логике Лукасевича $\Rightarrow \varphi$ т. и. в классической логике высказываний.\\

\zam

$\exists \varphi$ такие, что $\varphi$ т. и. в классической логике высказываний, но не в логике Лукасевича.

Примерами таких формул являются $(\psi\vee\lnot\psi)$ и $\lnot(\psi\ampersand\lnot\psi)$.\\

В 1938 г. Д.А. Бочваром была построена первая в мире логика бессмысленности $B_3$ в связи с проблемой разрешения логических антиномий, в первую очередь
\textit{парадокса Рассела}. В данной системе третье истинностное значение 1/2 предлагается интерпретировать не столько как промежуточное между истиной 1 и ложью 0, сколько как парадоксальное значение или даже как «бессмысленность».\\

\opr

\textbf{Логика Бочвара} задаётся истинностями: 

1 - "\textit{Истина}"{}, 

0 - "\textit{Ложь}"{}, 

1/2 - "\textit{Бессмысленно(Senselessly)}"{}.

Идея этой логики проста: если хотя бы одна пропозициональная переменная "бессмысленна"{}, то и вся формула "бессмысленна"{}.

\begin{center}
\begin{tabular}{|c|c|llll|c|c|c|c|llll|c|c|c|c|}
\cline{1-2} \cline{7-10} \cline{15-18}
\textbf{NOT} & & & & & & \textbf{$\rightarrow$} & \textbf{0} & \textbf{1/2} & \textbf{1} & & & & & \textbf{EQ} & \textbf{0} & \textbf{1/2} & \textbf{1} \\
\cline{1-2} \cline{7-10} \cline{15-18}
\textbf{0} & 1 & & & & & \textbf{0} & 1 & 1/2 & 1 & & & & & \textbf{0} & 1 & 1/2 & 0 \\
\cline{1-2} \cline{7-10} \cline{15-18}
\textbf{1/2} & 1/2 & & & & & \textbf{1/2} & 1/2 & 1/2 & 1/2 & & & & & \textbf{1/2} & 1/2 & 1/2 & 1/2 \\
\cline{1-2} \cline{7-10} \cline{15-18}
\textbf{1} & 0 & & & & & \textbf{1} & 0 & 1/2 & 1  & & & & & \textbf{1} & 0 & 1/2 & 0 \\
\cline{1-2} \cline{7-10} \cline{15-18}
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|c|llll|c|c|c|c|llll|c|c|c|c|}
\cline{1-4} \cline{9-12}
\textbf{OR} & \textbf{0} & \textbf{1/2} & \textbf{1} & & & & & \textbf{AND} & \textbf{0} & \textbf{1/2} & \textbf{1} \\
\cline{1-4} \cline{9-12}
\textbf{0} & 0 & 1/2 & 1 & & & & & \textbf{0} & 0 & 1/2 & 0 \\ 
\cline{1-4} \cline{9-12}
\textbf{1/2} & 1/2 & 1/2 & 1/2 & & & & & \textbf{1/2} & 1/2 & 1/2 & 1/2 \\ 
\cline{1-4} \cline{9-12}
\textbf{1} & 1 & 1/2 & 1 & & & & & \textbf{1} & 0 & 1/2 & 1 \\ 
\cline{1-4} \cline{9-12}
\end{tabular}
\end{center}

\predl

$\varphi$ т. и. в логике Бочвара $\Rightarrow \varphi$ т. и. в классической логике высказываний.\\

Как и в логике Лукасевича, здесь не выполняются законы исключения третьего и противоречия.\\

Разработка теории рекурсивных функций преводит к идее не всюду определённой (частичной) функции. В 1938 году С.Клини разрабатывает трёхзначную логику $K_3$, в которой введение логических связок должно моделировать рекурсивные функции. Отсюда третье истинностное значение интерпретируется как "не определено"{}, "неизвестно"{}, "неразрешимо"{}.\\

\opr

\textbf{Логика Клини} задаётся истинностями: 

1 - "\textit{Истина}"{}, 

0 - "\textit{Ложь}"{}, 

1/2 - "\textit{Не определено(Undefined)}"{}.

Таблицы истинности в данной логике задаются следующим образом:

\begin{center}
\begin{tabular}{|c|c|llll|c|c|c|c|}
\cline{1-2} \cline{7-10}
\textbf{NOT} & & & & & & \textbf{$\rightarrow$} & \textbf{0} & \textbf{1/2} & \textbf{1} \\
\cline{1-2} \cline{7-10}
\textbf{0} & 1 & & & & & \textbf{0} & 1 & 1 & 1 \\
\cline{1-2} \cline{7-10}
\textbf{1/2} & 1/2 & & & & & \textbf{1/2} & 1/2 & 1/2 & 1 \\
\cline{1-2} \cline{7-10}
\textbf{1} & 0 & & & & & \textbf{1} & 0 & 1/2 & 1 \\
\cline{1-2} \cline{7-10}
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|c|llll|c|c|c|c|llll|c|c|c|c|}
\cline{1-4} \cline{9-12} \cline{17-20}
\textbf{OR} & \textbf{0} & \textbf{1/2} & \textbf{1} & & & & & \textbf{AND} & \textbf{0} & \textbf{1/2} & \textbf{1} & & & & & \textbf{EQ} & \textbf{0} & \textbf{1/2} & \textbf{1} \\
\cline{1-4} \cline{9-12} \cline{17-20} 
\textbf{0} & 0 & 1/2 & 1 & & & & & \textbf{0} & 0 & 0 & 0 & & & & & \textbf{0} & 1 & 1/2 & 0 \\ 
\cline{1-4} \cline{9-12} \cline{17-20} 
\textbf{1/2} & 1/2 & 1/2 & 1 & & & & & \textbf{1/2} & 0 & 1/2 & 1/2 & & & & & \textbf{1/2} & 1/2 & 1 & 1/2 \\ 
\cline{1-4} \cline{9-12} \cline{17-20} 
\textbf{1} & 1 & 1 & 1 & & & & & \textbf{1} & 0 & 1/2 & 1 & & & & & \textbf{1} & 0 & 1/2 & 0 \\ 
\cline{1-4} \cline{9-12} \cline{17-20} 
\end{tabular}
\end{center}

Обратите внимание, что здесь $(1/2\rightarrow 1/2)=1/2$, а не 1, как в логике $L_3$, это их единственное различие.\newpage

\msubsection{Нечёткая логика}

Чуть позже, в 1965, Лотфи Заде придумывает \textbf{нечёткую логику} - обобщение логики и теории множеств, где основные операции производятся над над функцией принадлежности элемента к \textbf{нечёткому} множеству, принимающей любые значения в интервале $[0, 1]$, а не только 0 или 1.

Здесь основная работа с функцией принадлежности. Самая обычная функция - характеристическая для чётких множеств, выглядит так


\centr {$\mu_A(x)=\begin{cases}1,\;x\in A\\0,\;x\notin A\end{cases}$.}

А вот с функцией принадлежности элемента к нечёткому множеству всё будет поинтересней:\\

\primer

Рассмотрим самый простой пример.

Формализуем неточное определение "\textit{горячий чай}"{}. В качестве $x$ будет выступать шкала температуры в градусах Цельсия. Она будет изменяется от $0$ до $100$ градусов. Нечёткое множество для понятия "\textit{горячий чай}"{} может выглядеть следующим образом:

\begin{center}
    \scalebox{0.75}{$C=\{(0,0); (0,10); (0,20); (0.15,30); (0.3,40); (0.6,50); (0.8,60); (0.9,70); (1,80); (1,90); (1,100)\}$.}
\end{center}

т.е. $C$ - множество упорядоченных пар вида $(\mu_C(x),x)$.

Так, чай с температурой $60^{\circ}C$ принадлежит к множеству "\textit{Горячий}"{} со степенью принадлежности 0.8. Для одного человека чай при температуре $60^{\circ}C$ может оказаться горячим, для другого – не слишком горячим. Именно в этом и проявляется нечеткость задания соответствующего множества.

Для нечетких множеств, как и для обычных, определены основные логические операции. Существуют различные виды нечётких логик.

\oprT{Операции над нечёткими множествами}

1) \textbf{Операции Заде:} 

$\chf_{A\cup B}(x)=max\{\chf_A(x),\chf_B(x)\}$,

$\chf_{A\cap B}(x)=min\{\chf_A(x),\chf_B(x)\}$,

$\chf_{\lnot A}(x)=1-\chf_A(x)$.

\primer

Пусть $\chf_A(x)=0,7$. Тогда  $\chf_{\lnot A}(x)=0.3$.

$\chf_{A\cup\lnot A}(x)=max\{0.7,0.3\}=0.7\neq 1$.

$\chf_{A\cap\lnot A}(x)=min\{0.7,0.3\}=0.3\neq 0$.\\

2) \textbf{Логика Лукасевича:}

$\chf_{A\cup B}(x)=min\{\chf_A(x)+\chf_B(x),1\}$,

$\chf_{A\cap B}(x)=max\{\chf_A(x)+\chf_B(x)-1,0\}$,

$\chf_{\lnot A}(x)=1-\chf_A(x)$.\\

3) \textbf{Вероятностная логика:}

$\chf_{A\cup B}(x)=\chf_A(x)+\chf_B(x)-\chf_{A\cap B}(x)$,

$\chf_{A\cap B}(x)=\chf_A(x)\cdot\chf_B(x)$,

$\chf_{\lnot A}(x)=1-\chf_A(x)$.\\

4) \textbf{Драстическая логика:}

$\chf_{A\cup B}(x)=\begin{cases}\chf_A(x),&\chf_B(x)=0\\\chf_B(x),&\chf_A(x)=0\\1, & \text{иначе}\end{cases}$\leavevmode\\\\

$\chf_{A\cap B}(x)=\begin{cases}\chf_A(x),&\chf_B(x)=1\\\chf_B(x),&\chf_A(x)=1\\0, & \text{иначе}\end{cases}$\\

\opr

Двухместная функция $f\!\!:\![0,1]^2\to[0,1]$ называется $t$\textbf{-нормой}, если выполняются следующие условия:

1) $f(x,1)=x$ и $f(x,0)=0$;

2) $f(x,y)=f(y,x)$;

3) $f(x,f(y,z))=f(f(x,y),z)$;

4) $x_1\leqslant x_2\Rightarrow f(x_1,y)\leqslant f(x_2,y)$.\\

\opr

Двухместная функция $g\!\!:\![0,1]^2\to[0,1]$ называется $t$\textbf{-конормой}, если выполняются следующие условия:

1) $g(x,1)=1$ и $g(x,0)=x$;

2) $g(x,y)=g(y,x)$;

3) $g(x,g(y,z))=g(g(x,y),z)$;

4) $x_1\leqslant x_2\Rightarrow g(x_1,y)\leqslant g(x_2,y)$.\\

В настоящее время в нечеткой логике в качестве операций конъюнкции и дизъюнкции широко используются $t$-нормы и $t$-конормы соответственно, пришедшие в нечёткую логику из теории вероятностных метрических пространств. Эти операции достаточно хорошо изучены и лежат в основе многих формальных построений нечеткой логики и являются так называемыми \textbf{триангулярными формами}.\\

\opr 

Одноместная функция $N\!\!:\![0,1]\to[0,1]$ называется \textbf{нечётным отрицанием}, если выполняются следующие условия:

1) $N(N(x))=x$;

2) $N(0)=1$ и $N(1)=0$;

3) $x_1\leqslant x_2\Rightarrow N(x_2)<N(x_1)$.\\

\opr

\textbf{Законы де Моргана} в нечёткой логике выглядят следующим образом:

$N(f(x,y))=g(N(x),N(y))$,

$N(g(x,y))=f(N(x),N(y))$.\\

\predl

1) $\forall f$ - $t$-норм $\forall x,y\in[0,1]\!: f(x,y)\leqslant min\{x,y\}$;

2) $\forall g$ - $t$-конорм $\forall x,y\in[0,1]\!: g(x,y)\geqslant max\{x,y\}$.

\dok 

1) $\left.
  \begin{array}{c}
    f(x,y)\leqslant f(x,1)=x \\
    f(x,y)\leqslant f(1,y)=y
  \end{array}
  \right\}\Rightarrow f(x,y)\leqslant min\{x,y\}.$\\
  
2) Аналогично 1-му.

Предложение доказано.\\

\predl


1) $\forall f$ - $t$-норм $f(x,y)\geqslant f_d(x,y)$, где $f_d(x,y)$ - драстическая $t$-норма;

2) $\forall g$ - $t$-конорм $g(x,y)\leqslant g_d(x,y)$, где $g_d(x,y)$ - драстическая $t$-конорма.

Драстические $t$-конормы и $t$-нормы описаны в 49.1. соответственно.\newpage

\dok

Рассмотрим 3 возможных случая:

1) Пусть $x\neq 1,y\neq1$, тогда $f(x,y)\geqslant f_d(x,y)=0$;

2) Пусть $x=1$, тогда $f(1,y)=y=f_d(1,y)$;

3) Пусть $y=1$, тогда $f(x,1)=x=f_d(x,1)$.

Для $t$-конорм аналогично.

Предложение доказано.\\

\predl

Нормы Заде - единственные \textbf{идемпотентные нормы}, т.е. $f(x,x)=x$.  

\dok

Докажем от противного. Допустим, что $f$-идемпотентна, а норма Заде\\$f_z$ - нет. Тогда $\forall x\in[0,1]\!:f(x,x)=x$.

Пусть $f\neq f_z\Rightarrow\exists x,y\!: x<y\ampersand f(x,y)\neq f_z(x,y)\Rightarrow f(x,y)<f_z(x,y)\Rightarrow\newline\Rightarrow f(x,x)\leqslant f(x,y)<f_z(x,y)=x\Rightarrow f(x,x)<x\Rightarrow$ получаем противоречие с начальными условиями $\Rightarrow f_z$ - единственные идемпотентные.

Предложение доказано.\\

Идемпотентность соблюдается так же \underline{только у $t$-конорм Заде}.\\

\opr

Определим \textbf{лингвистическую переменную} набором $(X, T(X), U, G, M)$, где

$X$ - название переменной;

$T(X)$ - терм-множество переменной $X$ (лингвистические значения);

$U$ - универсальное множество с базовой переменной $u$;

$G$ - синтаксическое правило, порождающее названия значений $X$;

$M$ - семантическое правило, ставящее в соотвестствие каждой нечёткой переменной $x\in X$ её смысл $M(x)$.

\primer

Пусть

$X=$ "температура в комнате"{};

$T=$ \{холодно, комфортно, жарко\};

$U=[5;\;35]$;

$M=\{\mu_c(u),\;\mu_n(u), \mu_h(u)\}$, где

$\mu_c(u)=\frac{1}{1+(\frac{u-10}{7})^{12}},\;\;\;\mu_n(u)=\frac{1}{1+(\frac{u-20}{3})^{6}},\;\;\;\mu_h(u)=\frac{1}{1+(\frac{u-30}{6})^{10}}$;

$G$ порождает новые термы с использованием союзов "и"{}, "или"{}, "не"{}, "очень"{}, "более-менее"{}:

\begin{center}
\begin{tabular}{|c|c|}
\cline{1-2}
\textbf{Терм} & \textbf{Вероятность} \\
\cline{1-2}
$\textbf{не }A$ & $1-\mu_A(u)$ \\
\cline{1-2}
$\textbf{очень }A$ & $(\mu_A(u))^2$ \\
\cline{1-2}
$\textbf{более-менее }A$ & $\sqrt{\mu_A(u)}$ \\
\cline{1-2}
$A\textbf{ или }B$ & $max(\mu_A(u),\;\mu_B(u))$ \\
\cline{1-2}
$A\textbf{ и }B$ & $min(\mu_A(u),\;\mu_B(u))$ \\
\cline{1-2}
\end{tabular}
\end{center}\newpage

Покажем на плоскости графики некоторых функций:

\begin{center}
\begin{tikzpicture} [
    declare function={
        poss(\x,\y,\z,\t) = 1 / (1 + ((\x - \y) / \z)^\t);
    },
    declare function={
        cold(\x) = poss(\x, 10, 6, 12);
    },
    declare function={
        comfortable(\x) = poss(\x, 20, 3, 6);
    },
    declare function={
        hot(\x) = poss(\x, 30, 7, 10);
    }
]
\begin{axis}[
    title=Температура в комнате,
    width = 12 cm,
	xlabel = {$t,^{\circ}C$},
	ylabel = {$\mu$},
    ylabel style={rotate=-90, at={(0,.91)}},
    domain = 10:30,
	minor tick num = 1,
    legend pos = outer north east
]
\addlegendimage{empty legend}
\addplot[color=blue, line width=.08cm]{cold(x)};
\addplot[color=green, line width=.08cm]{comfortable(x)};
\addplot[color=red, line width=.08cm]{hot(x)};
\addplot[color=blue, line width=.05cm, densely dotted]{1-(cold(x))^2};
\addplot[color=green, line width=.05cm, densely dotted]{sqrt(comfortable(x))};
\addplot[color=red, line width=.05cm, densely dotted]{hot(x)^2};

\addlegendentry{\hspace{-.4cm}\textbf{Ощущения}}
\addlegendentry{холодно}
\addlegendentry{комфортно}
\addlegendentry{жарко}
\addlegendentry{не очень холодно}
\addlegendentry{более-менее комфортно}
\addlegendentry{очень жарко}
\end{axis}
\end{tikzpicture}
\end{center}

К нечётной логике сначала научное сообщество отнеслось скептически, поскольку нечётная логика противоречила логике самого Аристотеля, которой люди руководствовались на протяжении многих веков. Мотивацией создания подобной логики стал "\textit{принцип несовместимости}"{} Заде, который гласил "\textit{чем сложнее система, тем сложнее дать точные и в то же время имеющие практическое значение суждения об её поведении}"{}. Т.е. потребовался инструмент, что не нуждался в абсолютной строгости ответа и с помощью которого можно было бы обрабатывать неточные данные.

Нечёткая логика эту возможность и дала. Но не смотря на то, что она была придумана в 1965 году, полное признание она получила лишь 20 лет спустя после доказательства Бартоломеем Коско знаменитой теоремы FAT(Fuzzy Approximation Theorem). В бизнесе и финансах нечеткая логика получила признание после того, как в 1988 году экспертная система на основе нечетких правил для прогнозирования финансовых индикаторов единственная предсказала биржевой крах. И количество успешных нечётких-применений в настоящее время исчисляется тысячами.

На данный момент широкое применение нечёткая логика имеет в нейронных сетях, базах данных, \textit{мягких вычислениях}, гибридных интеллектуальных системах и т.д..\\

Но несмотря на такие огромные прорывы благодаря нечёткой логике, она так же имеет весомые недостатки и свои парадоксы. И она по сей день имеет противников.\\

\msection{Анализ формальных понятий}

Анализ формальных понятий появался относительно недавно, в 80-х годах прошлого века, под влиянием работ Рудольфа Вилле.

Каждый объект обладает какими-либо свойствами. Например, треугольник - имеет 3 стороны, сумма углов 180$^{\circ}$; квадрат - имеет 4 стороны, все углы прямые, все стороны равны и т. д. Мы можем объединять объекты по схожим свойствам в группы, например, те же квадрат и треугольник можно объединить в группу многоугольников, а куб и сферу - в группу геометрических тел. Это и лежит в основе АФП.\newpage

\msubsection{Формальные контекст и понятия}

\opr

\textbf{Формальным контекстом} называется кортеж $\mathbb{K}=(G,M,I)$, где

$G$ - множество \textbf{объектов} контекста $\mathbb{K}$,

$M$ - множество \textbf{атрибутов} или \textbf{свойств} контекста $\mathbb{K}$,

$I\subseteq G\times M$ - отношение между множествами.\\

\primer

\begin{tabular}{|c|c|cccc|llll}
\cline{1-6}
& $G\backslash M$ & a & b & c & d & & & & \\
\cline{1-6}
    1 & \begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (.5, 0);
    \draw[color=black, very thick](0, 0) -- (.25, .43);
    \draw[color=black, very thick](.25, .43) -- (.5, 0);
    \end{tikzpicture}
& $\times$ & & & $\times$ & & & & a - ровно 3 стороны, \\
    2 & \begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (0, .5);
    \draw[color=black, very thick](0, 0) -- (.5, 0);
    \draw[color=black, very thick](.5, 0) -- (0, .5);
    \end{tikzpicture}
& $\times$ & & $\times$ & & & & & b - ровно 4 стороны, \\
    3 & \begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (0, .5);
    \draw[color=black, very thick](0, 0) -- (1, 0);
    \draw[color=black, very thick](1, .5) -- (0, .5);
    \draw[color=black, very thick](1, .5) -- (1, 0);
    \end{tikzpicture}
& & $\times$ & $\times$ & & & & & c - имеет прямой угол, \\
    4 & \begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (0, .5);
    \draw[color=black, very thick](0, 0) -- (.5, 0);
    \draw[color=black, very thick](.5, .5) -- (0, .5);
    \draw[color=black, very thick](.5, .5) -- (.5, 0);
    \end{tikzpicture}
& & $\times$ & $\times$ & $\times$ & & & & d -  все стороны равны. \\
\cline{1-6}
\end{tabular}\\

Можно догадаться, что всякую таблицу, в которой для каждого объекта определено наличие или отсутствие каждого свойства, можно преобразовать в формальный контекст. Если в таблице на пересечении строк и столбцов
вместо "да"{} и "нет"{} стоит более контретная характеристика, например, население страны, то такую таблицу тоже можно преобразовать в формальный контекст, только он будет многозначным. О многозначных контекстах мы поговорим
в следующем параграфе.\\

\opr

Для множеств $A\subseteq G\text{ и } B\subseteq M$ формального контекста $\mathbb{K}=(G,M,I)$ определим \textbf{операторы Галуа} следующим образом:

1) $A\galoisup=\{m\in M\;|\;\forall g\in A:gIm\}$, или множество всех свойств, которыми обладают все объекты из $A$;

2) $B\galoisdown=\{g\in G\;|\;\forall m\in B:gIm\}$, или множество всех объектов, которые обладают всеми свойствами из $B$.

\primer

Пусть формальный контекст задан следующим образом:

\begin{center}
\begin{tabular}{|c|cccc|}
\cline{1-5}
\textbf{$I$} & \textbf{$y_1$} & \textbf{$y_2$} & \textbf{$y_3$} & \textbf{$y_4$} \\
\cline{1-5}
\textbf{$x_1$} & $\times$ & $\times$ & $\times$ & $\times$ \\
\textbf{$x_2$} & $\times$ & & $\times$ & $\times$ \\
\textbf{$x_3$} & & $\times$ & $\times$ & $\times$ \\
\textbf{$x_4$} & & $\times$ & $\times$ & $\times$ \\
\textbf{$x_5$} & $\times$ & & & \\
\cline{1-5}
\end{tabular}
\end{center}

Операторы Галуа работают следующим образом:

1) $\{x_2\}\galoisup=\{y_1,\;y_3,\;y_4\},\;\{x_2,\;x_3\}\galoisup=\{y_3,\;y_4\}$;

2) $\{x_1,\;x_4,\;x_5\}\galoisup=\varnothing$;

3) $X\galoisup=\varnothing,\;\varnothing\galoisup=Y$;

4) $\{y_1\}\galoisdown=\{x_1,\;x_2,\;x_5\},\;\{y_1,\;y_2\}\galoisdown=\{x_1\}$;

5) $Y\galoisdown=\{x_1\},\;\varnothing\galoisdown=X$.\\

В литературе оба оператора Галуа иногда обозначаются штрихом $'$, но мы здесь будем пользоваться стрелочками.\\

Как это состыкуется с аксиоматизируемыми классами? Если мы каждое свойство мы будем понимать как атомарную формулу, которые образуют сигнатуру $\sg=\{P_i(a_1, ..., a_{n_i})\}$, а объекты - как модели
$\mA_i\in K(\sg)$ такие, что $\mA_i\vD P_j(a_1, ..., a_{n_j})\Leftrightarrow g_iIm_j$, то можно легко перейти от АФП к аксиоматизируемым классам и наоборот. Теперь мы смогли ответить на вопрос, зачем существует 22 глава:)\\

\opr

Пара множеств $(A,B)$ называется \textbf{формальным понятием} формального контекста $\mathbb{K}=(G,M,I)$, если:

1) $A\subseteq G\text,\;B\subseteq M$;

2) $A\galoisup=B,\;B\galoisdown=A$.

Множество $A$ называется \textbf{объёмом} ф.п. $(A,B)$, множество $B$ - его \textbf{содержанием}.

\primer

Пусть формальный контекст $\mathbb{K}$ задан так же, как и в предыдущем примере:

\begin{center}
\begin{tabular}{|c|cccc|}
\cline{1-5}
\textbf{$I$} & \textbf{$y_1$} & \textbf{$y_2$} & \textbf{$y_3$} & \textbf{$y_4$} \\
\cline{1-5}
\textbf{$x_1$} & $\times$ & $\times$ & \textcolor{blue}{$\times$} & \textcolor{blue}{$\times$} \\
\textbf{$x_2$} & $\times$ & & \textcolor{blue}{$\times$} & \textcolor{blue}{$\times$} \\
\textbf{$x_3$} & & $\times$ & \textcolor{blue}{$\times$} & \textcolor{blue}{$\times$} \\
\textbf{$x_4$} & & $\times$ & \textcolor{blue}{$\times$} & \textcolor{blue}{$\times$} \\
\textbf{$x_5$} & $\times$ & & & \\
\cline{1-5}
\end{tabular}
\end{center}

Синим цветом выделено формальное понятие $(A,B)=(\{x_1,x_2,x_3,x_4\},\newline\;\{y_3,y_4\}):\{x_1,x_2,x_3,x_4\}\galoisup=\{y_3,y_4\}\text{ и }\{y_3,y_4\}\galoisdown=\{x_1,x_2,x_3,x_4\}$.

Тут можно выделить и другие формальные понятия, например, $\newline(\{x_1,x_3,x_4\},\{y_2,y_3,y_4\})\text{ и }(\{x_1,x_2\},\{y_1,y_3,y_4\})$.\\

\predlT{Свойства операторов Галуа}

Пусть $\mathbb{K}=(G,\;M,\;I)$. Тогда $\forall A,A_1,A_2\in G,\;\forall B,B_1,B_2\in M$ выполняются следующие свойства:

1) $A_1\subseteq A_2\Rightarrow A_2\galoisup\subseteq A_1\galoisup$;

2) $A\subseteq A\galoisup\galoisdown$ - замыкание;

3) $A\galoisup=A\galoisup\galoisdown\galoisup$;

4) $B_1\subseteq B_2\Rightarrow B_2\galoisdown\subseteq B_1\galoisdown$;

5) $B\subseteq B\galoisdown\galoisup$ - замыкание;

6) $B\galoisdown=B\galoisdown\galoisup\galoisdown$;

7) $A\subseteq B\galoisdown\Leftrightarrow B\subseteq A\galoisup\Leftrightarrow A\times B\subseteq I$.

\dok

1) $m\in A_2\galoisup\Rightarrow\forall g\in A_2:gIm\Rightarrow\forall g\in A_1:gIm\Rightarrow m\in A_1\galoisup$.

2) $g\in A\Rightarrow\forall m\in A\galoisup:gIm\Rightarrow g\in A\galoisup\galoisdown$.\\

3) $\left.
  \begin{array}{c}
    A\galoisup\subseteq (A\galoisup)\galoisdown\galoisup\text{ из пункта 5} \\
    A\subseteq A\galoisup\galoisdown\Rightarrow (A\galoisup\galoisdown)\galoisup\subseteq A\galoisup
  \end{array}
  \right\}\Rightarrow A\galoisup=A\galoisup\galoisdown\galoisup$.\\

4)-6) аналогично 1)-3).

7) Сначала покажем, что $A\subseteq B\galoisdown\Leftrightarrow B\subseteq A\galoisup$:

$\rightdok$ $m\in B\Rightarrow\forall g\in B\galoisdown:gIm\Rightarrow\forall g\in A:gIm\Rightarrow m\in A\galoisup$.

$\leftdok$ Аналогично.\\

Далее покажем, что $A\subseteq B\galoisdown\Leftrightarrow A\times B\subseteq I$:

$\rightdok$ $(g,m)\in A\times B\Rightarrow g\in A\Rightarrow g\in B\galoisdown\Rightarrow\forall m'\in B:gIm'\Rightarrow gIm$.

$\leftdok$ $g\in A\Rightarrow\forall m\in B: gIm\Rightarrow g\in B\galoisdown$.

Предложение доказано.\\

\predl

Пусть $\mathbb{K}=(G,M,I),\;A\subseteq G,\;B\subseteq M$, тогда эти утверждения эквивалентны:

1) $(A,B)$ - формальное понятие;

2) $(A,B)=(B\galoisdown,B\galoisdown\galoisup)$;

3) $(A,B)=(A\galoisup\galoisdown,A\galoisup)$.\newpage

\dok

Покажем $(1)\Leftrightarrow (2)$:

$\rightdok$ Пусть $(A,B)$ - формальное понятие, тогда $(A,B)=(B\galoisdown,A\galoisup)=\newline=(B\galoisdown,B\galoisdown\galoisup)$.

$\leftdok$ Пусть $(A,B)=(B\galoisdown,B\galoisdown\galoisup)$, тогда $A=B\galoisdown$ и $B=(B\galoisdown)\galoisup=A\galoisup$.

Для пары $(1)\Leftrightarrow (3)$ доказательство аналогичное.

Предложение доказано.\\

\predl

Пусть $\mathbb{K}=(G,M,I),\;\ki$ - некоторое множество индексов и $\forall i\in\ki:\newline A_i\subseteq G,\;B_i\subseteq M$. Тогда:

1) $\bigs(\underset{i\in\ki}{\bigs\bigcup}A_i\bigs)\galoisup=\underset{i\in\ki}{\bigs\bigcap}A_i\galoisup$,\\

2) $\bigs(\underset{i\in\ki}{\bigs\bigcup}B_i\bigs)\galoisdown=\underset{i\in\ki}{\bigs\bigcap}B_i\galoisdown$.

\dok

1) $m\in\bigs(\underset{i\in\ki}{\bigs\bigcup}A_i\bigs)\galoisup\Leftrightarrow\forall g\in\underset{i\in\ki}{\bigs\bigcup}A_i\bigs:\;gIm\Leftrightarrow\forall i\in\ki:\forall g\in A_i:gIm\Leftrightarrow\newline\newline
\Leftrightarrow\forall i\in\ki:m\in A_i\Leftrightarrow m\in\underset{i\in\ki}{\bigs\bigcap}A_i\galoisup$.

2) Аналогично 1-му пункту.

Предложение доказано.\\

Теперь мы можем построить решётку формальных понятий. Напомним, что решётка - это частично упорядоченное множество, каждое двухэлементное подмножество которого имеет инфинум и супремум.\newpage

\opr

Пусть $(A_1,B_1),\;(A_2,B_2)$ - формальные понятия формального контекста $\mathbb{K}=(G,M,I)$. Понятие $(A_1,B_1)$ называется \textbf{подпонятием} понятия $(A_2,B_2)$, если $A_1\subseteq A_2$ (или $B_2\subseteq B_1$), и
обозначается $(A_1,B_1)\le(A_2,B_2)$.

\primer

Вспомним пример с геометрическими фигурами:

\begin{tabular}{|c|c|cccc|llll}
\cline{1-6}
& $G\backslash M$ & a & b & c & d & & & & \\
\cline{1-6}
    1&\begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (.5, 0);
    \draw[color=black, very thick](0, 0) -- (.25, .43);
    \draw[color=black, very thick](.25, .43) -- (.5, 0);
    \end{tikzpicture}
& $\times$ & & & $\times$ & & & & a - ровно 3 стороны, \\
    2&\begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (0, .5);
    \draw[color=black, very thick](0, 0) -- (.5, 0);
    \draw[color=black, very thick](.5, 0) -- (0, .5);
    \end{tikzpicture}
& $\times$ & & $\times$ & & & & & b - ровно 4 стороны, \\
    3&\begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (0, .5);
    \draw[color=black, very thick](0, 0) -- (1, 0);
    \draw[color=black, very thick](1, .5) -- (0, .5);
    \draw[color=black, very thick](1, .5) -- (1, 0);
    \end{tikzpicture}
& & $\times$ & $\times$ & & & & & c - имеет прямой угол, \\
    4&\begin{tikzpicture}
    \draw[color=black, very thick](0, 0) -- (0, .5);
    \draw[color=black, very thick](0, 0) -- (.5, 0);
    \draw[color=black, very thick](.5, .5) -- (0, .5);
    \draw[color=black, very thick](.5, .5) -- (.5, 0);
    \end{tikzpicture}
& & $\times$ & $\times$ & $\times$ & & & & d - все стороны равны. \\
\cline{1-6}
\end{tabular}\\

Построим решётку понятий этого контекста:

\begin{wrapfigure}[8]{l}{0.4\textwidth}
\begin{tikzpicture}
\draw[color=black, very thick](0,0) -- (0,4);
\draw[color=black, very thick](2,1) -- (2,5);
\draw[color=black, very thick](6,1) -- (6,3);
\draw[color=black, very thick](6,3) -- (6,5);
\draw[color=black, very thick](4,0) -- (4,4);
\draw[color=black, very thick](0,0) -- (4,0);
\draw[color=black, very thick](0,4) -- (4,4);
\draw[color=black, very thick](2,1) -- (6,1);
\draw[color=black, very thick](2,5) -- (6,5);
\draw[color=black, very thick](0,0) -- (2,1);
\draw[color=black, very thick](0,4) -- (2,5);
\draw[color=black, very thick](4,4) -- (6,5);
\draw[color=black, very thick](4,0) -- (6,3);

\draw[fill=black, color=black, very thick](0,0) circle (.05);
\draw[fill=black, color=black, very thick](4,0) circle (.05);
\draw[fill=black, color=black, very thick](6,1) circle (.05);
\draw[fill=black, color=black, very thick](2,1) circle (.05);
\draw[fill=black, color=black, very thick](6,3) circle (.05);
\draw[fill=black, color=black, very thick](0,4) circle (.05);
\draw[fill=black, color=black, very thick](4,4) circle (.05);
\draw[fill=black, color=black, very thick](6,5) circle (.05);
\draw[fill=black, color=black, very thick](2,5) circle (.05);

\node[scale=1.1] at (0,-.6) {$A$};
\node[scale=1.1] at (4,-.6) {$B$};
\node[scale=1.1] at (6,.4) {$C$};
\node[scale=1.1] at (2,.4) {$D$};
\node[scale=1.1] at (0.1,4.6) {$A_1$};
\node[scale=1.1] at (4.1,4.6) {$B_1$};
\node[scale=1.1] at (6.1,5.5) {$C_1$};
\node[scale=1.1] at (2.1,5.5) {$D_1$};
\node[scale=1.1] at (6.5,3) {$C_2$};
\end{tikzpicture}
\end{wrapfigure}

$A: (\varnothing, M)$ - пусто;

$B: (\{2\}, \{a,c\})$ - прямоугольные треугольники;

$C: (\{3,4\}, \{b,c\})$ - прямоугольные четырёхугольники;

$D: (\{4\}, \{b,c,d\})$ - квадраты;

$A_1: (\{1\}, \{a,d\})$ - равносторонние треугольники;

$B_1: (\{1,2\}, \{a\})$ - треугольники;

$C_1: (G,\varnothing)$ - многоугольники;

$D_1: (\{1,4\}, \{d\})$ - равносторонние фигуры;

$C_2: (\{2,3,4\}, \{c\})$ - прямоугольные фигуры.

Необходимо отметить, что не все комбинации фигур образуют понятия, например, из множества $\{1,2,3\}$ в силу предложения 50.5 не получится формальное понятие, так как $\{1,2,3\}\galoisup\galoisdown\neq\{1,2,3\}$.

\teorT{основная теорема о формальных понятиях}

Множество $\mB(G,M,I)$ всех формальных понятий формального контекста $\mathbb{K}=(G,M,I)$ с отношением $\le$ образует решётку ${\underline{\mB}}(G,M,I):=(\mB(G,M,I),\newline\wedge,\vee)$, в которой инфинум и супремум
задаются следующим образом:

1) $\underset{i\in\ki}{\bigs\bigwedge}(A_i,B_i)=\bigs{\bigs(}\underset{i\in\ki}{\bigs\bigcap}A_i, \bigs(\underset{i\in\ki}{\bigs\bigcup}B_i\bigs){\galoisdown\galoisup}\bigs{\bigs)}$;\\

2) $\underset{i\in\ki}{\bigs\bigvee}(A_i,B_i)=\bigs{\bigs(}\bigs(\underset{i\in\ki}{\bigs\bigcup}A_i\bigs){\galoisup\galoisdown}, \underset{i\in\ki}{\bigs\bigcap}B_i\bigs{\bigs)}$.

\dok

1) $\forall i\in\ki:(A_i,B_i)$ - формальное понятие. Тогда\\

$\bigs{\bigs(}\underset{i\in\ki}{\bigs\bigcap}A_i, \bigs(\underset{i\in\ki}{\bigs\bigcup}B_i\bigs){\galoisdown\galoisup}\bigs{\bigs)}=
\bigs{\bigs(}\underset{i\in\ki}{\bigs\bigcap}B_i\galoisdown, \bigs(\underset{i\in\ki}{\bigs\bigcup}B_i\bigs){\galoisdown\galoisup}\bigs{\bigs)}=
\bigs{\bigs(}\underset{i\in\ki}{\bigs(\bigs\bigcup}B_i\bigs)\galoisdown, \bigs(\underset{i\in\ki}{\bigs\bigcup}B_i\bigs){\galoisdown\galoisup}\bigs{\bigs)}$.

По предложению 50.5 это формальное понятие.

Покажем, что это точная нижняя грань: $\forall j\in\ki:\underset{i\in\ki}{\bigs\bigcap}A_i\subseteq A_j\Leftrightarrow\newline\Leftrightarrow
\bigs{\bigs(}\underset{i\in\ki}{\bigs\bigcap}A_i, \bigs(\underset{i\in\ki}{\bigs\bigcup}B_i\bigs){\galoisdown\galoisup}\bigs{\bigs)}\le(A_j,B_j)$.

2) Аналогично.

Теорема доказана.

\msubsection{Многозначные контексты}

Когда мы строили "однозначные"{} формальные контексты, мы говорили, обладает ли объект данным свойством или нет. Но свойства могут быть разными, начиная цветом яблока и заканчивая составом коктейля. Для таких случаев и
были введены многозначные контексты.\newpage

\opr

Кортеж $\mathbb{M}=(G,M,W,I)$ называется \textbf{многозначным формальным контекстом}, где:

$G$ - множество \textbf{объектов},

$M$ - множество \textbf{многозначных атрибутов},

$W$ - множество \textbf{значения атрибутов} $\mathbb{M}$,

$I\subseteq G\times M\times W$ - отношение такое, что $(g,m,w)\in I\text{ и }(g,m,v)\in I\Rightarrow\newline\Rightarrow w=v$.

\primer

Пусть многозначный формальный контекст $\mathbb{M}=(G,M,W,I)$ задан следующим образом:

$G=\{$Меркурий, Венера, Земля, Марс$\}$ - планеты земной группы;

$M=\{$Масса в Землях, Средний радиус планеты в Землях, Период обращения в земных сутках, Число спутников$\}$;

$W=\{$"Всякие данные планет"$\}$;

Отношение $I$ проще задать таблицей:

\begin{center}
\scalebox{.8}
{
\begin{tabular}{|c|c|c|c|c|}
\cline{1-5}
\textbf{Планеты} & \textbf{Масса в} & \textbf{Средний радиус} & \textbf{Период обращения} & \textbf{Число} \\
& \textbf{Землях} & \textbf{планеты в Землях} & \textbf{в земных сутках} & \textbf{спутников} \\
\cline{1-5}
Меркурий & 0,055 & 0,38 & 87,97 & 0 \\
\cline{1-5}
Венера & 0,82 & 0,95 & 224,7 & 0 \\
\cline{1-5}
Земля & 1 & 1 & 365,26 & 1 \\
\cline{1-5}
Марс & 0,11 & 0,53 & 687 & 2 \\
\cline{1-5}
\end{tabular}
}
\end{center}

\opr

Пусть $\mathbb{M}=(G,M,W,I)$, тогда \textbf{область определения} атрибута $m\in M$ - множество

$dom(m)=\{g\in G\;|\;\exists w\in W:(g,m,w)\in I\}$.\newpage

\opr

Пусть $\mathbb{M}=(G,M,W,I)$.

1) $m\in M$ - \textbf{полный атрибут}, если $dom(m)=G$.

2) $\mathbb{M}$ - \textbf{полный контекст}, если все его атрибуты полные.\\

Пример выше является полным контекстом, так как нет планет, у которых нет, например, массы или среднего радиуса.\\

\opr

Пусть $\mathbb{M}=(G,M,W,I)$. \textbf{Шкалой} многозначного атрибута $m$ называется формальный контекст $\mathbb{S}_m=(W_m,W_m,I_m)$, где $W_m=\{w\in W\;|\;\exists g\in G:\newline(g,m,w)\in I\}$.\\

\opr

Определим следующие шкалы:

1) $\mathbb{N}_n=(n,n,=)$ - \textbf{номинальная шкала};

2) $\mathbb{O}_n=(n,n,\le)$ - \textbf{порядковая шкала};

3) $M_{n,m}=(n,n,\le)\uplus(m,m,\ge)$ - \textbf{бипорядковая шкала}.\\

\primerT{номинальной шкалы}

Пусть $G$ - это множество соков, $n=\{$яблочный, виноградный, персиковый$\}$. Тогда шкала $\mathbb{N}_n=(n,n,=)$ будет выглядеть так:

\begin{center}
\scalebox{.8}
{
\begin{tabular}{|c|c|c|c|}
\cline{1-4}
& \textbf{яблочный} & \textbf{виноградный} & \textbf{персиковый} \\
\cline{1-4}
\textbf{яблочный} & $\times$ & & \\
\cline{1-4}
\textbf{виноградный} & & $\times$ & \\
\cline{1-4}
\textbf{персиковый} & & & $\times$ \\
\cline{1-4}
\end{tabular}
}
\end{center}\newpage

Решётка данной шкалы:

\begin{center}
\begin{tikzpicture}
\draw[color=black, very thick](0,0) -- (2,-1);
\draw[color=black, very thick](0,0) -- (2,0);
\draw[color=black, very thick](0,0) -- (2,1);
\draw[color=black, very thick](4,0) -- (2,-1);
\draw[color=black, very thick](4,0) -- (2,0);
\draw[color=black, very thick](4,0) -- (2,1);

\draw[fill=black, color=black, very thick](0,0) circle (.05);
\draw[fill=black, color=black, very thick](2,-1) circle (.05);
\draw[fill=black, color=black, very thick](2,0) circle (.05);
\draw[fill=black, color=black, very thick](2,1) circle (.05);
\draw[fill=black, color=black, very thick](4,0) circle (.05);

\node[scale=1.1] at (0,-.6) {$\varnothing$};
\node[scale=1.1] at (2,-1.5) {Я};
\node[scale=1.1] at (2,-.5) {В};
\node[scale=1.1] at (2,.5) {П};
\node[scale=1.1] at (4,-.6) {$M$};
\end{tikzpicture}
\end{center}

\primerT{порядковой шкалы}

Пусть $G$ - это множество студентов, $n=\{$чрезвычайно глупый, очень глупый, глупый$\}$. Тогда шкала $\mathbb{O}_n=(n,n,\le)$ будет выглядеть так:

\begin{center}
\scalebox{.8}
{
\begin{tabular}{|c|c|c|c|}
\cline{1-4}
& \textbf{чрезвычайно} & \textbf{очень} & \textbf{глупый} \\
& \textbf{глупый} & \textbf{глупый} & \\
\cline{1-4}
\textbf{чрезвычайно} & $\times$ & $\times$ & $\times$ \\
\textbf{глупый} & & & \\
\cline{1-4}
\textbf{очень} & & $\times$ & $\times$ \\
\textbf{глупый} & & & \\
\cline{1-4}
\textbf{глупый} & & & $\times$ \\
\cline{1-4}
\end{tabular}
}
\end{center}

Решётка такой порядковой шкалы:

\begin{center}
\begin{tikzpicture}
\draw[color=black, very thick](0,0) -- (3,0);
\draw[color=black, very thick](3,0) -- (6,0);
\draw[color=black, very thick](6,0) -- (9,0);

\draw[fill=black, color=black, very thick](0,0) circle (.05);
\draw[fill=black, color=black, very thick](3,0) circle (.05);
\draw[fill=black, color=black, very thick](6,0) circle (.05);
\draw[fill=black, color=black, very thick](9,0) circle (.05);

\node[scale=1.1] at (0,-.6) {$\varnothing$};
\node[scale=1.1] at (3,-.6) {Г};
\node[scale=1.1] at (6,-.6) {ОГ};
\node[scale=1.1] at (9,-.6) {ЧГ};
\end{tikzpicture}
\end{center}


\primerT{бипорядковой шкалы}

Пусть $G$ - это множество студентов,

$n=\{$чрезвычайно глупый, очень глупый, глупый$\}$, $m=\{$умный, очень умный$\}$.\newpage

Тогда шкала $M_{n,m}=(n,n,\le)\uplus(m,m,\ge)$ будет выглядеть так:

\begin{center}
\scalebox{.8}
{
\begin{tabular}{|c|c|c|c|c|c|}
\cline{1-6}
& \textbf{чрезвычайно} & \textbf{очень} & \textbf{глупый} & \textbf{умный} & \textbf{очень} \\
& \textbf{глупый} & \textbf{глупый} & & & \textbf{умный} \\
\cline{1-6}
\textbf{чрезвычайно} & $\times$ & $\times$ & $\times$ & & \\
\textbf{глупый} & & & & & \\
\cline{1-6}
\textbf{очень} & & $\times$ & $\times$ & & \\
\textbf{глупый} & & & & & \\
\cline{1-6}
\textbf{глупый} & & & $\times$ & & \\
\cline{1-6}
\textbf{умный} & & & & $\times$ & \\
\cline{1-6}
\textbf{очень} & & & & $\times$ & $\times$ \\
\textbf{умный} & & & & & \\
\cline{1-6}
\end{tabular}
}
\end{center}

Решётка этой шкалы также не очень замысловатая:

\begin{center}
\begin{tikzpicture}
\draw[color=black, very thick](0,0) -- (2,-1);
\draw[color=black, very thick](2,-1) -- (4,-1);
\draw[color=black, very thick](4,-1) -- (6,-1);
\draw[color=black, very thick](6,-1) -- (8,0);
\draw[color=black, very thick](0,0) -- (2,1);
\draw[color=black, very thick](2,1) -- (6,1);
\draw[color=black, very thick](6,1) -- (8,0);

\draw[fill=black, color=black, very thick](0,0) circle (.05);
\draw[fill=black, color=black, very thick](2,-1) circle (.05);
\draw[fill=black, color=black, very thick](4,-1) circle (.05);
\draw[fill=black, color=black, very thick](6,-1) circle (.05);
\draw[fill=black, color=black, very thick](2,1) circle (.05);
\draw[fill=black, color=black, very thick](6,1) circle (.05);
\draw[fill=black, color=black, very thick](8,0) circle (.05);

\node[scale=1.1] at (0,-.6) {$\varnothing$};
\node[scale=1.1] at (2,-1.6) {Г};
\node[scale=1.1] at (4,-1.6) {ОГ};
\node[scale=1.1] at (6,-1.6) {ЧГ};
\node[scale=1.1] at (2,.4) {У};
\node[scale=1.1] at (6,.4) {ОУ};
\node[scale=1.1] at (8,-.4) {$M$};
\end{tikzpicture}
\end{center}

\opr

Рассмотрим многозначный контекст $\mathbb{M}=(G,M,W,I)$ и множество шкал $\mathbb{S}=\{\mathbb{S}_m\;|\;m\in M\}$. \textbf{Формальным контекстом, порождённым} из контекста $\mathbb{M}$ с учётом шкалирования $\mathbb{S}$, называется контекст $\mathbb{K}_{\mathbb{M}}=(G,N,J)$, где $N=\underset{m\in M}{\bigs\bigcup}\langle\{m\}\times W_m\rangle$,\\

$J=\{(g,\langle m,n\rangle)\;|\;\exists w\in W:(g,m,w)\in I\text{ и } wI_wn\}$.

Фактически, это "разворачивание"{} многозначного контекста в однозначный.

\primer

Пусть многозначный контекст $\mathbb{M}=(G,M,W,I)$ задан следующим образом:

$G=\{\downarrow,\to,\oplus\}$ - бинарные логические операции;

$M=\{$Рефлексивность, Симметричность, Сохраняет 0$\}$ - свойства функций;

Отношение $I$ задано следующим образом:

\begin{center}
\scalebox{.8}
{
\begin{tabular}{|c|c|c|c|}
\cline{1-4}
\textbf{Бинарная} & \textbf{Рефлексивность} & \textbf{Симметричность} & \textbf{Сохраняет} \\
\textbf{операция} & & & \textbf{0} \\
\cline{1-4}
\textbf{$\downarrow$} & Не рефлексивная & Симметричная & Нет \\
\cline{1-4}
\textbf{$\to$} & Рефлексивная & Антисимметричная & Нет \\
\cline{1-4}
\textbf{$\oplus$} & Иррефлексивная & Симметричная & Да \\
\cline{1-4}
\end{tabular}
}
\end{center}

Тогда отношение $J$ формального контекста $\mathbb{K}_{\mathbb{M}}$ будет задано так (все шкалы номинальные):

\begin{center}
\scalebox{.8}
{
\begin{tabular}{|c||c|c|c||c|c|c||c|c|}
\cline{1-9}
\textbf{Бинарная} & \multicolumn{3}{c||}{\textbf{Рефлексивность}} & \multicolumn{3}{c||}{\textbf{Симметричность}} & \multicolumn{2}{c|}{\textbf{Сохраняет 0}} \\
\cline{2-9}
\textbf{операция} & рефл. & ирр. & не рефл. & симм. & антисимм. & не симм. & да & нет \\
\cline{1-9}
\textbf{$\downarrow$} & & & $\times$ & $\times$ & & & & $\times$ \\
\cline{1-9}
\textbf{$\to$} & $\times$ & & & & $\times$ & & & $\times$ \\
\cline{1-9}
\textbf{$\oplus$} & & $\times$ & & $\times$ & & & $\times$ & \\
\cline{1-9}
\end{tabular}
}
\end{center}

К нынешнему времени АФП нашёл применение в таких областях, как проектирование баз данных, программная инженерия, поиск информации, лингвистика и многих других.

Решётки формальных понятий помогают выстроить объекты в иерархию, в которой мы идём от частных понятий к более общим. По ним гораздо проще определить объекты, которые удовлетворяют определённым условиям, чем если бы мы искали
их в исходных таблицах. Поэтому многие фирмы специально заказывают подобные формальные контексты, например, чтобы можно было представить другим технические свойства автомобильных двигателей.

В лингвистике АФП используется для анализа фонетических и грамматических особенностей языков. Также он помогает в лексическом анализе языка, как как лексика легко поддаётся иерархии и классификации.

Можно много чего ещё рассказать об темах, что мы прошли. Многие из них уже не актуальны и на данный момент пылятся на полке, а какие то по сей день имеют применение в алгоритмах обработки знаний. Но именно благодаря некоторым достижениям нечёткой логики, АФП и метода резолюций в обработке поисковых запросов мы смогли склепать Вам склепать столь прекрасное творение под названием "\textit{методичка по ЛОПу}"{} :) \\

\begin{center}
    \textit{Мы, мужчины, не умеем сказать «прощай», оставаясь при этом джентльменами. Может, Кэри Грант или Дэвид Нивен знали, как это делается, но я сомневаюсь, что им было под силу сказать: «Прощай, математическая логика», — сохраняя при этом обаяние.}
\end{center}
\leavevmode\\\\\leavevmode\\\\\leavevmode\\\\\leavevmode\\\\\leavevmode\\\\\leavevmode\\\\
\begin{flushright}
	Создатель методички: Большим М.А., 2020\\
	Автор 2го издания: Муратов М.А., 2022
\end{flushright}

\end{document}
